{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/articulos/regresion_lineal_por_minimos_cuadrados_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHfozEt_pNRE"
      },
      "source": [
        "# Evaluando Regresión Lineal: Métricas, Validación y Cuándo Usarla\n",
        "\n",
        "Ya sabes implementar regresión lineal por mínimos cuadrados. Pero un modelo que hace predicciones no es útil si no sabes **qué tan buenas son esas predicciones** y **cuándo es apropiado usarlo**.\n",
        "\n",
        "En este artículo aprenderás a evaluar tu modelo, interpretar sus resultados y decidir cuándo usar este método. Al finalizar, comprenderás las métricas clave, las limitaciones del método y cuándo considerar alternativas.\n",
        "\n",
        "**Nota**: Este artículo continúa donde lo dejamos en el artículo anterior. Si aún no has implementado regresión lineal por mínimos cuadrados, comienza por ahí para aprovechar al máximo este contenido.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-arE5vUcMZZ"
      },
      "source": [
        "# **1. Configuración inicial**\n",
        "\n",
        "Primero recreamos el modelo que construimos en el artículo anterior con los mismos datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xarx-Wo0pNRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4abd86a-1eea-40f5-a736-24ba43b4fcf4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datos de ejemplo: tamaño de casa vs precio (los mismos del artículo anterior)\n",
        "area = np.array([50, 55, 60, 64, 70, 78, 80, 89, 90, 100])\n",
        "price = np.array([140000, 155000, 190000, 200000, 225000,\n",
        "                  212000, 240000, 230000, 270000, 300000])\n",
        "\n",
        "# Matriz de diseño\n",
        "X = np.column_stack([np.ones(len(area)), area])\n",
        "y = price\n",
        "\n",
        "def least_squares(X, y):\n",
        "    \"\"\"Calcula los coeficientes óptimos usando mínimos cuadrados\"\"\"\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "\n",
        "# Calcular coeficientes y predicciones\n",
        "w = least_squares(X, y)\n",
        "y_pred = X @ w\n",
        "\n",
        "print(f\"Coeficientes calculados:\")\n",
        "print(f\"  w₀ (intercept) = ${w[0]:,.2f}\")\n",
        "print(f\"  w₁ (slope) = ${w[1]:,.2f}/m²\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes calculados:\n",
            "  w₀ (intercept) = $10,722.85\n",
            "  w₁ (slope) = $2,791.81/m²\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The strength of the linear relationship: the correlation coefficient $r$\n",
        "\n",
        "To evaluate our model, it's useful to ask ourselves: **to what extent are $x$ and $y$ linearly related?**\n",
        "\n",
        "The **linear correlation coefficient $r$** measures precisely that: the **strength and direction** of the linear relationship between two variables. Its value is always between $-1$ and $1$:\n",
        "- $r = 1$: perfect positive linear relationship (as $x$ increases, $y$ increases proportionally)\n",
        "- $r = -1$: perfect negative linear relationship\n",
        "- $r = 0$: no linear relationship\n",
        "- $|r|$ close to 1 → strong relationship\n",
        "- $|r|$ close to 0 → weak relationship\n",
        "\n",
        "In linear regression, the linear correlation coefficient $r$ is defined as the quotient between the covariance of the two variables and the product of their standard deviations. Covariance measures the joint variability of two variables.\n",
        "\n",
        "Mathematically,\n",
        "\n",
        "$$\n",
        "r = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X \\sigma_Y}\n",
        "$$\n",
        "\n",
        "Expanding the formula we obtain:\n",
        "\n",
        "$$\n",
        "r = \\frac{\\sum_{i=1}^{m} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{m} (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i=1}^{m} (y_i - \\bar{y})^2}}\n",
        "$$\n",
        "\n",
        "> **Intuitive note**: The numerator measures how the deviations of $x$ and $y$ from their means move together. If they always go up or down together, $r$ will be high. If not, they cancel out and $r$ will be low. Then it's divided by the product of the deviations to standardize between -1 and 1.\n",
        "\n",
        "This $r$ is especially useful **before fitting the model**: if $|r|$ is very low, we already know that a straight line won't capture the relationship between the variables well.\n",
        "\n",
        "These formulas work perfectly for one independent variable $X$, but what happens when we have multiple features? This is where matrix notation becomes indispensable."
      ],
      "metadata": {
        "id": "t-_A1YOgGWEF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdOYhHWvpNRG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Métricas de Evaluación**\n",
        "\n",
        "Ahora que tenemos predicciones, necesitamos cuantificar qué tan buenas son. Usaremos dos métricas fundamentales que nos dan perspectivas complementarias sobre el rendimiento del modelo.\n",
        "\n",
        "## RMSE: El error promedio\n",
        "\n",
        "El **RMSE (Root Mean Square Error)** nos dice el error promedio en las mismas unidades que nuestra variable objetivo (dólares). Es intuitivo: si el RMSE es \\\\$10,000, significa que en promedio nuestras predicciones se desvían ±\\\\$10,000 del valor real.\n",
        "\n",
        "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "## R²: La variabilidad explicada\n",
        "\n",
        "El **R² (Coeficiente de Determinación)** indica qué proporción de la variabilidad de los datos explica nuestro modelo. Varía entre 0 y 1, donde 1 significa ajuste perfecto.\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
        "\n",
        "**Interpretación práctica:**\n",
        "- **R² = 1**: Modelo perfecto (explica el 100% de la variabilidad)\n",
        "- **R² = 0.95**: El modelo explica el 95% de la variabilidad en los datos\n",
        "- **R² = 0**: El modelo no es mejor que simplemente predecir el promedio\n",
        "\n",
        "## Conexión con la correlación\n",
        "\n",
        "Aquí viene un detalle importante: **en regresión lineal simple (una sola variable), R² = r²**, donde r es el coeficiente de correlación de Pearson.\n",
        "\n",
        "Esto significa:\n",
        "- **r** te dice *cuánto se mueven juntos* $x$ e $y$ (y su dirección con el signo)\n",
        "- **R²** te dice *qué porcentaje de la variabilidad en $y$ explica tu modelo*\n",
        "\n",
        "Ejemplo práctico:\n",
        "- Si r = 0.9, entonces R² = 0.81 → el modelo explica el **81%** de la variabilidad\n",
        "- Si r = 0.5, entonces R² = 0.25 → el modelo explica solo el **25%** de la variabilidad"
      ],
      "metadata": {
        "id": "dIv_SiLlmEGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos las métricas de evaluación\n",
        "mse = np.mean((y - y_pred) ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Coeficiente de determinación R²\n",
        "ss_res = np.sum((y - y_pred) ** 2)  # Suma de cuadrados de residuos\n",
        "ss_tot = np.sum((y - y.mean()) ** 2)  # Suma total de cuadrados\n",
        "r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PERFORMANCE METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"R² (coefficient of determination): {r2:.4f}\")\n",
        "print(f\"  → The model explains {r2*100:.2f}% of variability\")\n",
        "print(f\"\\nRMSE (root mean squared error): ${rmse:,.2f}\")\n",
        "print(f\"  → Average prediction error of ~${rmse:,.0f}\")"
      ],
      "metadata": {
        "id": "GZqDjZoKmH-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcd9aab-4e02-4db6-c692-0a14ba970f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "PERFORMANCE METRICS\n",
            "==================================================\n",
            "R² (coefficient of determination): 0.9001\n",
            "  → The model explains 90.01% of variability\n",
            "\n",
            "RMSE (root mean squared error): $14,573.71\n",
            "  → Average prediction error of ~$14,574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizando el ajuste\n",
        "\n",
        "Las métricas nos dan números, pero visualizar el ajuste nos ayuda a entender mejor el rendimiento del modelo:"
      ],
      "metadata": {
        "id": "visualization_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización del modelo\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Subplot 1: Ajuste del modelo\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(area, price/1000, alpha=0.6, s=100, label='Actual data')\n",
        "plt.plot(area, y_pred/1000, 'r-', linewidth=2, label='Linear fit')\n",
        "plt.xlabel('Area (m²)', fontsize=11)\n",
        "plt.ylabel('Price (thousands $)', fontsize=11)\n",
        "plt.title(f'Model Fit (R² = {r2:.3f})', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Subplot 2: Análisis de residuos\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y - y_pred\n",
        "plt.scatter(y_pred/1000, residuals/1000, alpha=0.6, s=100)\n",
        "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "plt.xlabel('Predicted Price (thousands $)', fontsize=11)\n",
        "plt.ylabel('Residuals (thousands $)', fontsize=11)\n",
        "plt.title(f'Residual Analysis (RMSE = ${rmse/1000:.1f}k)', fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nResidual analysis shows how far off each prediction is from the actual value.\")\n",
        "print(\"Ideally, residuals should be randomly distributed around zero.\")"
      ],
      "metadata": {
        "id": "visualization_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "separator1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Haciendo Predicciones**\n",
        "\n",
        "Con nuestro modelo evaluado, podemos usarlo para predecir precios de nuevas viviendas:"
      ],
      "metadata": {
        "id": "predictions_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones para nuevas viviendas\n",
        "new_areas = np.array([65, 85, 95])\n",
        "predictions = w[0] + w[1] * new_areas\n",
        "\n",
        "print(\"\\nPREDICTIONS FOR NEW PROPERTIES\")\n",
        "print(\"-\" * 40)\n",
        "for area_val, pred in zip(new_areas, predictions):\n",
        "    print(f\"   {area_val}m² house  →  ${pred:,.0f}\")\n",
        "\n",
        "print(f\"\\n(Remember: predictions have ~${rmse:,.0f} average error)\")"
      ],
      "metadata": {
        "id": "T0nwWjqq0edR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c121f81-d9cc-4ac5-aa6a-6221ff2a0055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PREDICTIONS FOR NEW PROPERTIES\n",
            "----------------------------------------\n",
            "   65m² house  →  $192,190\n",
            "   85m² house  →  $248,027\n",
            "   95m² house  →  $275,945\n",
            "\n",
            "(Remember: predictions have ~$14,574 average error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "separator2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Comparación con scikit-learn**\n",
        "\n",
        "Una forma excelente de validar nuestra implementación es compararla con la biblioteca estándar de la industria:"
      ],
      "metadata": {
        "id": "E99vM8Zld5Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Creamos y entrenamos el modelo de scikit-learn\n",
        "sklearn_model = LinearRegression()\n",
        "sklearn_model.fit(area.reshape(-1, 1), price)\n",
        "\n",
        "# Predicciones con scikit-learn\n",
        "sklearn_pred = sklearn_model.predict(area.reshape(-1, 1))\n",
        "sklearn_rmse = np.sqrt(mean_squared_error(price, sklearn_pred))\n",
        "sklearn_r2 = r2_score(price, sklearn_pred)\n",
        "\n",
        "# Comparamos resultados\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"COMPARISON: Our Implementation vs scikit-learn\")\n",
        "print(\"=\"*65)\n",
        "print(f\"\\n{'Parameter':<20} {'Our impl.':<22} {'scikit-learn':<22}\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'w₀ (intercept)':<20} ${w[0]:>18,.2f}   ${sklearn_model.intercept_:>18,.2f}\")\n",
        "print(f\"{'w₁ (slope)':<20} ${w[1]:>17,.2f}/m²  ${sklearn_model.coef_[0]:>17,.2f}/m²\")\n",
        "print(f\"\\n{'R²':<20} {r2:>21.4f}   {sklearn_r2:>21.4f}\")\n",
        "print(f\"{'RMSE':<20} ${rmse:>20,.2f}   ${sklearn_rmse:>20,.2f}\")\n",
        "print(\"\\n✓ Results are identical! Our implementation is correct.\")"
      ],
      "metadata": {
        "id": "oYTFVW4W0gEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6031312c-9e6e-4564-f86d-88ef35f1f069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            "COMPARISON: Our Implementation vs scikit-learn\n",
            "=================================================================\n",
            "\n",
            "Parameter            Our impl.              scikit-learn          \n",
            "-----------------------------------------------------------------\n",
            "w₀ (intercept)       $         10,722.85   $         10,722.85\n",
            "w₁ (slope)           $         2,791.81/m²  $         2,791.81/m²\n",
            "\n",
            "R²                                  0.9001                  0.9001\n",
            "RMSE                 $           14,573.71   $           14,573.71\n",
            "\n",
            "✓ Results are identical! Our implementation is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "separator3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Ventajas, Limitaciones y Cuándo Usarlo**\n",
        "\n",
        "Ahora que entendemos cómo funciona y cómo evaluarlo, es crucial saber cuándo es apropiado usar este método.\n",
        "\n",
        "## Ventajas del método de mínimos cuadrados\n",
        "\n",
        "El método de mínimos cuadrados ordinarios (OLS) tiene características que lo hacen especialmente valioso:\n",
        "\n",
        "- **Solución exacta**: Encuentra los coeficientes óptimos directamente, sin iteraciones ni aproximaciones\n",
        "- **Rapidez**: Para datasets pequeños y medianos, es computacionalmente muy eficiente\n",
        "- **Interpretabilidad**: Los coeficientes tienen una interpretación directa y clara que puedes explicar a stakeholders\n",
        "- **Garantía matemática**: Si existe solución, este método la encuentra\n",
        "- **Sin hiperparámetros**: No requiere ajuste de learning rate ni otros parámetros\n",
        "\n",
        "## Limitaciones importantes\n",
        "\n",
        "Sin embargo, el método tiene limitaciones que debes conocer:"
      ],
      "metadata": {
        "id": "MyFfz5WWeunw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de problema con multicolinealidad\n",
        "X_problem = np.column_stack([area, area * 2])  # Columnas linealmente dependientes\n",
        "\n",
        "print(\"Example with linearly dependent columns:\")\n",
        "print(\"\\nFirst 3 rows of problematic matrix:\")\n",
        "print(X_problem[:3])\n",
        "print(f\"\\nDeterminant of X.T @ X: {np.linalg.det(X_problem.T @ X_problem):.2e}\")\n",
        "print(\"\\nA determinant near zero indicates matrix inversion problems!\")\n",
        "print(\"This happens when features are perfectly correlated.\")"
      ],
      "metadata": {
        "id": "MxawDmVwevly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78508a19-2a65-461e-bab2-a3d411fbdecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example with linearly dependent columns:\n",
            "\n",
            "First 3 rows of problematic matrix:\n",
            "[[ 50 100]\n",
            " [ 55 110]\n",
            " [ 60 120]]\n",
            "\n",
            "Determinant of X.T @ X: 0.00e+00\n",
            "\n",
            "A determinant near zero indicates matrix inversion problems!\n",
            "This happens when features are perfectly correlated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problemas principales del método:**\n",
        "\n",
        "1. **Matrices singulares**: Cuando las variables son linealmente dependientes, la matriz ($X^T X$) no es invertible\n",
        "2. **Multicolinealidad**: Variables predictoras muy correlacionadas causan coeficientes inestables\n",
        "3. **Escalabilidad limitada**: Para datasets muy grandes (millones de registros), la inversión de matriz tiene complejidad O(n³) y se vuelve prohibitivamente costosa\n",
        "4. **Sensibilidad a outliers**: Los errores al cuadrado amplifican el efecto de valores atípicos, pudiendo sesgar el modelo\n",
        "5. **Consumo de memoria**: Requiere cargar todo el dataset en memoria RAM\n",
        "\n",
        "## ¿Cuándo usar mínimos cuadrados vs Gradient Descent?\n",
        "\n",
        "La elección entre estos métodos depende principalmente del tamaño de tus datos:\n",
        "\n",
        "**Usa mínimos cuadrados cuando:**\n",
        "- Tienes  pocas características, normalmente menos de unos cientos de columnas en hardware de consumo\n",
        "- Necesitas la solución exacta en una sola operación\n",
        "- El dataset cabe cómodamente en memoria RAM\n",
        "- Requieres interpretabilidad directa de los coeficientes\n",
        "- No hay problemas de multicolinealidad\n",
        "\n",
        "**Usa Gradient Descent cuando:**\n",
        "- Tienes millones de registros o cientos/miles de características\n",
        "- El dataset no cabe en memoria (puedes usar mini-batches)\n",
        "- Necesitas actualizar el modelo con nuevos datos continuamente (online learning)\n",
        "- Trabajas con redes neuronales u otros modelos no lineales\n",
        "- Quieres regularización más flexible (L1, L2)\n",
        "\n",
        "**Regla práctica**: Superando varios cientos de características, el costo y la dificultad para invertir matrices aumentan de manera no lineal, haciendo que los métodos iterativos como el descenso del gradiente sean una mejor opción para datasets extensos o de alta dimensión."
      ],
      "metadata": {
        "id": "when_to_use"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "separator4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Conclusión**\n",
        "\n",
        "En este artículo completamos nuestro recorrido por la regresión lineal con mínimos cuadrados, aprendiendo no solo a construir el modelo, sino también a evaluarlo correctamente y entender cuándo usarlo.\n",
        "\n",
        "## Recapitulación\n",
        "\n",
        "**Lo que aprendimos:**\n",
        "- Cómo medir el rendimiento con **RMSE** y **R²**\n",
        "- La relación entre R² y la correlación\n",
        "- Cómo visualizar y validar el ajuste del modelo\n",
        "- Las ventajas y limitaciones del método\n",
        "- Cuándo elegir mínimos cuadrados vs Gradient Descent\n",
        "\n",
        "**Por qué importa:**\n",
        "La regresión lineal por mínimos cuadrados es:\n",
        "- **Tu punto de partida** para cualquier problema de predicción numérica\n",
        "- **Extremadamente efectiva** cuando hay relaciones lineales en los datos\n",
        "- **Interpretable y explicable**, crucial en contextos empresariales\n",
        "- **La base** para entender métodos más avanzados\n",
        "\n",
        "## Próximos pasos\n",
        "\n",
        "Ahora que dominas la solución de forma cerrada, el siguiente paso natural es explorar el **algoritmo de Gradient Descent**. Este método te permitirá:\n",
        "- Escalar a problemas con millones de datos\n",
        "- Entender la optimización iterativa\n",
        "- Prepararte para Deep Learning\n",
        "\n",
        "En el próximo artículo de esta serie, implementaremos Gradient Descent desde cero y compararemos su rendimiento con mínimos cuadrados, dándote todas las herramientas para decidir qué método usar en cada situación.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "h1GOTQ9wPTkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blog Tags\n",
        "\n",
        "```txt\n",
        "#Python\n",
        "#DataScience\n",
        "#MachineLearning\n",
        "#LinearRegression\n",
        "#ModelEvaluation\n",
        "#RMSE\n",
        "#R2Score\n",
        "#Statistics\n",
        "#scikit-learn\n",
        "#Tutorial\n",
        "#Metrics\n",
        "```"
      ],
      "metadata": {
        "id": "Q8oJLvNrEmA_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}