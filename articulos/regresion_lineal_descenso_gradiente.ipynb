{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsCzHpFfNF4+1xdRFUJjXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/articulos/regresion_lineal_descenso_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Descent: How a Linear Regression Model Learns to Fit Data**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introducción: ¿Qué problema queremos resolver?\n",
        "\n",
        "En el corazón del Machine Learning y la Ciencia de Datos se encuentra una tarea fundamental: la **predicción**. Queremos usar datos que ya tenemos para hacer estimaciones inteligentes sobre datos que aún no hemos visto.\n",
        "\n",
        "Empecemos con un ejemplo clásico y sencillo: **predecir el precio de una vivienda basándonos en su tamaño.**\n",
        "\n",
        "Imagina que tenemos un conjunto de datos de casas. Para cada casa, conocemos su tamaño en metros cuadrados (nuestra variable $x$) y el precio final por el que se vendió (nuestra variable $y$). Si visualizamos estos datos en un gráfico, probablemente veremos una \"nube de puntos\" que tiende a ir hacia arriba: a más metros cuadrados, mayor es el precio.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro objetivo es trazar **una línea recta** que represente de la mejor forma posible la tendencia de esos puntos. Esta línea será nuestro \"modelo\" de Regresión Lineal. ¿Por qué? Porque una vez que tengamos esa línea, si alguien nos da un nuevo tamaño ($x$) de una casa que no estaba en nuestros datos, podremos \"consultar\" la línea para estimar su precio ($y$).\n",
        "\n",
        "### La Ecuación de Nuestro Modelo\n",
        "\n",
        "Como recordarás de tus clases de matemáticas, la ecuación de una línea recta es $y = b + mx$. En Machine Learning, usamos una notación ligeramente diferente pero que significa exactamente lo mismo:\n",
        "\n",
        "$$\\hat{y} = w_0 + w_1 x$$\n",
        "\n",
        "Vamos a analizar estos términos, ya que los usaremos durante todo el artículo:\n",
        "\n",
        "* **$x$**: Es nuestra variable de entrada (el *feature*), en este caso, el tamaño de la casa.\n",
        "* **$\\hat{y}$** (se pronuncia \"y-sombrero\" o \"y-gorro\"): Es la **predicción** de nuestro modelo (el precio estimado). La distinguimos de la $y$ real (el precio de venta verdadero).\n",
        "* **$w_0$**: Es el **sesgo** (del inglés *bias*). Es la altura de la ordenada en el origen ($b$). Es el precio base que tendría nuestra predicción $\\hat{y}$ si $x$ fuera 0.\n",
        "* **$w_1$**: Es el **peso** (del inglés *weight*). Es el equivalente a la pendiente ($m$). Nos dice cuánto cambia $\\hat{y}$ (precio) por cada unidad que aumenta $x$ (metro cuadrado).\n",
        "\n",
        "**Objetivo:** Encontrar $ w_0 $ y $ w_1 $ que nos den la recta que mejor se ajuste a la nube de puntos.\n",
        "\n",
        "La pregunta clave que da origen a todo lo que sigue es: De todas las rectas posibles, ¿cómo encontramos la que **\"mejor se ajusta\"** a los datos? ¿Qué significa \"la mejor\"?\n",
        "\n",
        "Para responder a esto, necesitamos una forma de medir qué tan \"equivocada\" está nuestra línea. Necesitamos cuantificar el error. Y a esa medida la llamaremos nuestra **Función de Costes**."
      ],
      "metadata": {
        "id": "nZ3lqREXVpXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2. Midiendo el Error: La Función de Costes\n",
        "\n",
        "En el apartado anterior, nos quedamos con una pregunta clave: ¿cómo definimos la \"mejor\" línea?\n",
        "\n",
        "Intuitivamente, la mejor línea será aquella que esté **lo más cerca posible de todos los puntos de datos** al mismo tiempo. Necesitamos una forma de cuantificar esta \"cercanía\" total.\n",
        "\n",
        "### El Residuo: El Error de un Solo Punto\n",
        "\n",
        "Primero, veamos el error para un solo punto. Digamos que tenemos una casa (nuestro punto $i$-ésimo) que mide $x_i$ metros cuadrados y se vendió por un precio real $y_i$.\n",
        "\n",
        "Si nuestra línea (definida por $w_0$ y $w_1$) predice un precio $\\hat{y}_i$ para esa casa, el error para *ese punto* es simplemente la diferencia vertical entre el valor real y el valor predicho.\n",
        "\n",
        "$$\\text{Error}_i = e_i = y_i - \\hat{y}_i$$\n",
        "\n",
        "A esta diferencia la llamamos **\"residuo\"**.\n",
        "* Si el punto real está por encima de la línea ($y_i > \\hat{y}_i$), el residuo $e_i$ es positivo.\n",
        "* Si el punto real está por debajo de la línea ($y_i < \\hat{y}_i$), el residuo $e_i$ es negativo.\n",
        "\n",
        "### Agregando el Error: El Error Cuadrático Medio (MSE)\n",
        "\n",
        "Ahora, ¿cómo combinamos los residuos de *todos* nuestros puntos ($m$ puntos en total) en una sola métrica?\n",
        "\n",
        "El primer impulso sería simplemente sumarlos. Pero esto es una mala idea: un residuo de +1000 y otro de -1000 se cancelarían mutuamente, haciendo parecer que nuestro modelo no tiene error, ¡cuando en realidad está fallando estrepitosamente en ambos puntos!\n",
        "\n",
        "Para solucionar esto, hacemos dos cosas:\n",
        "\n",
        "1.  **Elevamos cada residuo al cuadrado:** $e_i^2 = (y_i - \\hat{y}_i)^2$.\n",
        "    * Esto convierte todos los errores en números positivos (ej. $(-100)^2 = 10000$ y $(+100)^2 = 10000$). ¡Se acabaron las cancelaciones!\n",
        "    * Además, **penaliza los errores grandes mucho más** que los pequeños. Un error de 10 se convierte en 100, pero un error de 2 solo se convierte en 4. Esto fuerza al modelo a evitar predicciones muy alejadas de la realidad.\n",
        "\n",
        "2.  **Calculamos la media:** Sumamos todos estos errores al cuadrado y los dividimos por el número de puntos ($m$). Esto nos da el **Error Cuadrático Medio** (o *Mean Squared Error, MSE*).\n",
        "\n",
        "Esta métrica es nuestra **Función de Costes**, que comúnmente se denota como $J$.\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Si sustituimos $\\hat{y}_i$ por la ecuación de nuestra línea, $(w_0 + w_1 x_i)$, obtenemos la fórmula completa:\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - (w_0 + w_1 x_i))^2$$\n",
        "\n",
        "> **Nota técnica:** En muchos libros verás esta fórmula con un $\\frac{1}{2m}$ en lugar de $\\frac{1}{m}$. (Ej. $J = \\frac{1}{2m} \\sum...$). Este $\\frac{1}{2}$ se añade por pura conveniencia matemática: al derivar $(y - \\hat{y})^2$ obtenemos $2(y - \\hat{y})$, y el factor $\\frac{1}{2}$ cancela ese 2, simplificando las ecuaciones del gradiente. Esto no cambia dónde está el mínimo de la función.\n",
        "\n",
        "\n",
        "### Nuestro Nuevo Objetivo\n",
        "\n",
        "¡Este es el punto clave! Fíjate en $J(w_0, w_1)$. Nuestros datos ($x$ e $y$) son fijos. Por lo tanto, el coste $J$ **no es una función de $x$**, sino una función de nuestros parámetros $w_0$ y $w_1$.\n",
        "\n",
        "* Diferentes valores de $w_0$ y $w_1$ (diferentes líneas) nos darán un coste $J$ diferente.\n",
        "* Una línea mala tendrá un coste $J$ muy alto.\n",
        "* Una línea buena tendrá un coste $J$ muy bajo.\n",
        "\n",
        "Si imaginamos todos los posibles valores de $w_0$ y $w_1$ y el coste $J$ que producen, obtendríamos una superficie en 3D con forma de \"cuenco\" o valle.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro problema de \"encontrar la mejor línea\" se ha transformado en un problema de optimización mucho más claro:\n",
        "\n",
        "**Encontrar los valores de $w_0$ y $w_1$ que nos sitúen en el punto más bajo (el mínimo) de este cuenco.**\n",
        "\n",
        "¿Y cómo encontramos ese punto mínimo? No lo haremos probando todas las combinaciones al azar. Usaremos un algoritmo inteligente llamado **Descenso del Gradiente**."
      ],
      "metadata": {
        "id": "h0FP2R1IXIL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. El Algoritmo: Descenso del Gradiente (Gradient Descent)\n",
        "\n",
        "Ahora que sabemos que nuestro objetivo es minimizar la Función de Costes $J(w_0, w_1)$, necesitamos un método sistemático para alcanzar ese mínimo global. Aquí es donde entra en juego el **Descenso del Gradiente**.\n",
        "\n",
        "El Descenso del Gradiente es un **algoritmo de optimización iterativo** que se utiliza para encontrar los valores de los parámetros $(w_0, w_1)$ que minimizan una función (nuestra función de costes).\n",
        "\n",
        "### La Analogía de la Montaña ⛰️\n",
        "\n",
        "La forma más intuitiva de entender el Descenso del Gradiente es a través de una analogía.\n",
        "\n",
        "Imagina que estás en la cima de una montaña, con los ojos vendados, y tu objetivo es llegar al valle (el punto más bajo).\n",
        "\n",
        "1.  **Tu Posición:** Tu posición actual en la montaña corresponde a los valores actuales de tus parámetros **$(w_0, w_1)$**.\n",
        "2.  **El Objetivo:** El valle corresponde al **mínimo global** de la función de costes $J$.\n",
        "\n",
        "Como estás vendado, no puedes ver el valle, pero puedes sentir el suelo bajo tus pies. ¿Cómo te mueves de manera eficiente?\n",
        "\n",
        "* **Paso 1: Siente la Pendiente:** Tientas el suelo a tu alrededor para determinar la dirección en la que la pendiente es **más pronunciada hacia abajo**. Esta dirección de máximo descenso es el **gradiente**.\n",
        "* **Paso 2: Da un Paso:** Una vez que conoces la dirección, das un paso. El tamaño de ese paso está determinado por la **tasa de aprendizaje**.\n",
        "* **Paso 3: Repite:** Repites este proceso (sentir la pendiente y dar un paso) hasta que llegas a un punto donde ya no puedes bajar más.\n",
        "\n",
        "El Descenso del Gradiente hace exactamente esto, pero en el mundo de las matemáticas:\n",
        "\n",
        "### El Descenso del Gradiente en ML\n",
        "\n",
        "El algoritmo comienza con unos valores **iniciales aleatorios** para nuestros parámetros $w_0$ y $w_1$ (estás en algún punto aleatorio de la montaña). Luego, repite un ciclo de actualización hasta la **convergencia**:\n",
        "\n",
        "#### 1. Calcular el Gradiente (La Dirección)\n",
        "\n",
        "El gradiente es una herramienta del cálculo (un vector de derivadas parciales) que nos dice exactamente cuál es la **pendiente** de la función de costes $J$ en nuestra posición actual $(w_0, w_1)$.\n",
        "\n",
        "* Si la pendiente es positiva, significa que estamos a la izquierda del mínimo y debemos reducir el valor de $w$.\n",
        "* Si la pendiente es negativa, estamos a la derecha y debemos aumentar el valor de $w$.\n",
        "\n",
        "Matemáticamente, el gradiente apunta siempre hacia la **máxima subida**. Por lo tanto, si queremos *descender* (minimizar el coste), debemos movernos en la **dirección opuesta** al gradiente. Esto explica el signo negativo que introduciremos.\n",
        "\n",
        "#### 2. La Actualización de los Parámetros (El Paso)\n",
        "\n",
        "En cada iteración, actualizamos **simultáneamente** $w_0$ y $w_1$ usando la siguiente regla:\n",
        "\n",
        "$$\\text{Nuevo } w_j = \\text{Antiguo } w_j - (\\text{Tasa de Aprendizaje } \\times \\text{ Gradiente})$$\n",
        "\n",
        "Donde $w_j$ representa cualquiera de nuestros parámetros ($w_0$ o $w_1$).\n",
        "\n",
        "El signo de resta es lo que garantiza el \"descenso\": estamos moviéndonos en contra de la dirección de la pendiente.\n",
        "\n",
        "Los detalles de cómo se calcula el gradiente y cómo se elige la tasa de aprendizaje son cruciales y se explican a continuación."
      ],
      "metadata": {
        "id": "t93VaGLxlGQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. Las Piezas Clave del Algoritmo\n",
        "\n",
        "El Descenso del Gradiente es simple, pero su eficacia reside en la correcta aplicación de dos componentes esenciales: el **Gradiente** (la dirección de la pendiente) y la **Tasa de Aprendizaje** (el tamaño del paso).\n",
        "\n",
        "### A. El Gradiente: La Dirección de Máximo Descenso\n",
        "\n",
        "Necesitamos calcular la pendiente de la función de costes $J(w_0, w_1)$ en nuestra posición actual. Esto se logra calculando las **derivadas parciales** de $J$ con respecto a cada parámetro ($w_0$ y $w_1$).\n",
        "\n",
        "El resultado de estas derivadas nos dice cuánto cambiaría el coste $J$ si modificáramos ligeramente un parámetro, manteniendo el otro fijo.\n",
        "\n",
        "### El Gradiente\n",
        "\n",
        "El gradiente es un vector que apunta en la dirección de máximo crecimiento. Como estamos buscando el mínimo coste, nos moveremos en la dirección opuesta (introduciremos un signo menos en la actualización).\n",
        "\n",
        "Derivando $J(w_0, w_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$ con respecto a cada parámetro, obtenemos inicialmente un término negativo: $-\\frac{1}{m}\\sum(y_i - \\hat{y}_i)$.\n",
        "\n",
        "Para simplificar la notación y eliminar el signo negativo, **reordenamos algebraicamente** la resta:\n",
        "$$-(y_i - \\hat{y}_i) = (\\hat{y}_i - y_i)$$\n",
        "\n",
        "Esto nos da las siguientes fórmulas del gradiente:\n",
        "\n",
        "1.  **Gradiente con respecto a $w_0$ (el sesgo):**\n",
        "    $$\\frac{\\partial J}{\\partial w_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)$$\n",
        "    *Esta derivada es simplemente la media de todos los errores de predicción.*\n",
        "\n",
        "2.  **Gradiente con respecto a $w_1$ (el peso/pendiente):**\n",
        "    $$\\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i) \\cdot x_i$$\n",
        "    *Esta derivada incluye la característica $x_i$, lo que da más peso a los puntos con valores grandes de $x$ en el ajuste de la pendiente.*\n",
        "\n",
        "---\n",
        "\n",
        "### B. La Tasa de Aprendizaje ($\\alpha$): El Tamaño del Paso\n",
        "\n",
        "La **tasa de aprendizaje** ($\\alpha$) es un **hiperparámetro** fundamental que controla la magnitud de los pasos que damos en la dirección del gradiente.\n",
        "\n",
        "#### La Regla de Actualización\n",
        "\n",
        "Con la dirección del gradiente y el tamaño del paso $\\alpha$, definimos la regla de actualización. Esta se aplica repetidamente durante un número predefinido de iteraciones (**épocas**):\n",
        "\n",
        "Repetir (Iteraciones/Épocas) {\n",
        "\n",
        "$$w_0 := w_0 - \\alpha \\frac{\\partial J}{\\partial w_0}$$\n",
        "$$w_1 := w_1 - \\alpha \\frac{\\partial J}{\\partial w_1}$$\n",
        "\n",
        "}\n",
        "\n",
        "#### El Impacto Crítico de $\\alpha$\n",
        "\n",
        "Elegir la $\\alpha$ correcta es un acto de equilibrio:\n",
        "\n",
        "| Si $\\alpha$ es... | Consecuencia... |\n",
        "| :--- | :--- |\n",
        "| **Demasiado Pequeña** | Convergencia **extremadamente lenta**. Se necesitan miles de épocas. |\n",
        "| **Correcta** | Convergencia eficiente, acercándose al mínimo en un número razonable de pasos. |\n",
        "| **Demasiado Grande** | **Divergencia** u **oscilación**. El modelo salta de un lado a otro, o se aleja del mínimo, haciendo que el coste $J$ aumente. |\n",
        "\n",
        "El impacto de $\\alpha$ es particularmente sensible cuando las características de entrada tienen rangos de valores muy diferentes. De hecho, esta sensibilidad extrema es la razón principal por la que la **normalización de características** es un paso obligatorio en la práctica, ya que permite usar un $\\alpha$ más grande sin riesgo de divergencia.\n",
        "\n",
        "---\n",
        "\n",
        "### C. Nota sobre el Cálculo Simultáneo\n",
        "\n",
        "Es vital entender que, dentro de cada paso (cada época), las actualizaciones de $w_0$ y $w_1$ deben realizarse **simultáneamente**.\n",
        "\n",
        "Esto significa que primero se deben calcular *ambas* derivadas (gradientes) utilizando los valores de $w_0$ y $w_1$ de la *iteración anterior*. Una vez que se tienen los dos gradientes, se actualizan ambos parámetros a sus nuevos valores. Si se actualizara $w_0$ y luego se usara el *nuevo* $w_0$ para calcular la derivada de $w_1$, se introduciría un sesgo en el algoritmo que podría llevar a resultados incorrectos."
      ],
      "metadata": {
        "id": "z9fpRWAwmrz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Manos a la Obra: Implementación \"Manual\" con Python y NumPy\n",
        "\n",
        "Pasamos de la teoría a la práctica programando el algoritmo de **Regresión Lineal con Descenso de Gradiente (Gradient Descent)** desde cero. Usaremos las librerías NumPy para las operaciones matriciales eficientes y Matplotlib para la visualización.\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.1. Importación y Preparación de Datos\n",
        "\n",
        "Comenzamos importando las librerías necesarias y creando un conjunto de datos de ejemplo. Utilizaremos una relación lineal simple a la que añadiremos un poco de \"ruido\" aleatorio para simular datos reales."
      ],
      "metadata": {
        "id": "mazwxGYYpSmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear datos de ejemplo\n",
        "np.random.seed(42) # Fijar semilla para reproducibilidad\n",
        "\n",
        "# Variable independiente X (característica)\n",
        "X = 2 * np.random.rand(100, 1) # 100 valores entre 0 y 2\n",
        "\n",
        "# Variable dependiente y (objetivo)\n",
        "# Relación real: y = 4 + 3 * X + ruido\n",
        "y = 4 + 3 * X + np.random.randn(100, 1) * 1.5 # El ruido es esencial\n",
        "y = y.ravel()  # Aplanamos 'y' a un vector 1D de forma (100,)\n",
        "\n",
        "print(\"Dimensiones de los datos\")\n",
        "print(f\"Forma de X: {X.shape}, y: {y.shape}\\n\")\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, alpha=0.7, label='Datos reales')\n",
        "plt.xlabel('Tamaño (normalizado)')\n",
        "plt.ylabel('Precio')\n",
        "plt.title('Datos de Entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tg47hHkfp0ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.2. Escalamiento de Características (Estandarización)\n",
        "\n",
        "**Importante:** Antes de iniciar el Descenso de Gradiente, es **crucial** realizar el **Escalado de Características** (*Feature Scaling*).\n",
        "\n",
        "#### ¿Por qué es crucial el Escalado?\n",
        "\n",
        "El Descenso de Gradiente funciona mejor cuando las características de entrada (las columnas de $X$) están en una escala similar. Si una característica tiene valores mucho mayores que otra, la función de costes ($J(w)$) se vuelve muy asimétrica (una \"elipse\" alargada).\n",
        "\n",
        "  * **Función de Costes Asimétrica:** Esto hace que las derivadas (el gradiente) sean desproporcionadamente grandes en la dirección de la característica con mayor escala.\n",
        "  * **Convergencia Lenta o Divergencia:** El algoritmo tendrá que dar \"pasos\" muy pequeños en ciertas direcciones, haciendo que la convergencia sea **extremadamente lenta** o, en el peor de los casos, **diverja**.\n",
        "\n",
        "La **Estandarización** (o *Z-score normalization*) transforma los datos para que tengan una media ($\\mu$) de 0 y una desviación estándar ($\\sigma$) de 1, haciendo que el valle de costes sea más simétrico y permitiendo una convergencia más rápida y estable.\n",
        "\n",
        "$$X_{\\text{estandarizado}} = X' = \\frac{X - \\mu}{\\sigma}$$\n",
        "\n",
        "#### El Problema: Pesos en el Espacio Estandarizado\n",
        "- Al estandarizar $X \\to X' = \\frac{X - \\mu}{\\sigma}$, el modelo ajusta:\n",
        "  $$\n",
        "  \\hat{y} = w_0' + w_1' \\cdot X'\n",
        "  $$\n",
        "- Pero **$w_0'$ y $w_1'$ están en el espacio estandarizado**, no en el original.\n",
        "\n",
        "#### Solución (obligatoria): Desnormalización de los Pesos\n",
        "Posteriormente debemos **transformar los pesos al espacio original**:\n",
        "\n",
        "$$\n",
        "w_1 = \\frac{w_1'}{\\sigma}, \\quad w_0 = w_0' - w_1' \\cdot \\frac{\\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "O, sustituyendo la primera en la segunda:\n",
        "\n",
        "$$w_0 = w_0' - w_1 \\cdot \\mu$$\n",
        "\n",
        "### Código para la estandarización\n",
        "Estandarizamos $X$ y luego crearemos la matriz aumentada `X_b` añadiendo una columna de unos para el término de sesgo $w_0$."
      ],
      "metadata": {
        "id": "HXuHd1w3rUik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular media y desviación estándar\n",
        "mu = X.mean()\n",
        "sigma = X.std()\n",
        "\n",
        "print(f\"Media (μ): {mu:.4f}\")\n",
        "print(f\"Desviación estándar (σ): {sigma:.4f}\")\n",
        "print()\n",
        "\n",
        "# Estandarizar: X' = (X - μ) / σ\n",
        "X_scaled = (X - mu) / sigma\n",
        "\n",
        "# Añadir columna de 1s para w0 (el sesgo)\n",
        "# np.c_ concatena arrays por columnas\n",
        "X_b = np.c_[np.ones((100, 1)), X_scaled]\n",
        "\n",
        "# Mostramos las 5 primeras filas de la matriz\n",
        "X_b[:5] # Columna 0: bias (1s), Columna 1: X escalado"
      ],
      "metadata": {
        "id": "r0GEhKRna9XY",
        "outputId": "c581bbfc-c268-47f6-8867-3cb3a7f613a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media (μ): 0.9404\n",
            "Desviación estándar (σ): 0.5920\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.32311215],\n",
              "       [ 1.        ,  1.62343393],\n",
              "       [ 1.        ,  0.88450935],\n",
              "       [ 1.        ,  0.43404902],\n",
              "       [ 1.        , -1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> El bias (`w0`) no se escala porque representa el valor predicho cuando todas las características son cero; añadir una columna de unos después del escalado mantiene su interpretación original."
      ],
      "metadata": {
        "id": "ZL1KrfzAVNG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.3. Implementación del Descenso de Gradiente\n",
        "\n",
        "Ahora implementamos el núcleo del algoritmo, siguiendo la fórmula del Descenso de Gradiente.\n",
        "\n",
        "**Fórmulas Clave (Vectorial):**\n",
        "\n",
        "1.  **Predicción:** $\\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w}$\n",
        "2.  **Función de Coste (MSE/2):** $J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2$\n",
        "3.  **Regla de Actualización:** $\\mathbf{w} := \\mathbf{w} - \\alpha \\cdot \\frac{1}{m} \\cdot \\mathbf{X}^{\\text{T}} \\cdot (\\hat{\\mathbf{y}} - \\mathbf{y})$"
      ],
      "metadata": {
        "id": "vLjlunD2sJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "learning_rate = 0.01    # alpha (tasa de aprendizaje)\n",
        "epochs = 1000           # número de iteraciones\n",
        "m = len(X)              # número de ejemplos de entrenamiento\n",
        "tol = 1e-5              # criterio de parada (early stopping)\n",
        "prev_cost = np.inf      # coste anterior (inicial infinito)\n",
        "\n",
        "# Inicialización\n",
        "w = np.zeros(2)         # w[0] = w0 (bias), w[1] = w1 (pendiente)\n",
        "cost_history = []\n",
        "w0_history = []\n",
        "w1_history = []\n",
        "\n",
        "# Bucle de entrenamiento (las epochs)\n",
        "for epoch in range(epochs):\n",
        "    # Predicciones: ŷ = X_b @ w  (X_b tiene columna de 1s)\n",
        "    y_pred = X_b @ w        # shape: (m,) porque w es 1D\n",
        "\n",
        "    # Error\n",
        "    errors = y_pred - y     # El error es (ŷ - y). shape: (m, 1)\n",
        "\n",
        "    # Gradiente: (1/m) * X_transpuesta * Errores\n",
        "    gradients = (1/m) * X_b.T @ errors      # shape: (2,)\n",
        "\n",
        "    # Actualización simultánea de parámetros: w := w - alpha * gradiente\n",
        "    w = w - learning_rate * gradients\n",
        "\n",
        "    # Coste de cada paso (MSE/2)\n",
        "    cost = (1/(2*m)) * np.sum(errors**2)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    # Guardar parámetros\n",
        "    w0_history.append(w[0])\n",
        "    w1_history.append(w[1])\n",
        "\n",
        "    # Early stopping\n",
        "    # si la mejora en el coste es menor a la tolerancia, se detiene el entrenamiento\n",
        "    if prev_cost - cost < tol:\n",
        "        print(f\"Convergencia alcanzada en la época {epoch}\")\n",
        "        break\n",
        "    prev_cost = cost\n",
        "\n",
        "# Pesos óptimos (en espacio estandarizado)\n",
        "w_optimal = w.copy()  # buena práctica: no modificar w después del bucle\n",
        "\n",
        "# --- REVERTIR LA ESTANDARIZACIÓN (Desnormalización) ---\n",
        "# Parámetros estandarizados\n",
        "w0_prime = w_optimal[0]   # intercepto en espacio escalado\n",
        "w1_prime = w_optimal[1]   # pendiente en espacio escalado\n",
        "\n",
        "# 1. Pendiente Original: w1 = w1' / sigma\n",
        "w1_original = w1_prime / sigma\n",
        "\n",
        "# 2. Intercepto Original: w0 = w0' - w1_original * mu\n",
        "w0_original = w0_prime - w1_original * mu\n",
        "\n",
        "print(f\"w0' (estandarizado): {w0_prime:.6f}\")\n",
        "print(f\"w1' (estandarizado): {w1_prime:.6f}\")\n",
        "print(\"\\n--- Parámetros Óptimos en el espacio de datos ORIGINAL ---\")\n",
        "# La relación real es y = 4 + 3 * X + ruido\n",
        "print(f\"w0 (Intercepto original): {w0_original:.4f} (~4.0)\")\n",
        "print(f\"w1 (Pendiente original): {w1_original:.4f} (~3.0)\")"
      ],
      "metadata": {
        "id": "UBQLoV7pVmAO",
        "outputId": "d725ab18-9159-4035-ecc4-47b563ef63ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en la época 539\n",
            "w0' (estandarizado): 6.789489\n",
            "w1' (estandarizado): 1.564942\n",
            "\n",
            "--- Parámetros Óptimos en el espacio de datos ORIGINAL ---\n",
            "w0 (Intercepto original): 4.3036 (~4.0)\n",
            "w1 (Pendiente original): 2.6435 (~3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.4. Interpretación Correcta: Revertir la Estandarización\n",
        "\n",
        "Los parámetros $w_0'$ y $w_1'$ que ha encontrado nuestro algoritmo son óptimos, pero solo son válidos para la versión **estandarizada** de la característica $X$. Si los comparáramos directamente con la relación real de nuestros datos ($y = 4 + 3x$), veríamos una gran diferencia ($w_1' \\approx 1.5$ en lugar de $3$), lo que erróneamente sugeriría que el modelo ha fallado.\n",
        "\n",
        "Esto no es un error, sino una consecuencia necesaria del escalado para lograr una convergencia eficiente. Para **interpretar** correctamente los resultados, debemos transformar los pesos de vuelta al espacio de datos original.\n",
        "\n",
        "La transformación utiliza la media ($\\mu$) y la desviación estándar ($\\sigma$) que calculamos previamente:\n",
        "\n",
        "$$w_1 = \\frac{w_1'}{\\sigma}$$\n",
        "\n",
        "$$w_0 = w_0' - w1 \\cdot \\mu$$\n",
        "\n",
        "Al aplicar esta transformación, vemos que el modelo ha convergido a los valores correctos de $w_0$ y $w_1$, verificando que el Descenso del Gradiente funcionó con éxito para descubrir la relación subyacente de nuestros datos.\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.5. Visualización de Resultados\n",
        "\n",
        "Para finalizar, ploteamos el historial de costes para confirmar que el algoritmo converge correctamente y visualizamos la línea de regresión final sobre los datos originales.\n",
        "\n",
        "#### 5.5.1. Gráfico del Historial de Costes\n",
        "\n",
        "El coste debe disminuir drásticamente al inicio y luego aplanarse, indicando la convergencia."
      ],
      "metadata": {
        "id": "I8HHRmSAsqbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(cost_history, 'b.-', markersize=4)\n",
        "plt.title('Historial de Costes (con Early Stopping)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Función de Coste J(w)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- MENSAJE DE EARLY STOPPING ---\n",
        "if len(cost_history) < epochs:\n",
        "    print(f\"\\nEarly stopping activado: no fueron necesarias las {epochs} épocas. \")\n",
        "    print(f\"Convergencia alcanzada en {len(cost_history)} épocas.\")\n",
        "else:\n",
        "    print(f\"\\nSe completaron las {epochs} épocas sin activar early stopping.\")"
      ],
      "metadata": {
        "id": "1NtshbJksvFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.5.2. Gráfico de la Regresión Lineal\n",
        "\n",
        "Para plotear la línea de regresión, debemos usar los valores originales de $X$ (sin estandarizar) y aplicarles la misma estandarización antes de multiplicarlos por los $w$ óptimos."
      ],
      "metadata": {
        "id": "y3nS1iIMszfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un rango de X para dibujar la línea\n",
        "X_plot = np.array([[0], [2]])\n",
        "\n",
        "# 1. Estandarizar X_plot de la misma forma que los datos de entrenamiento\n",
        "X_plot_scaled = (X_plot - mu) / sigma\n",
        "\n",
        "# 2. Añadir el sesgo (columna de unos)\n",
        "X_plot_b = np.c_[np.ones((2, 1)), X_plot_scaled]\n",
        "\n",
        "# 3. Calcular las predicciones con los pesos (w) óptimos\n",
        "# Usamos w_optimal que son los pesos estandarizados\n",
        "y_predict = X_plot_b @ w_optimal\n",
        "\n",
        "# Plotear los datos originales y la línea de regresión\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X, y, 'o', label='Datos originales')\n",
        "plt.plot(X_plot, y_predict, 'r-', label='Recta de Regresión')\n",
        "plt.title('Regresión Lineal con Descenso de Gradiente')\n",
        "plt.xlabel('X (Característica Original)')\n",
        "plt.ylabel('y (Objetivo)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ru5H5FOZs3Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta forma, hemos implementado el Descenso de Gradiente de forma manual, mostrando cómo el algoritmo itera para encontrar los parámetros $w_0$ y $w_1$ que minimizan la función de costes y definen la línea de mejor ajuste."
      ],
      "metadata": {
        "id": "7dG6VElxpQo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. La Vía Rápida: Implementación con Scikit-Learn\n",
        "\n",
        "Tras haber programado la **Regresión Lineal con Descenso de Gradiente** manualmente, el objetivo de esta sección es mostrar cómo se realiza esta tarea en un **entorno profesional** utilizando la librería estándar de *machine learning* en Python: **Scikit-Learn (sklearn)**.\n",
        "\n",
        "El modelo que utilizaremos es `sklearn.linear_model.SGDRegressor`.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.1. ¿Por qué `SGDRegressor`?\n",
        "\n",
        "Mientras que en el apartado anterior implementamos el **Descenso de Gradiente por Lotes (*Batch Gradient Descent*)**, Scikit-Learn ofrece una variante mucho más común y eficiente para datos grandes: el **Descenso de Gradiente Estocástico (*Stochastic Gradient Descent - SGD*)**.\n",
        "\n",
        "#### Concepto Clave: SGD\n",
        "\n",
        "El SGD es una variante del Descenso de Gradiente donde, en lugar de calcular el gradiente usando **todos** los ejemplos de entrenamiento (*batch* completo) en cada paso, el algoritmo:\n",
        "\n",
        "1.  Calcula el gradiente usando **un solo ejemplo** de entrenamiento seleccionado al azar (o un pequeño subconjunto llamado *mini-batch*).\n",
        "2.  Actualiza los parámetros $w$ inmediatamente.\n",
        "\n",
        "Esta aproximación hace que el proceso sea **mucho más rápido** en *datasets* con millones de datos, aunque el camino hacia el mínimo de la función de costes es más ruidoso y aleatorio. Para la regresión lineal, el `SGDRegressor` es la herramienta estándar cuando se desea aplicar el Descenso de Gradiente.\n",
        "\n",
        "### Variantes del Descenso del Gradiente\n",
        "\n",
        "Existen diversas variantes del Descenso del Gradiente, adaptadas a diferentes tamaños de datos y necesidades computacionales:\n",
        "\n",
        "**1. Batch Gradient Descent (por lotes)**\n",
        "- Como el que implementamos manualmente.\n",
        "- Calcula el gradiente usando **todo el conjunto de datos** en cada iteración.\n",
        "- **Ventaja:** Dirección precisa hacia el mínimo.\n",
        "- **Desventaja:** Lento y requiere mucha memoria para datasets grandes.\n",
        "\n",
        "**2. Stochastic Gradient Descent (SGD)**\n",
        "- Actualiza los parámetros con **un solo ejemplo aleatorio** por iteración.\n",
        "- **Ventaja:** Mucho más rápido.\n",
        "- **Desventaja:** Trayectoria más \"ruidosa\" y zigzagueante hacia el mínimo.\n",
        "\n",
        "**3. Mini-Batch Gradient Descent**\n",
        "- Equilibra ambos enfoques al usar **pequeños subconjuntos (mini-batches)** de datos.\n",
        "- **Ventaja:** Combina velocidad y estabilidad.\n",
        "- **Nota:** Esta es la variante más común en *deep learning* y se puede configurar en `SGDRegressor` con el parámetro `batch_size`.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.2. Implementación con Scikit-Learn\n",
        "\n",
        "A diferencia de la implementación manual, Scikit-Learn requiere que el escalado de características y el modelo se manejen como objetos separados.\n",
        "\n",
        "#### 6.2.1. Preparación y Escalado de Datos\n",
        "\n",
        "**Nota Importante:** Usaremos los datos originales $X$ e $y$ del apartado 5 para el proceso de escalado."
      ],
      "metadata": {
        "id": "mPBbTXkl0u8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Datos originales (asumimos que X e y son los del apartado 5)\n",
        "# X (100, 1), y (100, 1)\n",
        "\n",
        "# 1. Ajustar la forma de 'y' si es necesario (Scikit-Learn prefiere (n_samples,))\n",
        "y_flat = y.ravel()\n",
        "\n",
        "# 2. Crear y ajustar el StandardScaler\n",
        "# El escalador calculará la media y la desviación estándar de X y la almacenará\n",
        "scaler = StandardScaler()\n",
        "X_scaled_skl = scaler.fit_transform(X)\n",
        "X_scaled_skl[:5]"
      ],
      "metadata": {
        "id": "SY3bfQ0s0zyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c11ff95-d591-4f61-ea28-bfef32aa5f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.32311215],\n",
              "       [ 1.62343393],\n",
              "       [ 0.88450935],\n",
              "       [ 0.43404902],\n",
              "       [-1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.2. Entrenamiento del Modelo `SGDRegressor`\n",
        "\n",
        "Instanciamos y entrenamos el modelo. Es crucial especificar los hiperparámetros que controlan el proceso de optimización:\n",
        "\n",
        "* `loss='squared_error'`: Indica que queremos minimizar el Error Cuadrático Medio (MSE), la función de costes adecuada para la regresión lineal.\n",
        "* `eta0`: La tasa de aprendizaje inicial ($\\alpha$), que determina el tamaño de los pasos.\n",
        "* `max_iter`: El número de épocas o pasadas completas a través del conjunto de datos.\n",
        "* `learning_rate='constant'` (por defecto): Mantiene `eta0` constante durante todo el entrenamiento. Otras opciones incluyen `'optimal'`, `'invscaling'` y `'adaptive'`.\n",
        "\n",
        "Una vez finalizado el entrenamiento, desnormalizamos los pesos encontrados (`coef_` e `intercept_`) usando la media y desviación estándar almacenadas previamente en el objeto `scaler`."
      ],
      "metadata": {
        "id": "iPsk-iPn09Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Crear una instancia de SGDRegressor\n",
        "sgd_reg = SGDRegressor(\n",
        "    loss='squared_error',\n",
        "    eta0=0.01,         # Learning rate (alpha)\n",
        "    max_iter=1000,     # Número de épocas\n",
        "    tol=1e-5,          # Criterio de parada\n",
        "    random_state=42    # Para obtener resultados reproducibles\n",
        ")\n",
        "\n",
        "# 4. Entrenar el modelo con los datos escalados\n",
        "sgd_reg.fit(X_scaled_skl, y_flat)\n",
        "\n",
        "# 5. Mostrar los parámetros encontrados\n",
        "\n",
        "# Pesos estandarizados (w')\n",
        "w_0_prime_skl = sgd_reg.intercept_[0]\n",
        "w_1_prime_skl = sgd_reg.coef_[0]\n",
        "\n",
        "# --- REVERTIR LA ESTANDARIZACIÓN (Desnormalización) ---\n",
        "# Usamos las propiedades almacenadas por el scaler: .mean_ y .scale_\n",
        "mu_skl = scaler.mean_[0]\n",
        "sigma_skl = scaler.scale_[0]\n",
        "\n",
        "# 1. Pendiente Original: w1 = w1' / sigma\n",
        "w1_original_skl = w_1_prime_skl / sigma_skl\n",
        "\n",
        "# 2. Intercepto Original: w0 = w0' - w1_original * mu\n",
        "w0_original_skl = w_0_prime_skl - w1_original_skl * mu_skl\n",
        "\n",
        "\n",
        "print(\"\\n--- Parámetros Óptimos encontrados por SGDRegressor (ESTANDARIZADOS) ---\")\n",
        "print(f\"w0' (Intercepto estandarizado): {w_0_prime_skl:.4f}\")\n",
        "print(f\"w1' (Pendiente estandarizada): {w_1_prime_skl:.4f}\")\n",
        "print(\"\\n--- Parámetros Óptimos en el espacio de datos ORIGINAL ---\")\n",
        "# La relación real era y = 4 + 3 * X + ruido\n",
        "print(f\"w0 (Intercepto original): {w0_original_skl:.4f} (~4.0)\")\n",
        "print(f\"w1 (Pendiente original): {w1_original_skl:.4f} (~3.0)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-wdihhqfUfJ",
        "outputId": "3e0b44ac-b8b5-4025-fe19-ad7621479e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Parámetros Óptimos encontrados por SGDRegressor (ESTANDARIZADOS) ---\n",
            "w0' (Intercepto estandarizado): 6.8214\n",
            "w1' (Pendiente estandarizada): 1.5721\n",
            "\n",
            "--- Parámetros Óptimos en el espacio de datos ORIGINAL ---\n",
            "w0 (Intercepto original): 4.3242 (~4.0)\n",
            "w1 (Pendiente original): 2.6555 (~3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 6.3. Comparación de Resultados\n",
        "\n",
        "Comparamos los resultados de la implementación manual (Descenso de Gradiente por Lotes) y la implementación profesional de Scikit-Learn (Descenso de Gradiente Estocástico) **después de revertir la estandarización**.\n",
        "\n",
        "| Parámetro (Original) | Manual (Batch GD) | Scikit-Learn (SGDRegressor) | Realidad Subyacente ($y=4+3x$) |\n",
        "| :---: | :---: | :---: | :---: |\n",
        "| $w_0$ (Intercepto) | $4.30 $ | $4.32 $ | **$4$** |\n",
        "| $w_1$ (Pendiente) | $2.64$ | $2.66 $ | **$3$** |\n",
        "\n",
        "Los resultados son prácticamente **iguales** y ambos se aproximan con éxito a los parámetros reales de $4$ y $3$ de nuestros datos generados.  \n",
        "\n",
        "Las pequeñas **discrepancias entre las estimaciones y los valores reales** (4 y 3) se deben al ruido aleatorio que introdujimos al generar el conjunto de datos. Esto demuestra que la Regresión Lineal ha encontrado la línea de mejor ajuste para los datos observados.\n",
        "\n",
        "> **Experimento:** Puedes ver otros valores ligeramente diferentes variando la semilla de los números aleatorios (por ejemplo, usando `random_state=44` en lugar de `42`).\n",
        "\n",
        "Esto permite verificar dos puntos fundamentales:\n",
        "\n",
        "1.  **Validación de la teoría:** Nuestra implementación manual funcionó correctamente.\n",
        "2.  **Eficiencia de la herramienta:** El `SGDRegressor` nos permite obtener los mismos resultados óptimos con una fracción del código, beneficiándonos de la optimización y robustez de una librería profesional.\n",
        "\n",
        "> **Nota:** Scikit-Learn también ofrece `LinearRegression`, que permite calcular los parámetros por el **método de Mínimos Cuadrados Ordinarios (OLS)** mediante una solución analítica directa, en lugar del Descenso del Gradiente iterativo. Este método es más rápido para datasets pequeños o medianos (hasta decenas de miles de filas), pero no escala bien a millones de datos debido a la complejidad computacional de la inversión de matrices. Para aprendizaje online o datasets muy grandes, `SGDRegressor` es la opción preferida.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "w0HPZ77StqgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Generalizando: De la Recta al Hiperplano (Regresión Múltiple)\n",
        "\n",
        "Hasta ahora, hemos utilizado la Regresión Lineal Simple (una sola variable $x$) como herramienta didáctica. Sin embargo, en el mundo real, los problemas tienen múltiples factores o **características** ($x_1, x_2, \\dots, x_n$).\n",
        "\n",
        "### La Ecuación se Convierte en un Hiperplano\n",
        "\n",
        "Cuando añadimos más características, la ecuación del modelo se extiende:\n",
        "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
        "\n",
        "  * Si tuviéramos solo dos características ($x_1$ y $x_2$), la línea de mejor ajuste se convertiría en un **plano** en un espacio tridimensional.\n",
        "  * Con tres o más características, esta superficie se denomina **hiperplano** (un plano en un espacio de $n$ dimensiones).\n",
        "\n",
        "### La Ventaja de la Notación Matricial\n",
        "\n",
        "La gran ventaja de haber utilizado la **notación matricial** desde el principio es que la complejidad del Descenso del Gradiente **no aumenta** al añadir variables.\n",
        "\n",
        "Nuestras fórmulas clave de optimización (para la predicción y el gradiente) son exactamente las mismas:\n",
        "\n",
        "| Concepto | Fórmula Matricial (General) |\n",
        "| :--- | :--- |\n",
        "| **Predicción** | $\\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w}$ |\n",
        "| **Cálculo del Gradiente** | $\\mathbf{g} = \\frac{1}{m} \\mathbf{X}^{\\text{T}} (\\hat{\\mathbf{y}} - \\mathbf{y})$ |\n",
        "\n",
        "El código de entrenamiento solo necesita que la matriz $\\mathbf{X}$ tenga más columnas y el vector de pesos $\\mathbf{w}$ tenga más filas. El proceso de cálculo se mantiene idéntico.\n",
        "\n",
        "-----\n",
        "\n",
        "### 7.1. Caso con Dos Variables Independientes ($x_1, x_2$)\n",
        "\n",
        "Utilizamos `SGDRegressor` para encontrar los tres parámetros ($w_0, w_1, w_2$) de un modelo basado en la relación real:\n",
        "\n",
        "$$y = 4 + 3x_1 + 5x_2 + \\text{ruido}$$\n",
        "\n",
        "#### Desnormalización con múltiples variables\n",
        "\n",
        "Para múltiples características, las fórmulas de desnormalización se extienden:\n",
        "\n",
        "$$w_j = \\frac{w_j'}{\\sigma_j} \\quad \\text{para } j = 1, 2, \\ldots, n$$\n",
        "\n",
        "$$w_0 = w_0' - \\sum_{j=1}^{n} w_j \\cdot \\mu_j = w_0' - (w_1 \\cdot \\mu_1 + w_2 \\cdot \\mu_2 + \\cdots)$$\n",
        "\n",
        "Donde:\n",
        "- $w_j'$ son los pesos estandarizados\n",
        "- $\\mu_j$ y $\\sigma_j$ son la media y desviación estándar de la característica $j$"
      ],
      "metadata": {
        "id": "TZJeizRld3eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Generación de Datos con dos variables\n",
        "W_REAL = np.array([4, 3, 5])    # [w0, w1, w2] - Parámetros reales del modelo\n",
        "np.random.seed(42)\n",
        "\n",
        "# Ambos con el mismo rango para mejor visualización posterior\n",
        "X1 = 2 * np.random.rand(1000, 1)  # X1: rango [0, 2]\n",
        "X2 = 2 * np.random.rand(1000, 1)  # X2: rango [0, 2]\n",
        "X_multi = np.hstack([X1, X2])\n",
        "\n",
        "# Misma relación real: y = 4 + 3*X1 + 5*X2 + ruido\n",
        "y_multi = W_REAL[0] + W_REAL[1] * X1 + W_REAL[2] * X2 + np.random.randn(1000, 1) * 2\n",
        "y_flat = y_multi.ravel()\n",
        "\n",
        "# 2. Escalado. Estas dos variables tienen la misma escala pero\n",
        "# sigue siendo necesario por si usamos más variables después\n",
        "scaler = StandardScaler()\n",
        "X_scaled_multi = scaler.fit_transform(X_multi)\n",
        "\n",
        "# 3. Entrenamiento con SGD\n",
        "sgd_reg = SGDRegressor(\n",
        "    loss='squared_error',\n",
        "    eta0=0.01,\n",
        "    max_iter=1000,\n",
        "    tol=1e-5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "sgd_reg.fit(X_scaled_multi, y_flat)\n",
        "\n",
        "# 4. Desnormalización (Para obtener w0, w1, w2 originales)\n",
        "w_0_prime = sgd_reg.intercept_[0]\n",
        "w_1_prime, w_2_prime = sgd_reg.coef_\n",
        "\n",
        "mu, sigma = scaler.mean_, scaler.scale_\n",
        "\n",
        "w1_original = w_1_prime / sigma[0]\n",
        "w2_original = w_2_prime / sigma[1]\n",
        "w0_original = w_0_prime - (w1_original * mu[0]) - (w2_original * mu[1])\n",
        "\n",
        "print(\"\\n--- Resultados con Regresión Múltiple (2 Variables) ---\")\n",
        "print(f\"w0 (Intercepto): {w0_original:.3f} (Real: {W_REAL[0]})\")\n",
        "print(f\"w1 (Peso X1): {w1_original:.3f} (Real: {W_REAL[1]})\")\n",
        "print(f\"w2 (Peso X2): {w2_original:.3f} (Real: {W_REAL[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guzm2buuhoKi",
        "outputId": "5277ec8a-36c0-4ebd-b10a-7f145128a24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados con Regresión Múltiple (2 Variables) ---\n",
            "w0 (Intercepto): 4.039 (Real: 4)\n",
            "w1 (Peso X1): 2.967 (Real: 3)\n",
            "w2 (Peso X2): 5.014 (Real: 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de los resultados:**\n",
        "- El modelo ha encontrado parámetros muy cercanos a los valores reales ($w_0=4$, $w_1=3$, $w_2=5$)\n",
        "- Las pequeñas diferencias se deben al ruido aleatorio añadido a los datos\n",
        "- Esto verifica que el Descenso del Gradiente es una herramienta escalable que funciona igualmente bien para encontrar los parámetros óptimos de un hiperplano, resolviendo problemas de *Regresión Múltiple*."
      ],
      "metadata": {
        "id": "xodsGkB8hw_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 7.2. Visualización: El Plano de Regresión (3D)\n",
        "\n",
        "Visualizamos el plano de regresión en un espacio tridimensional para apreciar cómo el modelo se ajusta a los datos. Se muestra que el algoritmo ha encontrado el plano óptimo que minimiza el error cuadrático medio en el espacio 3D."
      ],
      "metadata": {
        "id": "0A3IeYwDk_gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualización 3D ---\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "\n",
        "# 1. Crear malla para superficie del plano (40x40 = 1600 puntos)\n",
        "x1_surf = np.linspace(X1.min(), X1.max(), 40)\n",
        "x2_surf = np.linspace(X2.min(), X2.max(), 40)\n",
        "x1_surf, x2_surf = np.meshgrid(x1_surf, x2_surf)\n",
        "\n",
        "# Plano con parámetros originales\n",
        "Z = w0_original + w1_original * x1_surf + w2_original * x2_surf\n",
        "\n",
        "# 2. Figura grande\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# --- Puntos: grandes y con borde blanco para resaltar ---\n",
        "ax.scatter(X1, X2, y_multi,\n",
        "           c='navy', marker='o', s=40, alpha=0.8,\n",
        "           edgecolors='white', linewidth=0.5, depthshade=True)\n",
        "\n",
        "# --- Plano: color suave, opaco y con bordes ---\n",
        "ax.plot_surface(x1_surf, x2_surf, Z,\n",
        "                color='crimson', alpha=0.50,\n",
        "                linewidth=0.5, edgecolor='darkred', antialiased=True)\n",
        "\n",
        "# Etiquetas con salto de línea para evitar solapamiento\n",
        "ax.set_xlabel('\\n$X_1$ (Caract. 1)', fontsize=13, linespacing=1.5)\n",
        "ax.set_ylabel('\\n$X_2$ (Caract. 2)', fontsize=13, linespacing=1.5)\n",
        "ax.set_zlabel('\\nPrecio ($Y$)', fontsize=13, linespacing=1.5)\n",
        "ax.set_title('Regresión Lineal Múltiple: Plano Ajustado\\n', fontsize=16, pad=40)\n",
        "\n",
        "# ÁNGULO de visión: plano visible desde arriba y lateral\n",
        "ax.view_init(elev=32, azim=65)\n",
        "\n",
        "# Grid suave\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_facecolor('white')\n",
        "\n",
        "# --- LEYENDA FUERA DEL GRÁFICO ---\n",
        "point_proxy = Line2D([0], [0], linestyle=\"none\", marker='o',\n",
        "                     color='navy', markerfacecolor='navy',\n",
        "                     markeredgecolor='white', markersize=10)\n",
        "plane_proxy = Line2D([0], [0], linestyle=\"-\", color='crimson', linewidth=6)\n",
        "\n",
        "legend = fig.legend([point_proxy, plane_proxy],\n",
        "                    ['Datos de entrenamiento', 'Plano de Regresión'],\n",
        "                    loc='upper right',\n",
        "                    bbox_to_anchor=(0.88, 0.88),\n",
        "                    frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
        "\n",
        "legend.get_frame().set_facecolor('white')\n",
        "legend.get_frame().set_edgecolor('black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CGGkS8amkjCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Nota sobre la visualización:** El gráfico muestra 1000 puntos de datos (en azul marino) y el plano de regresión encontrado por el algoritmo (en rojo).  \n",
        "La transparencia del plano permite ver los puntos que quedan por encima y por debajo, representando los residuos del modelo."
      ],
      "metadata": {
        "id": "141Kp4JZWFlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusión: ¿Qué Hemos Aprendido?\n",
        "\n",
        "A lo largo de este artículo, hemos desglosado la **Regresión Lineal** desde sus cimientos matemáticos hasta su implementación práctica, comprendiendo que es mucho más que una simple línea de mejor ajuste. Los conceptos que hemos cubierto forman la base de la optimización en casi todo el campo del *Machine Learning*.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumen de Puntos Clave\n",
        "\n",
        "* **Objetivo de la Regresión Lineal:** La meta fundamental de la Regresión Lineal es encontrar los parámetros ($w_0, w_1, \\ldots, w_n$) que definen la recta (o hiperplano) que mejor se ajusta a los datos.\n",
        "* **La Función de Costes (MSE):** Para determinar qué tan \"buena\" es una recta, utilizamos una métrica de error, conocida comúnmente como el **Error Cuadrático Medio (MSE)** o $J(w)$. El verdadero objetivo del modelo es **minimizar** el valor de esta función.\n",
        "* **El Algoritmo de Optimización: Descenso de Gradiente:** El **Descenso de Gradiente (*Gradient Descent*)** es el algoritmo que nos permite alcanzar ese mínimo. Podemos visualizarlo como un proceso iterativo en el que \"caminamos\" por la superficie de la función de costes.\n",
        "    * **El Gradiente es la Brújula:** El gradiente (las derivadas parciales) indica la **dirección de máximo ascenso** en la función de costes. Puesto que queremos *minimizar* el coste, nuestro paso va en la dirección **opuesta** al gradiente.\n",
        "    * **La Tasa de Aprendizaje ($\\alpha$) es el Tamaño del Paso:** La **tasa de aprendizaje** determina la magnitud de cada paso. Si es muy grande, corremos el riesgo de \"saltar\" el mínimo; si es muy pequeña, la convergencia será extremadamente lenta.\n",
        "* **El Escalado es Crucial, la Desnormalización es Obligatoria:** El **Escalado de Características** (Estandarización) es crucial para la **estabilidad y rapidez** del Descenso del Gradiente. Sin embargo, para la **interpretación** correcta de los pesos finales en el contexto de los datos originales, es **obligatorio revertir** la estandarización de los parámetros.\n",
        "* **Implementaciones (Manual vs. Scikit-Learn):** Hemos comprobado que, si bien es posible y educativo programar el algoritmo desde cero con NumPy (Batch Gradient Descent), en un entorno profesional se utiliza `SGDRegressor` de Scikit-Learn (Descenso Estocástico), que ofrece la misma precisión con mayor eficiencia y rapidez en grandes volúmenes de datos.\n",
        "* **Escalabilidad a Múltiples Dimensiones:** El mismo algoritmo de Descenso del Gradiente funciona para regresión múltiple (múltiples características) sin aumentar la complejidad conceptual, gracias al uso de notación matricial.\n",
        "\n",
        "---\n",
        "\n",
        "### La Base de todo el *Machine Learning*\n",
        "\n",
        "El concepto de **Descenso de Gradiente** no se limita a la Regresión Lineal. La idea de definir una función de costes, calcular su gradiente y ajustar parámetros de forma iterativa es el **motor de optimización** de la inmensa mayoría de los modelos de *Machine Learning* modernos, incluyendo:\n",
        "\n",
        "* **Regresión Logística** para clasificación binaria.\n",
        "* **Máquinas de Soporte Vectorial (SVM)**.\n",
        "* **Redes Neuronales Profundas**, donde el Descenso del Gradiente se combina con **Retropropagación (*Backpropagation*)** para entrenar modelos con millones de parámetros.\n",
        "* **Modelos de Lenguaje (LLMs)** como GPT, que utilizan variantes avanzadas del Descenso del Gradiente (Adam, AdamW) para ajustar billones de parámetros.\n",
        "\n",
        "Entender el Descenso de Gradiente es, por lo tanto, entender **cómo aprende una máquina**.\n",
        "\n",
        "---\n",
        "\n",
        "### ¿Y Ahora Qué?\n",
        "\n",
        "Si has llegado hasta aquí, has nevegado por uno de los conceptos más fundamentales del Machine Learning. Estás listo para explorar:\n",
        "\n",
        "* **Regularización (Ridge/Lasso):** Técnicas para evitar el sobreajuste.\n",
        "* **Regresión Logística:** El mismo Descenso del Gradiente aplicado a clasificación.\n",
        "* **Optimizadores Avanzados:** Adam, RMSprop, Momentum y otras variantes que aceleran la convergencia.\n",
        "* **Redes Neuronales:** Donde el Descenso del Gradiente se combina con Backpropagation para entrenar modelos profundos.\n",
        "\n",
        "**El viaje apenas comienza.** Cada modelo que encuentres, por complejo que parezca, probablemente esté usando alguna variante de lo que acabas de aprender."
      ],
      "metadata": {
        "id": "FmUj4QLlui91"
      }
    }
  ]
}