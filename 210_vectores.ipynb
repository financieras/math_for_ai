{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN/K4RkATMwUiVkpYOSMZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/210_vectores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectores\n",
        "\n",
        "## 1. Fundamentos\n",
        "\n",
        "### Concepto de Vector\n",
        "\n",
        "- Un vector es una cantidad matemática que posee tanto magnitud (tamaño) como dirección.\n",
        "- A diferencia de los escalares (que solo tienen magnitud), los vectores son fundamentales para representar cantidades direccionales en matemáticas y sus aplicaciones.\n",
        "- En el contexto de la Inteligencia Artificial, los vectores son estructuras de datos fundamentales que permiten representar características, atributos o propiedades de manera ordenada y matemáticamente manipulable.\n",
        "- A efectos prácticos, podemos ver un vector como una lista ordenada de números.\n",
        "- Podemos hacer operaciones de traslación (suma) y de escala (multiplicación por escalar).\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_1.svg?raw=1\" alt=\"vector en una direccion\" width=\"320\"/>"
      ],
      "metadata": {
        "id": "6jNz3FXWpG4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Componentes de un Vector\n",
        "\n",
        "Un vector se puede representar mediante sus componentes, que son las proyecciones del vector sobre los ejes coordenados:\n",
        "\n",
        "- En 2D: un vector $\\vec{v}$ se representa como un par ordenado $(v_x, v_y)$\n",
        "- En 3D: un vector $\\vec{v}$ se representa como una terna ordenada $(v_x, v_y, v_z)$\n",
        "- En IA: un vector $\\vec{v}$ puede tener $n$ componentes $(v_1, v_2, ..., v_n)$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_11.gif?raw=1\" alt=\"componentes de un vector\" width=\"320\"/>\n",
        "\n",
        "Cada componente representa una magnitud en la dirección de un eje coordenado particular.\n",
        "\n",
        "**Ejemplos:**\n",
        "- Vector en 2D: $\\vec{v} = (4, 5)$ tiene componente $x = 4$ y componente $y = 5$\n",
        "- Vector en 3D: $\\vec{w} = (1, -2, 5)$ tiene componente $x = 1$, componente $y = -2$ y componente $z = 5$\n",
        "- Vector de características: $\\vec{f} = (8, \\,1.5,\\, -2.1,\\, 0.4)$ podría representar diferentes atributos de un dato\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_2.svg?raw=1\" alt=\"modulo direccion sentido\" width=\"320\"/>"
      ],
      "metadata": {
        "id": "9azom0GppS6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Representación Gráfica\n",
        "\n",
        "#### En 2D\n",
        "Los vectores bidimensionales se representan en un plano cartesiano:\n",
        "- El origen del vector se ubica típicamente en $(0,0)$\n",
        "- La flecha indica la dirección y magnitud\n",
        "- Las componentes $(v_x, v_y)$ determinan que el vector comienza en el punto $(0,0)$ y finalizan en el punto $(v_x, v_y)$ del plano.\n",
        "- Ejemplo, si el vector es el $(3, 2)$, este vector se representa mediante una flecha que parte del $(0, 0)$ y termina en el punto $(3, 2)$ del plano cartesiano.\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_3.svg?raw=1\" alt=\"componentes de un vector 2D\" width=\"320\"/>\n",
        "\n",
        "#### En 3D\n",
        "Los vectores tridimensionales se representan en un espacio cartesiano:\n",
        "- El origen suele ubicarse en $(0,0,0)$\n",
        "- Las componentes $(v_x, v_y, v_z)$ determinan el punto final\n",
        "- La visualización requiere perspectiva para mostrar la profundidad\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_4.webp?raw=1\" alt=\"punto en el espacio\" width=\"320\"/>"
      ],
      "metadata": {
        "id": "xuG8hfy_pjS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicaciones en IA\n",
        "\n",
        "Los vectores son fundamentales en IA por varias razones:\n",
        "\n",
        "1. **Representación de Datos**\n",
        "   - Cada dato se puede representar como un vector de características\n",
        "   - Ejemplo: Una imagen de 28×28 píxeles se convierte en un vector de 784 componentes\n",
        "\n",
        "2. **Embeddings**\n",
        "   - Las palabras se pueden representar como vectores en un espacio semántico\n",
        "   - Ejemplo: La palabra \"gato\" podría representarse como $\\vec{v} = (0.2, -0.5, 0.8, ...)$\n",
        "\n",
        "3. **Redes Neuronales**\n",
        "   - Las entradas y salidas son vectores\n",
        "   - Los pesos de las conexiones se almacenan como vectores\n",
        "   - Los gradientes durante el entrenamiento son vectores\n",
        "\n",
        "4. **Procesamiento de Datos**\n",
        "   - La normalización se aplica a vectores de características\n",
        "   - Las distancias entre vectores miden similitud entre datos\n",
        "   - La reducción de dimensionalidad opera sobre vectores\n",
        "\n",
        "Este concepto fundamental de vectores sirve como base para entender operaciones más complejas en machine learning y deep learning, donde los datos multidimensionales son la norma.\n",
        "\n",
        "Los vectores permiten:\n",
        "- Representar datos de manera uniforme\n",
        "- Aplicar operaciones matemáticas consistentes\n",
        "- Medir similitudes y diferencias entre datos\n",
        "- Transformar y manipular información de manera sistemática"
      ],
      "metadata": {
        "id": "KfhpPbPgCPBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Operaciones Básicas\n",
        "\n",
        "## Suma y Resta de Vectores\n",
        "\n",
        "Las operaciones de suma y resta de vectores son fundamentales en IA, especialmente en el procesamiento de datos y en el entrenamiento de modelos.\n",
        "\n",
        "### Método Algebraico\n",
        "\n",
        "#### Suma de Vectores\n",
        "\n",
        "La suma de dos vectores se realiza componente a componente:\n",
        "\n",
        "Si $\\vec{u} = (u_1, u_2, ..., u_n)$ y $\\vec{v} = (v_1, v_2, ..., v_n)$, entonces:\n",
        "\n",
        "$$\\vec{u} + \\vec{v} = (u_1 + v_1, u_2 + v_2, ..., u_n + v_n)$$\n",
        "\n",
        "**Ejemplo:**\n",
        "- $\\vec{u} = (3, 4)$ y $\\vec{v} = (1, 2)$\n",
        "- $\\vec{u} + \\vec{v} = (3+1, 4+2) = (4, 6)$"
      ],
      "metadata": {
        "id": "9fSMZi2GXdDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sumando los elementos de una lista de listas\n",
        "x = [3, 4]\n",
        "y = [1, 2]\n",
        "\n",
        "z = [u + v for u, v in zip(x, y)]   # sumando componente a componente\n",
        "\n",
        "print(f\"{x} + {y} = {z}\")"
      ],
      "metadata": {
        "outputId": "0affcbf9-d152-45b9-c9ee-cff6f154433b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1r44S_tXdDV"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4] + [1, 2] = [4, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sumando con la librería NumPy\n",
        "# con NumPy se manejan ndarray que están preparados para álgebra lineal\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "u = np.array([3, 4])\n",
        "v = np.array([1, 2])\n",
        "\n",
        "w = u + v           # sumando los dos vectores como ndarrays\n",
        "print(f\"{u}  + {v}  = {w}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD4oaT__I3l3",
        "outputId": "7722525f-209f-490e-d62f-f923c4d930d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4]  + [1 2]  = [4 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resta de Vectores\n",
        "La resta se realiza también componente a componente:\n",
        "\n",
        "$$\\vec{u} - \\vec{v} = (u_1 - v_1, u_2 - v_2, ..., u_n - v_n)$$\n",
        "\n",
        "**Ejemplo:**\n",
        "- $\\vec{u} = (3, 4)$ y $\\vec{v} = (1, 2)$\n",
        "- $\\vec{u} - \\vec{v} = (3-1,\\, 4-2) = (2, 2)$"
      ],
      "metadata": {
        "id": "6TnhrOIrLWl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Resta de Vectores con NumPy\n",
        "\n",
        "w = u - v           # restando los dos vectores como ndarrays\n",
        "print(f\"{u}  - {v}  = {w}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqG1azb2JSbE",
        "outputId": "c59a1bd5-a264-488a-9643-efce9ec287cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4]  - [1 2]  = [2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Método Gráfico\n",
        "\n",
        "#### Suma de Vectores\n",
        "1. Dibujar el primer vector\n",
        "2. Desde el final del primer vector, dibujar el segundo vector\n",
        "3. El vector resultante va desde el origen hasta el final del segundo\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_5.png?raw=1\" alt=\"suma de vectores\" width=\"320\"/>\n",
        "\n",
        "#### Resta de Vectores\n",
        "1. Dibujar el primer vector\n",
        "2. Dibujar el segundo vector en dirección opuesta\n",
        "3. El vector resultante va desde el origen hasta el final del segundo vector\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_6.png?raw=1\" alt=\"resta de vectores\" width=\"380\"/>\n",
        "\n",
        "## Multiplicación por Escalar\n",
        "\n",
        "La multiplicación de un vector por un escalar $k$ multiplica cada componente del vector por ese número:\n",
        "\n",
        "Sea el vector $\\vec{v} = (v_1, v_2, ..., v_n)$ y $k$ el escalar:\n",
        "\n",
        "$$k\\vec{v} = (kv_1, kv_2, ..., kv_n)$$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_7.png?raw=1\" alt=\"producto por escalar\" width=\"280\"/>\n",
        "\n",
        "**Propiedades**\n",
        "1. Distributiva respecto a la suma de vectores: $k(\\vec{u} + \\vec{v}) = k\\vec{u} + k\\vec{v}$\n",
        "2. Distributiva respecto a la suma de escalares:: $(k_1 + k_2)\\vec{v} = k_1\\vec{v} + k_2\\vec{v}$\n",
        "3. Asociativa respecto a la multiplicación de escalares:: $k_1(k_2\\vec{v}) = (k_1k_2)\\vec{v}$\n",
        "4. Identidad: $1\\vec{v} = \\vec{v}$\n",
        "5. La multiplicación por cero da el vector cero: $0\\vec{v} = \\vec{0}$\n",
        "\n",
        "**Ejemplos**\n",
        "\n",
        "1. **Vector en 2D:**\n",
        "   - **Ejemplo 1:** Multiplicar el vector $\\vec{v} = (3, 4)$ por el escalar $k = 2$.\n",
        "\n",
        "   $$\\vec{w} = 2 \\vec{v} = (2 \\cdot 3,\\, 2 \\cdot 4) = (6, 8)$$\n",
        "\n",
        "   - **Ejemplo 2:** Multiplicar el vector $\\vec{u} = (-2, 1)$ por el escalar $k = -3$.\n",
        "\n",
        "   $$\n",
        "   \\vec{w} = -3 \\vec{u} = (-3 \\cdot -2,\\, -3 \\cdot 1) = (6, -3)\n",
        "   $$\n",
        "\n",
        "2. **Vector en 3D:**\n",
        "   - **Ejemplo:** Multiplicar el vector $\\vec{w} = (-2, 0, 6)$ por el escalar $k = -\\frac{1}{2}$.\n",
        "\n",
        "   $$\\vec{z} =  -\\tfrac{1}{2} \\vec{w} = (( -\\tfrac{1}{2}) \\cdot (-2), \\, ( -\\tfrac{1}{2}) \\cdot 0, \\, ( -\\tfrac{1}{2}) \\cdot 6) = (1, 0, -3)$$"
      ],
      "metadata": {
        "id": "0-Dx_GP8VoWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "v = np.array([3, 4])    # usando NumPy creamos un ndarray\n",
        "w = 2 * v               # producto de escalar por vector\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dPhRWVZVsB_",
        "outputId": "1612d3d5-8445-4ff2-ef80-d838cde6a733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sin usar Numpy\n",
        "\n",
        "v = [3, 4]\n",
        "k = 2\n",
        "w = [k * val for val in v]\n",
        "w"
      ],
      "metadata": {
        "id": "difxDe1tqsfs",
        "outputId": "0f7c0afd-d41d-4d5f-a7ee-690cc1a0252b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplos en contexto de IA\n",
        "\n",
        "### 1. Actualización de Pesos en Redes Neuronales\n",
        "En el entrenamiento de redes neuronales, los pesos se actualizan mediante:\n",
        "\n",
        "$$\\vec{w}_{\\text{nuevo}} = \\vec{w}_{\\text{actual}} - \\alpha\\nabla\\vec{w}$$\n",
        "\n",
        "Donde:\n",
        "- $\\vec{w}$ es el vector de pesos\n",
        "- $\\alpha$ es la tasa de aprendizaje (escalar)\n",
        "- $\\nabla\\vec{w}$ es el gradiente (vector de las derivadas parciales)\n",
        "\n",
        "### 2. Promedio de Vectores de Características\n",
        "Para calcular el centroide $\\vec{c}$ de un cluster:\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\vec{c} &= \\frac{\\vec{x}_1 + \\vec{x}_2 + \\vec{x}_3 + \\cdots + \\vec{x}_n}{n} \\\\\n",
        "\\vec{c} &= \\frac{1}{n}\\sum_{i=1}^n \\vec{x}_i\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $\\vec{x}_i$ son los vectores de características\n",
        "- $n$ es el número de vectores\n",
        "- $\\vec{c}$ es el vector promedio\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_8.webp?raw=1\" alt=\"centroides de clusters\" width=\"420\"/>\n",
        "\n",
        "### 3. Combinación de Embeddings\n",
        "En procesamiento de lenguaje natural:\n",
        "\n",
        "$$\\vec{v}_{\\text{frase}} = \\frac{\\vec{v}_{\\text{palabra1}} + \\vec{v}_{\\text{palabra2}} + ... + \\vec{v}_{\\text{palabraN}}}{N}$$\n",
        "\n",
        "### 4. Normalización de Datos\n",
        "Escalado de vectores de características:\n",
        "\n",
        "$$\\vec{x}_{\\text{normalizado}} = \\frac{\\vec{x} - \\mu}{\\sigma}$$\n",
        "\n",
        "Donde:\n",
        "- $\\mu$ es la media\n",
        "- $\\sigma$ es la desviación estándar\n",
        "\n",
        "Estas operaciones básicas son fundamentales en muchos algoritmos de IA, desde el preprocesamiento de datos hasta el entrenamiento de modelos complejos."
      ],
      "metadata": {
        "id": "jJE7MuRaXdDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Propiedades Fundamentales\n",
        "\n",
        "## Norma\n",
        "\n",
        "La norma o magnitud de un vector $\\vec{v}$ es una medida de su longitud.  \n",
        "En el contexto de machine learning, representa la \"fuerza\" o \"intensidad\" de un vector de características.\n",
        "\n",
        "### Definición Formal\n",
        "Para un vector $\\vec{v} = (v_1, v_2, ..., v_n)$, la norma euclidiana (L2) se define como:\n",
        "\n",
        "$$\\|\\vec{v}\\| = \\sqrt{\\sum_{i=1}^n v_i^2}$$\n",
        "\n",
        "**Ejemplos comunes:**\n",
        "- En 2D: $\\|\\vec{v}\\| = \\sqrt{v_1^2 + v_2^2}$\n",
        "    - Si $\\vec{v} = (3, -4)$ entonces su norma es $\\|\\vec{v}\\| = \\sqrt{3^2 + (-4)^2}= \\sqrt{9 + 16} = \\sqrt{25} = 5$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_9.png?raw=1\" alt=\"norma de un vector 2D\" width=\"280\"/>\n",
        "\n",
        "**Teorema de Pitágoras** (recordatorio):\n",
        "\n",
        "$$c^2 = a^2 + b^2$$\n",
        "\n",
        "Donde:\n",
        "- $c$: es la hipotenusa, el lado opuesto al ángulo recto.\n",
        "- $a$: es uno de los catetos del triángulo rectángulo.\n",
        "- $b$: es el otro cateto del triángulo rectángulo.\n",
        "\n",
        "Si despejamos $c$, obtenemos:\n",
        "\n",
        "$$c = \\sqrt{a^2 + b^2}$$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/pitagoras.jpg?raw=1\" alt=\"Pitagoras\"/>\n",
        "\n",
        "- En 3D: $\\|\\vec{v}\\| = \\sqrt{v_1^2 + v_2^2 + v_3^2}$\n",
        "\n",
        "### Otras Normas Comunes en ML\n",
        "1. **Norma L1 (Manhattan):**\n",
        "   $$\\|\\vec{v}\\|_1 = \\sum_{i=1}^n |v_i|$$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/vector_10.png?raw=1\" alt=\"norma Manhattan\" width=\"320\"/>\n",
        "\n",
        "2. **Norma L∞ (Máximo):**\n",
        "   $$\\|\\vec{v}\\|_∞ = \\max_{i} |v_i|$$"
      ],
      "metadata": {
        "id": "EKhGfWA0ku_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando las tres normas de la imagen\n",
        "v = np.array([6, 6])\n",
        "\n",
        "L1 = np.linalg.norm(v, ord=1)           # L1 = norma Manhattan\n",
        "L2 = np.linalg.norm(v, ord=2)           # L2 = norma Euclídea\n",
        "Linf = np.linalg.norm(v, ord=np.inf)    # L∞ = norma Infinita\n",
        "\n",
        "print(\"L1\", L1)\n",
        "print(\"L2\", L2)\n",
        "print(\"L∞\", Linf)"
      ],
      "metadata": {
        "id": "LM1Bm5n1ukpj",
        "outputId": "40283db6-76ef-4028-8f08-e325d6b51f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 12.0\n",
            "L2 8.48528137423857\n",
            "L∞ 6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Norma euclídea por varios métodos\n",
        "\n",
        "v = [3, -4]                                 # una lista\n",
        "\n",
        "# Método 1\n",
        "print(np.linalg.norm(v))                    # usando NumPy con una lista\n",
        "\n",
        "# Método 2\n",
        "print(np.sqrt(np.sum([x**2 for x in v])))   # usando NumPy solo con sum y sqrt\n",
        "\n",
        "# Método 3\n",
        "print(sum([x**2 for x in v]) ** .5)         # sin usar NumPy\n",
        "# Nota: elevar a 1/2 = 0.5 es como hacer la Raiz cuadrada\n",
        "\n",
        "# Método 4\n",
        "w = np.array([3, -4])                       # w es un ndarray\n",
        "\n",
        "print(np.linalg.norm(w))                    # usando NumPy con un ndarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgGVEjbOk1hX",
        "outputId": "ef5952cb-3f6d-4dd9-c50f-66a088464ac2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n",
            "5.0\n",
            "5.0\n",
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distancia entre Puntos\n",
        "\n",
        "La distancia entre dos puntos es crucial en muchos algoritmos de ML, especialmente en clustering y clasificación.\n",
        "\n",
        "### Distancia Euclidiana\n",
        "Para dos vectores $\\vec{u}$ y $\\vec{v}$:\n",
        "\n",
        "$$d(\\vec{u}, \\vec{v}) = \\|\\vec{u} - \\vec{v}\\| = \\sqrt{\\sum_{i=1}^n (u_i - v_i)^2}$$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/distancia.jpg?raw=1\" alt=\"distancia entre dos puntos\" width=\"320\"/>\n",
        "\n",
        "### Otras Métricas de Distancia en ML\n",
        "1. **Distancia Manhattan:**\n",
        "   $$d_1(\\vec{u}, \\vec{v}) = \\sum_{i=1}^n |u_i - v_i|$$\n",
        "\n",
        "2. **Distancia de Coseno:**\n",
        "   $$d_{\\cos}(\\vec{u}, \\vec{v}) = 1 - \\frac{\\vec{u} \\cdot \\vec{v}}{\\,\\,\\,\\,\\|\\vec{u}\\| \\, \\|\\vec{v}\\|}$$"
      ],
      "metadata": {
        "id": "_1EMuLWXndOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distancia entre dos vectores usando NumPy\n",
        "u = np.array([1, 2])\n",
        "v = np.array([4, 6])\n",
        "\n",
        "distancia = np.linalg.norm(u - v)\n",
        "print(distancia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdagtxbznnlT",
        "outputId": "ae3d31b7-1f81-47c3-80e7-7cd7447d5ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distancia entre dos vectores sin usar NumPy, usando listas\n",
        "u = [1, 2]\n",
        "v = [4, 6]\n",
        "\n",
        "# Método 1\n",
        "distancia = sum((u[i] - v[i])**2 for i in range(len(u))) ** 0.5\n",
        "print(distancia)\n",
        "\n",
        "# Método 2\n",
        "distancia = sum([(x - y)**2 for x, y in zip(u, v)]) ** 0.5\n",
        "print(distancia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9EHq-ty1d8k",
        "outputId": "2faf4411-becf-4b71-b105-80fef86a82d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n",
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalización y Vectores Unitarios\n",
        "\n",
        "### Vector Unitario\n",
        "Un vector unitario tiene norma igual a 1. Se obtiene dividiendo un vector por su norma:\n",
        "\n",
        "$$\\hat{v} = \\frac{\\vec{v}}{\\|\\vec{v}\\|}$$\n",
        "\n",
        "\n",
        "**Ejemplos**\n",
        "\n",
        "1. **Vector en 2D:**\n",
        "   - **Ejemplo 1:** Normalizar el vector $\\vec{v} = (3, 4)$.\n",
        "\n",
        "   Primero, calculamos la norma de $\\vec{v}$:\n",
        "\n",
        "   $$\n",
        "   \\|\\vec{v}\\| = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5\n",
        "   $$\n",
        "\n",
        "   Luego, dividimos $\\vec{v}$ por su norma:\n",
        "\n",
        "   $$\n",
        "   \\hat{u} = \\frac{\\vec{v}}{\\|\\vec{v}\\|} = \\frac{(3, 4)}{5} = \\left(\\frac{3}{5}, \\frac{4}{5}\\right)\n",
        "   $$\n",
        "\n",
        "   - **Ejemplo 2:** Normalizar el vector $\\vec{u} = (-2, 1)$.\n",
        "\n",
        "   Primero, calculamos la norma de $\\vec{u}$:\n",
        "\n",
        "   $$\n",
        "   \\|\\vec{u}\\| = \\sqrt{(-2)^2 + 1^2} = \\sqrt{4 + 1} = \\sqrt{5}\n",
        "   $$\n",
        "\n",
        "   Luego, dividimos $\\vec{u}$ por su norma:\n",
        "\n",
        "   $$\n",
        "   \\hat{u} = \\frac{\\vec{u}}{\\|\\vec{u}\\|} = \\frac{(-2, 1)}{\\sqrt{5}} = \\left(\\frac{-2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}}\\right)\n",
        "   $$\n",
        "\n",
        "2. **Vector en 3D:**\n",
        "   - **Ejemplo 1:** Normalizar el vector $\\vec{w} = (1, 2, 3)$.\n",
        "\n",
        "   Primero, calculamos la norma de $\\vec{w}$:\n",
        "\n",
        "   $$\n",
        "   \\|\\vec{w}\\| = \\sqrt{1^2 + 2^2 + 3^2} = \\sqrt{1 + 4 + 9} = \\sqrt{14}\n",
        "   $$\n",
        "\n",
        "   Luego, dividimos $\\vec{w}$ por su norma:\n",
        "\n",
        "   $$\n",
        "   \\hat{u} = \\frac{\\vec{w}}{\\|\\vec{w}\\|} = \\frac{(1, 2, 3)}{\\sqrt{14}} = \\left(\\frac{1}{\\sqrt{14}}, \\frac{2}{\\sqrt{14}}, \\frac{3}{\\sqrt{14}}\\right)\n",
        "   $$\n",
        "\n",
        "   - **Ejemplo 2:** Normalizar el vector $\\vec{z} = (0, -1, 2)$.\n",
        "\n",
        "   Primero, calculamos la norma de $\\vec{z}$:\n",
        "\n",
        "   $$\n",
        "   \\|\\vec{z}\\| = \\sqrt{0^2 + (-1)^2 + 2^2} = \\sqrt{0 + 1 + 4} = \\sqrt{5}\n",
        "   $$"
      ],
      "metadata": {
        "id": "1rIdVCra26f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.array([1, 2, 3])\n",
        "print(w / np.linalg.norm(w))\n",
        "\n",
        "# Comprobación manual\n",
        "norma = (1**2 + 2**2 + 3**2) ** 0.5\n",
        "[1 / norma, 2 / norma, 3 / norma]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrG4Mdfx3JTf",
        "outputId": "706e4975-e643-4ff4-e064-a7917e65838b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.26726124 0.53452248 0.80178373]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2672612419124244, 0.5345224838248488, 0.8017837257372732]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proceso de Normalización\n",
        "1. **Min-Max Scaling:**\n",
        "   $$x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$$\n",
        "\n",
        "2. **Z-Score Normalization:**\n",
        "   $$x_{\\text{norm}} = \\frac{x - \\mu}{\\sigma}$$"
      ],
      "metadata": {
        "id": "i-7rcop1XdDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Productos entre Vectores\n",
        "\n",
        "## Producto Escalar (Dot Product)\n",
        "\n",
        "El producto escalar es una operación fundamental en deep learning que produce un escalar a partir de dos vectores.\n",
        "\n",
        "### Definición\n",
        "Para dos vectores $\\vec{u} = (u_1, u_2, ..., u_n)$ y $\\vec{v} = (v_1, v_2, ..., v_n)$:\n",
        "\n",
        "$$\\vec{u} \\cdot \\vec{v} = \\sum_{i=1}^n u_i v_i = u_1v_1 + u_2v_2 + ... + u_nv_n$$\n",
        "\n",
        "**Ejemplo**\n",
        "\n",
        "Calcular el producto escalar de $\\vec{u} = (1, 2, 3)$ y $\\vec{v} = (-4, 5, 6)$.\n",
        "\n",
        "   $$\n",
        "   \\vec{u} \\cdot \\vec{v} = 1 \\cdot (-4) + 2 \\cdot 5 + 3 \\cdot 6 = -4 + 10 + 18 = 24\n",
        "   $$"
      ],
      "metadata": {
        "id": "yqosGlIwXdDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "v1 = np.array([1,2,3])\n",
        "v2 = np.array([-4,5,6])     # v1 y v2 deben ser de la misma longitud\n",
        "print(f\"Producto punto: 1*(-4) + 2*5 + 3*6 = {1*(-4) + 2*5 + 3*6}\")\n",
        "print(v1.dot(v2))   # forma clásica de hacer el producto punto de dos vectores\n",
        "v1 @ v2             # la @ funciona desde la versión 3.5 de Python"
      ],
      "metadata": {
        "outputId": "07ff4e2c-36b3-4a43-81a8-bdd7975c156b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1V1oXp6XdDW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producto punto: 1*(-4) + 2*5 + 3*6 = 24\n",
            "24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sin usar Numpy, considerando v1 y v2 como listas\n",
        "v1 = [1,2,3]\n",
        "v2 = [-4,5,6]\n",
        "sum([x*y for x, y in zip(v1, v2)])"
      ],
      "metadata": {
        "id": "Ixs-zGOL3mW9",
        "outputId": "744a7457-05ea-434f-b806-98dcd2bd2660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades\n",
        "1. **Conmutativa:** $\\vec{u} \\cdot \\vec{v} = \\vec{v} \\cdot \\vec{u}$\n",
        "2. **Distributiva:** $\\vec{u} \\cdot (\\vec{v} + \\vec{w}) = \\vec{u} \\cdot \\vec{v} + \\vec{u} \\cdot \\vec{w}$\n",
        "3. **Asociativa respecto a la multiplicación por escalar:** $(k\\vec{u}) \\cdot \\vec{v} = k(\\vec{u} \\cdot \\vec{v})$\n",
        "4. **Producto escalar de un vector consigo mismo:** $\\vec{v} \\cdot \\vec{v} = \\|\\vec{v}\\|^2$\n",
        "\n",
        "### Ángulo entre Vectores\n",
        "El producto escalar está relacionado con el ángulo $\\theta$ entre dos vectores:\n",
        "\n",
        "$$\\cos \\theta = \\dfrac{\\vec{u} \\cdot \\vec{v}}{\\,\\,\\,\\,\\|\\vec{u}\\| \\, \\|\\vec{v}\\|}$$"
      ],
      "metadata": {
        "id": "l6spGYZU6Tbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definir dos vectores\n",
        "u = np.array([1, 0, 0])\n",
        "v = np.array([2, 2, 0])\n",
        "\n",
        "# Calcular el producto escalar (dot product) de los vectores\n",
        "dot_product = np.dot(u, v)\n",
        "\n",
        "# Calcular las normas (magnitudes) de los vectores\n",
        "norm_u = np.linalg.norm(u)\n",
        "norm_v = np.linalg.norm(v)\n",
        "\n",
        "# Calcular el coseno del ángulo theta\n",
        "cos_theta = dot_product / (norm_u * norm_v)\n",
        "\n",
        "# Calcular el ángulo theta en radianes\n",
        "theta_rad = np.arccos(cos_theta)\n",
        "print(\"El ángulo en radianes es:\", theta_rad)\n",
        "\n",
        "# Convertir el ángulo theta a grados\n",
        "theta_deg = np.degrees(theta_rad)\n",
        "print(\"El ángulo en grados es:\", round(theta_deg, 12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZJIgb576ZwG",
        "outputId": "862385e7-b9d1-41d2-f575-aaa8dd78a4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El ángulo en radianes es: 0.7853981633974484\n",
            "El ángulo en grados es: 45.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Producto Vectorial (Cross Product)\n",
        "\n",
        "El producto vectorial es menos común en deep learning, pero es importante en ciertas aplicaciones de visión por computador y gráficos.\n",
        "\n",
        "### Definición\n",
        "Para vectores en 3D, $\\vec{u} = (u_1, u_2, u_3)$ y $\\vec{v} = (v_1, v_2, v_3)$:\n",
        "\n",
        "$$\\vec{u} \\times \\vec{v} = (u_2v_3 - u_3v_2, \\; u_3v_1 - u_1v_3, \\; u_1v_2 - u_2v_1)$$\n",
        "\n",
        "También puede representarse mediante un determinante 3x3:\n",
        "\n",
        "$$\n",
        "\\vec{u} \\times \\vec{v} =\n",
        "\\begin{vmatrix}\n",
        "i & j & k \\\\\n",
        "u_1 & u_2 & u_3 \\\\\n",
        "v_1 & v_2 & v_3\n",
        "\\end{vmatrix}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $i$, $j$ y $k$ son los vectores unitarios en las direcciones de los ejes $x$, $y$ y $z$.\n",
        "\n",
        "Desarrollando el determinante y reorganizando términos:\n",
        "\n",
        "$$\n",
        "\\vec{u} \\times \\vec{v} = i(u_2v_3) + j(u_3v_1) + k(u_1v_2) -i(u_3v_2) - j(u_1v_3) - k(u_2v_1) + i(u_2v_3 - u_3v_2) + j(u_3v_1 - u_1v_3) + k(u_1v_2 - u_2v_1) =\n",
        "$$\n",
        "\n",
        "$$\n",
        "=\n",
        "\\big(u_2v_3 - u_3v_2\\big)i +\n",
        "\\big(u_3v_1 - u_1v_3\\big)j +\n",
        "\\big(u_1v_2 - u_2v_1\\big)k\n",
        "$$\n",
        "\n",
        "Esto corresponde a:\n",
        "\n",
        "$$\n",
        "\\vec{u} \\times \\vec{v} = (u_2v_3 - u_3v_2, \\; u_3v_1 - u_1v_3, \\; u_1v_2 - u_2v_1)\n",
        "$$\n",
        "\n",
        "<img src=\"https://github.com/financieras/math_for_ai/blob/main/img/mano_derecha.jpg?raw=1\" alt=\"mano derecha\" width=\"480\"/>\n",
        "\n",
        "\n",
        "### Propiedades\n",
        "1. **Anticonmutativa:** $\\vec{u} \\times \\vec{v} = -(\\vec{v} \\times \\vec{u})$\n",
        "2. **Distributiva:** $\\vec{u} \\times (\\vec{v} + \\vec{w}) = \\vec{u} \\times \\vec{v} + \\vec{u} \\times \\vec{w}$\n",
        "3. **Escalar:** $(k\\vec{u}) \\times \\vec{v} = k(\\vec{u} \\times \\vec{v})$"
      ],
      "metadata": {
        "id": "qE6alk8LXdDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "u = np.array([2, 3, 4])\n",
        "v = np.array([5, 6, 7])\n",
        "\n",
        "# Calculamos el producto vectorial\n",
        "cross_product = np.cross(u, v)\n",
        "\n",
        "print(\"Producto vectorial:\", cross_product)"
      ],
      "metadata": {
        "id": "yhvPlioY7eNV",
        "outputId": "b2089a29-15d9-41cc-eb84-970608b8e216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producto vectorial: [-3  6 -3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación del código:**\n",
        "- `np.cross` realiza el cálculo del producto vectorial entre dos vectores tridimensionales.\n",
        "- En este caso, el resultado es un nuevo vector perpendicular a ambos."
      ],
      "metadata": {
        "id": "d70_shXy7sDO"
      }
    }
  ]
}