{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVdTqke64YPxqvg0mOVsFk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/temario_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß≠ **Programa de Estad√≠stica para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estad√≠stica Descriptiva**\n",
        "\n",
        "**Objetivo:** Comprender los tipos de datos, su descripci√≥n y visualizaci√≥n inicial.\n",
        "\n",
        "1. **Tema 1.** Conceptos b√°sicos: poblaci√≥n, muestra, variables, tipos y escalas de medici√≥n.\n",
        "2. **Tema 2.** Medidas de tendencia central: media, mediana, moda.\n",
        "3. **Tema 3.** Medidas de dispersi√≥n: rango, varianza, desviaci√≥n est√°ndar, coeficiente de variaci√≥n.\n",
        "4. **Tema 4.** Medidas de posici√≥n y forma: percentiles, cuartiles, asimetr√≠a y curtosis.\n",
        "5. **Tema 5.** Estad√≠stica bivariante: covarianza, correlaci√≥n (Pearson, Spearman).\n",
        "6. **Tema 6.** Visualizaci√≥n y an√°lisis exploratorio de datos (EDA): histogramas, boxplots, scatter plots, outliers.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad y Distribuciones**\n",
        "\n",
        "**Objetivo:** Entender la incertidumbre y las distribuciones que modelan fen√≥menos aleatorios.\n",
        "\n",
        "1. **Tema 1.** Conceptos de probabilidad: espacio muestral, eventos, independencia, probabilidad condicional.\n",
        "2. **Tema 2.** Teorema de Bayes e interpretaci√≥n pr√°ctica.\n",
        "3. **Tema 3.** Variables aleatorias: discretas y continuas, funciones de probabilidad y densidad.\n",
        "4. **Tema 4.** Distribuciones discretas: Bernoulli, Binomial, Poisson.\n",
        "5. **Tema 5.** Distribuciones continuas: Uniforme, Normal, Exponencial, t-Student, Chi-cuadrado, F.\n",
        "6. **Tema 6.** Esperanza, varianza, covarianza y Teorema del L√≠mite Central.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Inferencia Estad√≠stica**\n",
        "\n",
        "**Objetivo:** Extraer conclusiones sobre poblaciones a partir de muestras.\n",
        "\n",
        "1. **Tema 1.** Muestreo y sesgos: m√©todos de muestreo y error muestral.\n",
        "2. **Tema 2.** Distribuciones muestrales y estimadores (insesgados, eficientes, consistentes).\n",
        "3. **Tema 3.** Intervalos de confianza para medias y proporciones.\n",
        "4. **Tema 4.** Pruebas de hip√≥tesis: hip√≥tesis nula/alternativa, p-valor, errores tipo I y II.\n",
        "5. **Tema 5.** Tests param√©tricos: t-test, ANOVA.\n",
        "6. **Tema 6.** Tests no param√©tricos: chi-cuadrado, Mann-Whitney, Kruskal-Wallis.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Modelos Estad√≠sticos y Regresi√≥n**\n",
        "\n",
        "**Objetivo:** Modelar relaciones entre variables y sentar las bases de los algoritmos de ML.\n",
        "\n",
        "1. **Tema 1.** Correlaci√≥n vs causalidad.\n",
        "2. **Tema 2.** Regresi√≥n lineal simple: estimaci√≥n por m√≠nimos cuadrados, interpretaci√≥n, supuestos.\n",
        "3. **Tema 3.** Regresi√≥n m√∫ltiple: multicolinealidad, selecci√≥n de variables, diagn√≥stico de residuos.\n",
        "4. **Tema 4.** Regresi√≥n log√≠stica: clasificaci√≥n binaria, odds ratio, m√©tricas b√°sicas (precisi√≥n, recall, F1).\n",
        "5. **Tema 5.** Regularizaci√≥n: Ridge, Lasso y Elastic Net.\n",
        "6. **Tema 6.** Modelos lineales generalizados (GLM): visi√≥n general.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. M√©todos de Validaci√≥n y Evaluaci√≥n de Modelos**\n",
        "\n",
        "**Objetivo:** Aplicar principios estad√≠sticos para evaluar y validar modelos predictivos.\n",
        "\n",
        "1. **Tema 1.** Partici√≥n de datos: train/test/validation, muestreo estratificado.\n",
        "2. **Tema 2.** Validaci√≥n cruzada (K-fold, Leave-One-Out).\n",
        "3. **Tema 3.** Bootstrapping y Jackknife: remuestreo y estimaci√≥n de incertidumbre.\n",
        "4. **Tema 4.** M√©tricas de evaluaci√≥n: MSE, RMSE, MAE, R¬≤, ROC, AUC, Precision-Recall.\n",
        "5. **Tema 5.** Sesgo, varianza, overfitting y underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. An√°lisis Multivariante y Series Temporales**\n",
        "\n",
        "**Objetivo:** Analizar datos complejos y dependientes del tiempo.\n",
        "\n",
        "1. **Tema 1.** An√°lisis de componentes principales (PCA) y reducci√≥n de dimensionalidad.\n",
        "2. **Tema 2.** Clustering: K-means, clustering jer√°rquico, evaluaci√≥n de cl√∫steres.\n",
        "3. **Tema 3.** An√°lisis factorial y discriminante.\n",
        "4. **Tema 4.** Series temporales: componentes, estacionariedad, autocorrelaci√≥n.\n",
        "5. **Tema 5.** Modelos ARIMA y su interpretaci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. Enfoque Bayesiano y Aplicaciones en ML**\n",
        "\n",
        "**Objetivo:** Comprender la inferencia bayesiana y su papel en Machine Learning.\n",
        "\n",
        "1. **Tema 1.** Paradigma bayesiano vs frecuentista.\n",
        "2. **Tema 2.** Distribuciones a priori, verosimilitud y posterior.\n",
        "3. **Tema 3.** Inferencia bayesiana y ejemplos simples.\n",
        "4. **Tema 4.** Clasificador Naive Bayes y aplicaciones pr√°cticas.\n",
        "5. **Tema 5.** Introducci√≥n a MCMC y herramientas como PyMC.\n"
      ],
      "metadata": {
        "id": "u7ecmr68-m92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß≠ **Programa de Estad√≠stica para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estad√≠stica Descriptiva**\n",
        "\n",
        "**Objetivo:** Comprender los tipos de datos, su descripci√≥n y visualizaci√≥n inicial.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Conceptos b√°sicos: poblaci√≥n, muestra, variables, tipos y escalas de medici√≥n**\n",
        "\n",
        "* **Lecci√≥n 1.1.** ¬øQu√© es la estad√≠stica? Ramas descriptiva e inferencial.\n",
        "* **Lecci√≥n 1.2.** Conceptos fundamentales: poblaci√≥n, muestra, par√°metro y estad√≠stico.\n",
        "* **Lecci√≥n 1.3.** Tipos de estudios: observacional vs experimental.\n",
        "* **Lecci√≥n 1.4.** Tipos de variables: cualitativas, cuantitativas discretas y continuas.\n",
        "* **Lecci√≥n 1.5.** Escalas de medici√≥n: nominal, ordinal, de intervalo y de raz√≥n.\n",
        "* **Lecci√≥n 1.6.** Organizaci√≥n y presentaci√≥n de datos: tablas de frecuencias y porcentajes.\n",
        "* **Lecci√≥n 1.7.** Introducci√≥n al an√°lisis de datos con Python (pandas y numpy).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Medidas de tendencia central: media, mediana, moda**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Concepto y utilidad de las medidas de tendencia central.\n",
        "* **Lecci√≥n 2.2.** C√°lculo de la media aritm√©tica, ponderada y geom√©trica.\n",
        "* **Lecci√≥n 2.3.** C√°lculo e interpretaci√≥n de la mediana.\n",
        "* **Lecci√≥n 2.4.** Moda: definici√≥n, tipos y limitaciones.\n",
        "* **Lecci√≥n 2.5.** Comparaci√≥n entre media, mediana y moda (efecto de valores at√≠picos).\n",
        "* **Lecci√≥n 2.6.** Implementaci√≥n en Python: funciones `mean()`, `median()`, `mode()`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Medidas de dispersi√≥n: rango, varianza, desviaci√≥n est√°ndar, coeficiente de variaci√≥n**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Concepto de dispersi√≥n y su importancia.\n",
        "* **Lecci√≥n 3.2.** C√°lculo e interpretaci√≥n del rango y rango intercuart√≠lico (IQR).\n",
        "* **Lecci√≥n 3.3.** Varianza y desviaci√≥n est√°ndar: significado y f√≥rmulas.\n",
        "* **Lecci√≥n 3.4.** Coeficiente de variaci√≥n y su interpretaci√≥n relativa.\n",
        "* **Lecci√≥n 3.5.** Relaci√≥n entre dispersi√≥n y estabilidad de datos.\n",
        "* **Lecci√≥n 3.6.** C√°lculo con Python: `var()`, `std()`, `quantile()`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Medidas de posici√≥n y forma: percentiles, cuartiles, asimetr√≠a y curtosis**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Concepto de posici√≥n relativa en un conjunto de datos.\n",
        "* **Lecci√≥n 4.2.** Percentiles y cuartiles: interpretaci√≥n y c√°lculo.\n",
        "* **Lecci√≥n 4.3.** Diagramas de caja y bigotes (boxplots).\n",
        "* **Lecci√≥n 4.4.** Asimetr√≠a (skewness): tipos e interpretaci√≥n.\n",
        "* **Lecci√≥n 4.5.** Curtosis: leptoc√∫rtica, mesoc√∫rtica y platic√∫rtica.\n",
        "* **Lecci√≥n 4.6.** C√°lculo e interpretaci√≥n pr√°ctica con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Estad√≠stica bivariante: covarianza, correlaci√≥n (Pearson, Spearman)**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Concepto de relaci√≥n entre dos variables.\n",
        "* **Lecci√≥n 5.2.** Covarianza: f√≥rmula e interpretaci√≥n.\n",
        "* **Lecci√≥n 5.3.** Coeficiente de correlaci√≥n de Pearson.\n",
        "* **Lecci√≥n 5.4.** Correlaci√≥n de Spearman (rangos).\n",
        "* **Lecci√≥n 5.5.** Diferencias entre correlaci√≥n y causalidad.\n",
        "* **Lecci√≥n 5.6.** Matriz de correlaciones y mapa de calor en Python (Seaborn/Matplotlib).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Visualizaci√≥n y an√°lisis exploratorio de datos (EDA): histogramas, boxplots, scatter plots, outliers**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Importancia del EDA en Data Science.\n",
        "* **Lecci√≥n 6.2.** Histogramas y densidades: forma y dispersi√≥n de la distribuci√≥n.\n",
        "* **Lecci√≥n 6.3.** Diagramas de caja, viol√≠n y barras.\n",
        "* **Lecci√≥n 6.4.** Gr√°ficos de dispersi√≥n (scatter plots) y relaci√≥n entre variables.\n",
        "* **Lecci√≥n 6.5.** Detecci√≥n de outliers: m√©todos z-score e IQR.\n",
        "* **Lecci√≥n 6.6.** Herramientas de visualizaci√≥n en Python: Matplotlib, Seaborn, Plotly.\n",
        "* **Lecci√≥n 6.7.** Proyecto pr√°ctico: an√°lisis exploratorio de un dataset real (ej. Iris o Titanic).\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad y Distribuciones**\n",
        "\n",
        "**Objetivo:** Entender la incertidumbre y las distribuciones que modelan fen√≥menos aleatorios.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Conceptos de probabilidad: espacio muestral, eventos, independencia, probabilidad condicional**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Concepto de experimento aleatorio y espacio muestral.\n",
        "* **Lecci√≥n 1.2.** Eventos y operaciones entre eventos (uni√≥n, intersecci√≥n, complemento).\n",
        "* **Lecci√≥n 1.3.** Definiciones cl√°sica, frecuentista y axiom√°tica de probabilidad.\n",
        "* **Lecci√≥n 1.4.** Propiedades b√°sicas de la probabilidad.\n",
        "* **Lecci√≥n 1.5.** Independencia y dependencia de eventos.\n",
        "* **Lecci√≥n 1.6.** Probabilidad condicional y regla de la multiplicaci√≥n.\n",
        "* **Lecci√≥n 1.7.** Ejercicios pr√°cticos con Python y simulaciones (lanzamiento de dados y monedas).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Teorema de Bayes e interpretaci√≥n pr√°ctica**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Idea fundamental del razonamiento bayesiano.\n",
        "* **Lecci√≥n 2.2.** Derivaci√≥n y enunciado del Teorema de Bayes.\n",
        "* **Lecci√≥n 2.3.** Probabilidad total y √°rboles de probabilidad.\n",
        "* **Lecci√≥n 2.4.** Aplicaciones pr√°cticas: diagn√≥stico m√©dico, detecci√≥n de spam.\n",
        "* **Lecci√≥n 2.5.** Simulaci√≥n del Teorema de Bayes en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Variables aleatorias: discretas y continuas, funciones de probabilidad y densidad**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Concepto de variable aleatoria y su funci√≥n de probabilidad.\n",
        "* **Lecci√≥n 3.2.** Funci√≥n de distribuci√≥n acumulada (FDA).\n",
        "* **Lecci√≥n 3.3.** Diferencias entre variables discretas y continuas.\n",
        "* **Lecci√≥n 3.4.** C√°lculo de esperanza, varianza y desviaci√≥n t√≠pica.\n",
        "* **Lecci√≥n 3.5.** Representaci√≥n gr√°fica de distribuciones discretas y continuas.\n",
        "* **Lecci√≥n 3.6.** Implementaci√≥n en Python: `numpy.random` y `scipy.stats`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Distribuciones discretas: Bernoulli, Binomial, Poisson**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Distribuci√≥n de Bernoulli: definici√≥n y propiedades.\n",
        "* **Lecci√≥n 4.2.** Distribuci√≥n Binomial: probabilidad de √©xitos y funci√≥n de masa.\n",
        "* **Lecci√≥n 4.3.** Distribuci√≥n Poisson: conteo de eventos raros.\n",
        "* **Lecci√≥n 4.4.** Relaci√≥n entre Binomial y Poisson.\n",
        "* **Lecci√≥n 4.5.** Aplicaciones pr√°cticas: defectos en producci√≥n, llegadas en colas.\n",
        "* **Lecci√≥n 4.6.** Simulaci√≥n y visualizaci√≥n en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Distribuciones continuas: Uniforme, Normal, Exponencial, t-Student, Chi-cuadrado, F**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Distribuci√≥n Uniforme: definici√≥n y ejemplos.\n",
        "* **Lecci√≥n 5.2.** Distribuci√≥n Normal: propiedades y regla del 68‚Äì95‚Äì99,7%.\n",
        "* **Lecci√≥n 5.3.** Tipificaci√≥n y uso de la distribuci√≥n normal est√°ndar.\n",
        "* **Lecci√≥n 5.4.** Distribuci√≥n Exponencial: tiempo entre eventos y memoria sin efecto.\n",
        "* **Lecci√≥n 5.5.** Distribuciones t-Student, Chi-cuadrado y F: usos en inferencia.\n",
        "* **Lecci√≥n 5.6.** Aplicaciones pr√°cticas en Python y comparaci√≥n de distribuciones.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Esperanza, varianza, covarianza y Teorema del L√≠mite Central**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Esperanza matem√°tica y propiedades lineales.\n",
        "* **Lecci√≥n 6.2.** Varianza y covarianza: interpretaci√≥n y f√≥rmulas.\n",
        "* **Lecci√≥n 6.3.** Propiedades de la varianza de combinaciones lineales.\n",
        "* **Lecci√≥n 6.4.** Ley de los grandes n√∫meros.\n",
        "* **Lecci√≥n 6.5.** Teorema del L√≠mite Central: enunciado e importancia en estad√≠stica.\n",
        "* **Lecci√≥n 6.6.** Demostraci√≥n emp√≠rica del Teorema del L√≠mite Central con Python (simulaciones).\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Inferencia Estad√≠stica**\n",
        "\n",
        "**Objetivo:** Extraer conclusiones sobre poblaciones a partir de muestras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Muestreo y sesgos: m√©todos de muestreo y error muestral**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Concepto de muestreo y necesidad de inferencia.\n",
        "* **Lecci√≥n 1.2.** Poblaci√≥n, marco muestral y muestra representativa.\n",
        "* **Lecci√≥n 1.3.** Tipos de muestreo: aleatorio simple, sistem√°tico, estratificado, por conglomerados.\n",
        "* **Lecci√≥n 1.4.** Tama√±o muestral y error muestral.\n",
        "* **Lecci√≥n 1.5.** Sesgos de selecci√≥n y no respuesta.\n",
        "* **Lecci√≥n 1.6.** Simulaci√≥n del proceso de muestreo con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Distribuciones muestrales y estimadores (insesgados, eficientes, consistentes)**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Concepto de distribuci√≥n muestral.\n",
        "* **Lecci√≥n 2.2.** Distribuci√≥n muestral de la media y de la proporci√≥n.\n",
        "* **Lecci√≥n 2.3.** Propiedades de los estimadores: insesgadez, eficiencia, consistencia.\n",
        "* **Lecci√≥n 2.4.** Errores est√°ndar y su interpretaci√≥n.\n",
        "* **Lecci√≥n 2.5.** Ejemplos pr√°cticos de distribuciones muestrales con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Intervalos de confianza para medias y proporciones**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Concepto de intervalo de confianza y nivel de confianza.\n",
        "* **Lecci√≥n 3.2.** Intervalo de confianza para una media (œÉ conocida y desconocida).\n",
        "* **Lecci√≥n 3.3.** Intervalo de confianza para una proporci√≥n.\n",
        "* **Lecci√≥n 3.4.** Intervalos de confianza para diferencia de medias y proporciones.\n",
        "* **Lecci√≥n 3.5.** Interpretaci√≥n pr√°ctica y errores comunes.\n",
        "* **Lecci√≥n 3.6.** C√°lculo en Python con `scipy.stats` y comparaci√≥n visual.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Pruebas de hip√≥tesis: hip√≥tesis nula/alternativa, p-valor, errores tipo I y II**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Fundamentos de la prueba de hip√≥tesis: H‚ÇÄ y H‚ÇÅ.\n",
        "* **Lecci√≥n 4.2.** Tipos de errores (I y II) y potencia de una prueba.\n",
        "* **Lecci√≥n 4.3.** Estad√≠stico de prueba y regiones de rechazo.\n",
        "* **Lecci√≥n 4.4.** Valor p e interpretaci√≥n correcta.\n",
        "* **Lecci√≥n 4.5.** Procedimiento paso a paso para realizar un test de hip√≥tesis.\n",
        "* **Lecci√≥n 4.6.** Ejercicios pr√°cticos en Python: prueba de medias y proporciones.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Tests param√©tricos: t-test, ANOVA**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Supuestos de los tests param√©tricos.\n",
        "* **Lecci√≥n 5.2.** Prueba t para una muestra y para dos muestras independientes.\n",
        "* **Lecci√≥n 5.3.** Prueba t pareada (muestras relacionadas).\n",
        "* **Lecci√≥n 5.4.** ANOVA de un factor: hip√≥tesis, estad√≠stico F e interpretaci√≥n.\n",
        "* **Lecci√≥n 5.5.** Comparaciones m√∫ltiples (Tukey HSD).\n",
        "* **Lecci√≥n 5.6.** Implementaci√≥n pr√°ctica con `scipy.stats` y `statsmodels`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Tests no param√©tricos: chi-cuadrado, Mann-Whitney, Kruskal-Wallis**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Cu√°ndo usar tests no param√©tricos.\n",
        "* **Lecci√≥n 6.2.** Test chi-cuadrado de independencia y de bondad de ajuste.\n",
        "* **Lecci√≥n 6.3.** Prueba de Mann-Whitney U (dos muestras independientes).\n",
        "* **Lecci√≥n 6.4.** Prueba de Kruskal-Wallis (m√°s de dos muestras).\n",
        "* **Lecci√≥n 6.5.** Comparaci√≥n entre m√©todos param√©tricos y no param√©tricos.\n",
        "* **Lecci√≥n 6.6.** Aplicaciones en Python con `scipy.stats`.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Modelos Estad√≠sticos y Regresi√≥n**\n",
        "\n",
        "**Objetivo:** Modelar relaciones entre variables y realizar predicciones mediante t√©cnicas de regresi√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Concepto de modelo estad√≠stico y ajuste de modelos**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Qu√© es un modelo estad√≠stico y su papel en el an√°lisis de datos.\n",
        "* **Lecci√≥n 1.2.** Tipos de modelos: deterministas vs. probabil√≠sticos.\n",
        "* **Lecci√≥n 1.3.** Etapas del modelado estad√≠stico.\n",
        "* **Lecci√≥n 1.4.** Medidas de ajuste: error cuadr√°tico medio, R¬≤ y R¬≤ ajustado.\n",
        "* **Lecci√≥n 1.5.** Overfitting y underfitting: diagn√≥stico y prevenci√≥n.\n",
        "* **Lecci√≥n 1.6.** Evaluaci√≥n de modelos con datos de entrenamiento y prueba.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Regresi√≥n lineal simple**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Concepto y ecuaci√≥n del modelo lineal simple.\n",
        "* **Lecci√≥n 2.2.** Estimaci√≥n de par√°metros por m√≠nimos cuadrados.\n",
        "* **Lecci√≥n 2.3.** Interpretaci√≥n de coeficientes y significado del intercepto.\n",
        "* **Lecci√≥n 2.4.** Supuestos del modelo lineal.\n",
        "* **Lecci√≥n 2.5.** Diagn√≥stico de residuos: homocedasticidad, normalidad, independencia.\n",
        "* **Lecci√≥n 2.6.** Implementaci√≥n en Python con `scikit-learn` y `statsmodels`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Regresi√≥n lineal m√∫ltiple**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Extensi√≥n del modelo a m√∫ltiples variables explicativas.\n",
        "* **Lecci√≥n 3.2.** Multicolinealidad y su detecci√≥n (VIF).\n",
        "* **Lecci√≥n 3.3.** Selecci√≥n de variables: m√©todos hacia adelante, hacia atr√°s y stepwise.\n",
        "* **Lecci√≥n 3.4.** Evaluaci√≥n del modelo m√∫ltiple: R¬≤ ajustado y AIC/BIC.\n",
        "* **Lecci√≥n 3.5.** Interacci√≥n entre variables y t√©rminos polin√≥micos.\n",
        "* **Lecci√≥n 3.6.** Ejemplo pr√°ctico completo en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Regresi√≥n log√≠stica y modelos para variables categ√≥ricas**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Concepto y funci√≥n sigmoide.\n",
        "* **Lecci√≥n 4.2.** Odds, log-odds y probabilidad.\n",
        "* **Lecci√≥n 4.3.** Estimaci√≥n de par√°metros por m√°xima verosimilitud.\n",
        "* **Lecci√≥n 4.4.** Evaluaci√≥n del modelo: matriz de confusi√≥n, precisi√≥n, recall, F1-score.\n",
        "* **Lecci√≥n 4.5.** Curva ROC y AUC.\n",
        "* **Lecci√≥n 4.6.** Implementaci√≥n pr√°ctica con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Diagn√≥stico y validaci√≥n de modelos**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Supuestos y problemas comunes: multicolinealidad, outliers, leverage.\n",
        "* **Lecci√≥n 5.2.** M√©todos de validaci√≥n cruzada (k-fold, leave-one-out).\n",
        "* **Lecci√≥n 5.3.** Regularizaci√≥n: Ridge, Lasso y Elastic Net.\n",
        "* **Lecci√≥n 5.4.** Comparaci√≥n de modelos mediante m√©tricas de error.\n",
        "* **Lecci√≥n 5.5.** Interpretaci√≥n de resultados y comunicaci√≥n de modelos.\n",
        "* **Lecci√≥n 5.6.** Ejercicios pr√°cticos integrados con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. An√°lisis Multivariante**\n",
        "\n",
        "**Objetivo:** Analizar relaciones simult√°neas entre m√∫ltiples variables y reducir la dimensionalidad de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Introducci√≥n al an√°lisis multivariante**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Qu√© es el an√°lisis multivariante y su importancia en Data Science.\n",
        "* **Lecci√≥n 1.2.** Tipos de variables y estructuras de datos multivariantes.\n",
        "* **Lecci√≥n 1.3.** Matriz de datos y matriz de covarianzas/correlaciones.\n",
        "* **Lecci√≥n 1.4.** Escalado y normalizaci√≥n de variables.\n",
        "* **Lecci√≥n 1.5.** Visualizaci√≥n multivariante: pairplots, mapas de calor y gr√°ficos 3D.\n",
        "* **Lecci√≥n 1.6.** Ejemplo introductorio en Python con `pandas` y `seaborn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. An√°lisis de Componentes Principales (PCA)**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Motivaci√≥n y fundamentos matem√°ticos del PCA.\n",
        "* **Lecci√≥n 2.2.** Autovalores y autovectores: interpretaci√≥n geom√©trica.\n",
        "* **Lecci√≥n 2.3.** Varianza explicada y selecci√≥n del n√∫mero de componentes.\n",
        "* **Lecci√≥n 2.4.** Proyecci√≥n de los datos en los componentes principales.\n",
        "* **Lecci√≥n 2.5.** Visualizaci√≥n de resultados: biplot y scree plot.\n",
        "* **Lecci√≥n 2.6.** Implementaci√≥n pr√°ctica con `scikit-learn` y `matplotlib`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. An√°lisis de Factores (FA)**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Diferencias entre PCA y An√°lisis Factorial.\n",
        "* **Lecci√≥n 3.2.** Modelo factorial com√∫n y comunalidades.\n",
        "* **Lecci√≥n 3.3.** M√©todos de extracci√≥n: componentes principales, m√°xima verosimilitud.\n",
        "* **Lecci√≥n 3.4.** Rotaci√≥n de factores: Varimax, Promax.\n",
        "* **Lecci√≥n 3.5.** Interpretaci√≥n de factores y cargas factoriales.\n",
        "* **Lecci√≥n 3.6.** Ejemplo pr√°ctico con `factor_analyzer` en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. An√°lisis de Conglomerados (Clustering)**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Concepto de agrupamiento y medidas de similitud/distancia.\n",
        "* **Lecci√≥n 4.2.** M√©todos jer√°rquicos: dendrogramas y linkage.\n",
        "* **Lecci√≥n 4.3.** M√©todos no jer√°rquicos: K-means y K-medoids.\n",
        "* **Lecci√≥n 4.4.** Determinaci√≥n del n√∫mero √≥ptimo de clusters (Elbow, Silhouette).\n",
        "* **Lecci√≥n 4.5.** Visualizaci√≥n y an√°lisis de clusters.\n",
        "* **Lecci√≥n 4.6.** Aplicaci√≥n pr√°ctica con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. An√°lisis Discriminante y Reducci√≥n de Dimensionalidad Supervisada**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Concepto de an√°lisis discriminante lineal (LDA).\n",
        "* **Lecci√≥n 5.2.** Funciones discriminantes y separaci√≥n de grupos.\n",
        "* **Lecci√≥n 5.3.** Comparaci√≥n LDA vs PCA.\n",
        "* **Lecci√≥n 5.4.** An√°lisis discriminante cuadr√°tico (QDA).\n",
        "* **Lecci√≥n 5.5.** Aplicaci√≥n de LDA y QDA a conjuntos de datos reales.\n",
        "* **Lecci√≥n 5.6.** Implementaci√≥n con `scikit-learn` y comparaci√≥n de rendimiento.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. T√©cnicas avanzadas y aplicaciones en Machine Learning**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Reducci√≥n de dimensionalidad no lineal: t-SNE, UMAP.\n",
        "* **Lecci√≥n 6.2.** Clustering jer√°rquico avanzado y DBSCAN.\n",
        "* **Lecci√≥n 6.3.** Detecci√≥n de outliers multivariantes.\n",
        "* **Lecci√≥n 6.4.** Combinaci√≥n de PCA y clustering.\n",
        "* **Lecci√≥n 6.5.** Visualizaci√≥n de datos de alta dimensi√≥n.\n",
        "* **Lecci√≥n 6.6.** Casos pr√°cticos en Python con datasets del mundo real.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. Series Temporales y An√°lisis Predictivo**\n",
        "\n",
        "**Objetivo:** Analizar datos que var√≠an en el tiempo, identificar patrones y construir modelos predictivos basados en series temporales.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Fundamentos de series temporales**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Qu√© es una serie temporal y su importancia en Data Science.\n",
        "* **Lecci√≥n 1.2.** Componentes de una serie: tendencia, estacionalidad, ciclo y ruido.\n",
        "* **Lecci√≥n 1.3.** Tipos de series: aditivas y multiplicativas.\n",
        "* **Lecci√≥n 1.4.** Visualizaci√≥n y descomposici√≥n de series en Python (`statsmodels`).\n",
        "* **Lecci√≥n 1.5.** Transformaciones y limpieza de datos temporales.\n",
        "* **Lecci√≥n 1.6.** Resampling y manejo de fechas con `pandas`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. An√°lisis exploratorio de series temporales**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Autocorrelaci√≥n y funci√≥n de autocorrelaci√≥n parcial (ACF y PACF).\n",
        "* **Lecci√≥n 2.2.** Identificaci√≥n de patrones estacionales.\n",
        "* **Lecci√≥n 2.3.** Estacionariedad y pruebas de ra√≠z unitaria (ADF, KPSS).\n",
        "* **Lecci√≥n 2.4.** Diferenciaci√≥n y transformaci√≥n logar√≠tmica.\n",
        "* **Lecci√≥n 2.5.** Correlogramas y diagn√≥stico visual.\n",
        "* **Lecci√≥n 2.6.** Ejemplo pr√°ctico de an√°lisis exploratorio con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Modelos cl√°sicos: AR, MA, ARMA, ARIMA, SARIMA**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Introducci√≥n a los procesos autoregresivos y de medias m√≥viles.\n",
        "* **Lecci√≥n 3.2.** Modelos ARMA y su formulaci√≥n matem√°tica.\n",
        "* **Lecci√≥n 3.3.** Modelos ARIMA: integraci√≥n y diferenciaci√≥n.\n",
        "* **Lecci√≥n 3.4.** Modelos SARIMA: estacionalidad y par√°metros (p,d,q)(P,D,Q,s).\n",
        "* **Lecci√≥n 3.5.** Selecci√≥n de modelos mediante AIC y BIC.\n",
        "* **Lecci√≥n 3.6.** Implementaci√≥n pr√°ctica con `statsmodels` y predicci√≥n futura.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Modelos avanzados: Prophet, VAR y GARCH**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Introducci√≥n al modelo Prophet (Facebook).\n",
        "* **Lecci√≥n 4.2.** Modelado multivariante con VAR y VARMAX.\n",
        "* **Lecci√≥n 4.3.** Modelos GARCH para volatilidad financiera.\n",
        "* **Lecci√≥n 4.4.** Comparaci√≥n entre modelos ARIMA, Prophet y VAR.\n",
        "* **Lecci√≥n 4.5.** Evaluaci√≥n de precisi√≥n: MAPE, RMSE, MAE.\n",
        "* **Lecci√≥n 4.6.** Casos pr√°cticos de predicci√≥n econ√≥mica y de demanda.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Forecasting y validaci√≥n de modelos temporales**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Separaci√≥n de datos en entrenamiento y validaci√≥n temporal.\n",
        "* **Lecci√≥n 5.2.** Validaci√≥n cruzada para series (TimeSeriesSplit).\n",
        "* **Lecci√≥n 5.3.** Backtesting y rolling forecast origin.\n",
        "* **Lecci√≥n 5.4.** Interpretaci√≥n y comunicaci√≥n de predicciones.\n",
        "* **Lecci√≥n 5.5.** Integraci√≥n de predicciones en dashboards o pipelines ML.\n",
        "* **Lecci√≥n 5.6.** Proyecto pr√°ctico de forecasting con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Introducci√≥n al Deep Learning para series temporales**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Limitaciones de los modelos cl√°sicos.\n",
        "* **Lecci√≥n 6.2.** Redes neuronales recurrentes (RNN) y su arquitectura.\n",
        "* **Lecci√≥n 6.3.** LSTM y GRU para predicci√≥n de series.\n",
        "* **Lecci√≥n 6.4.** Preparaci√≥n de datos secuenciales con `TensorFlow/Keras`.\n",
        "* **Lecci√≥n 6.5.** Evaluaci√≥n y comparaci√≥n con modelos tradicionales.\n",
        "* **Lecci√≥n 6.6.** Ejemplo pr√°ctico de predicci√≥n con LSTM.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. T√©cnicas de Muestreo Avanzadas y Bootstrapping**\n",
        "\n",
        "**Objetivo:** Profundizar en t√©cnicas modernas de muestreo, estimaci√≥n por remuestreo y sus aplicaciones en la inferencia estad√≠stica y el aprendizaje autom√°tico.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Repaso y fundamentos del muestreo**\n",
        "\n",
        "* **Lecci√≥n 1.1.** Conceptos clave: poblaci√≥n, muestra, error muestral y sesgo.\n",
        "* **Lecci√≥n 1.2.** Ventajas y limitaciones del muestreo cl√°sico.\n",
        "* **Lecci√≥n 1.3.** Revisi√≥n de m√©todos de muestreo aleatorio y estratificado.\n",
        "* **Lecci√≥n 1.4.** Problemas pr√°cticos de representatividad en grandes datos.\n",
        "* **Lecci√≥n 1.5.** Introducci√≥n al remuestreo y su motivaci√≥n.\n",
        "* **Lecci√≥n 1.6.** Ejemplos de muestreo con `numpy` y `pandas`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. T√©cnicas de remuestreo: Jackknife, Bootstrap y Permutaciones**\n",
        "\n",
        "* **Lecci√≥n 2.1.** Idea general del remuestreo: generar nuevas muestras a partir de los datos observados.\n",
        "* **Lecci√≥n 2.2.** M√©todo Jackknife: estimaci√≥n del sesgo y la varianza.\n",
        "* **Lecci√≥n 2.3.** M√©todo Bootstrap: concepto, fundamentos te√≥ricos y ventajas.\n",
        "* **Lecci√≥n 2.4.** Bootstrapping param√©trico y no param√©trico.\n",
        "* **Lecci√≥n 2.5.** Pruebas de permutaci√≥n y su aplicaci√≥n en contrastes de hip√≥tesis.\n",
        "* **Lecci√≥n 2.6.** Implementaci√≥n de remuestreo con `scipy` y `sklearn.utils.resample`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Aplicaciones del Bootstrap en inferencia estad√≠stica**\n",
        "\n",
        "* **Lecci√≥n 3.1.** Estimaci√≥n de intervalos de confianza por Bootstrapping.\n",
        "* **Lecci√≥n 3.2.** Estimaci√≥n del error est√°ndar y sesgo de un estimador.\n",
        "* **Lecci√≥n 3.3.** Comparaci√≥n entre m√©todos bootstrap y aproximaciones normales.\n",
        "* **Lecci√≥n 3.4.** Visualizaci√≥n de distribuciones bootstrap.\n",
        "* **Lecci√≥n 3.5.** Ejemplo pr√°ctico: estimar la media y la mediana con Bootstrap.\n",
        "* **Lecci√≥n 3.6.** Casos de uso en Data Science (muestreo en datasets grandes).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Validaci√≥n estad√≠stica mediante remuestreo**\n",
        "\n",
        "* **Lecci√≥n 4.1.** Validaci√≥n cruzada y su relaci√≥n con el Bootstrap.\n",
        "* **Lecci√≥n 4.2.** Bootstrap .632 y su uso en modelos predictivos.\n",
        "* **Lecci√≥n 4.3.** Bagging: relaci√≥n entre Bootstrap y modelos de ensamblado.\n",
        "* **Lecci√≥n 4.4.** Comparaci√≥n de modelos mediante remuestreo.\n",
        "* **Lecci√≥n 4.5.** M√©tricas de estabilidad de modelos y estimadores.\n",
        "* **Lecci√≥n 4.6.** Implementaci√≥n pr√°ctica en `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. T√©cnicas avanzadas de muestreo en Big Data**\n",
        "\n",
        "* **Lecci√≥n 5.1.** Submuestreo aleatorio y estratificado en datasets grandes.\n",
        "* **Lecci√≥n 5.2.** Muestreo ponderado y muestreo por importancia.\n",
        "* **Lecci√≥n 5.3.** Muestreo secuencial y adaptativo.\n",
        "* **Lecci√≥n 5.4.** Reservoir sampling y algoritmos eficientes para flujos de datos.\n",
        "* **Lecci√≥n 5.5.** Uso de muestreo en pipelines de Machine Learning.\n",
        "* **Lecci√≥n 5.6.** Ejemplo pr√°ctico con datos masivos simulados en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Aplicaciones integradas y casos pr√°cticos**\n",
        "\n",
        "* **Lecci√≥n 6.1.** Bootstrapping aplicado a regresi√≥n lineal y log√≠stica.\n",
        "* **Lecci√≥n 6.2.** Estimaci√≥n de intervalos de predicci√≥n por remuestreo.\n",
        "* **Lecci√≥n 6.3.** Validaci√≥n de modelos ensemble con bagging y random forest.\n",
        "* **Lecci√≥n 6.4.** Bootstrap en estimaciones bayesianas aproximadas.\n",
        "* **Lecci√≥n 6.5.** Comparaci√≥n emp√≠rica: muestreo tradicional vs Bootstrap.\n",
        "* **Lecci√≥n 6.6.** Proyecto final: construcci√≥n de un estimador bootstrap personalizado en Python.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TWvB0jdjCeA6"
      }
    }
  ]
}