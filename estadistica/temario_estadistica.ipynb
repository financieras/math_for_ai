{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVdTqke64YPxqvg0mOVsFk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/temario_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧭 **Programa de Estadística para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estadística Descriptiva**\n",
        "\n",
        "**Objetivo:** Comprender los tipos de datos, su descripción y visualización inicial.\n",
        "\n",
        "1. **Tema 1.** Conceptos básicos: población, muestra, variables, tipos y escalas de medición.\n",
        "2. **Tema 2.** Medidas de tendencia central: media, mediana, moda.\n",
        "3. **Tema 3.** Medidas de dispersión: rango, varianza, desviación estándar, coeficiente de variación.\n",
        "4. **Tema 4.** Medidas de posición y forma: percentiles, cuartiles, asimetría y curtosis.\n",
        "5. **Tema 5.** Estadística bivariante: covarianza, correlación (Pearson, Spearman).\n",
        "6. **Tema 6.** Visualización y análisis exploratorio de datos (EDA): histogramas, boxplots, scatter plots, outliers.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad y Distribuciones**\n",
        "\n",
        "**Objetivo:** Entender la incertidumbre y las distribuciones que modelan fenómenos aleatorios.\n",
        "\n",
        "1. **Tema 1.** Conceptos de probabilidad: espacio muestral, eventos, independencia, probabilidad condicional.\n",
        "2. **Tema 2.** Teorema de Bayes e interpretación práctica.\n",
        "3. **Tema 3.** Variables aleatorias: discretas y continuas, funciones de probabilidad y densidad.\n",
        "4. **Tema 4.** Distribuciones discretas: Bernoulli, Binomial, Poisson.\n",
        "5. **Tema 5.** Distribuciones continuas: Uniforme, Normal, Exponencial, t-Student, Chi-cuadrado, F.\n",
        "6. **Tema 6.** Esperanza, varianza, covarianza y Teorema del Límite Central.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Inferencia Estadística**\n",
        "\n",
        "**Objetivo:** Extraer conclusiones sobre poblaciones a partir de muestras.\n",
        "\n",
        "1. **Tema 1.** Muestreo y sesgos: métodos de muestreo y error muestral.\n",
        "2. **Tema 2.** Distribuciones muestrales y estimadores (insesgados, eficientes, consistentes).\n",
        "3. **Tema 3.** Intervalos de confianza para medias y proporciones.\n",
        "4. **Tema 4.** Pruebas de hipótesis: hipótesis nula/alternativa, p-valor, errores tipo I y II.\n",
        "5. **Tema 5.** Tests paramétricos: t-test, ANOVA.\n",
        "6. **Tema 6.** Tests no paramétricos: chi-cuadrado, Mann-Whitney, Kruskal-Wallis.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Modelos Estadísticos y Regresión**\n",
        "\n",
        "**Objetivo:** Modelar relaciones entre variables y sentar las bases de los algoritmos de ML.\n",
        "\n",
        "1. **Tema 1.** Correlación vs causalidad.\n",
        "2. **Tema 2.** Regresión lineal simple: estimación por mínimos cuadrados, interpretación, supuestos.\n",
        "3. **Tema 3.** Regresión múltiple: multicolinealidad, selección de variables, diagnóstico de residuos.\n",
        "4. **Tema 4.** Regresión logística: clasificación binaria, odds ratio, métricas básicas (precisión, recall, F1).\n",
        "5. **Tema 5.** Regularización: Ridge, Lasso y Elastic Net.\n",
        "6. **Tema 6.** Modelos lineales generalizados (GLM): visión general.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. Métodos de Validación y Evaluación de Modelos**\n",
        "\n",
        "**Objetivo:** Aplicar principios estadísticos para evaluar y validar modelos predictivos.\n",
        "\n",
        "1. **Tema 1.** Partición de datos: train/test/validation, muestreo estratificado.\n",
        "2. **Tema 2.** Validación cruzada (K-fold, Leave-One-Out).\n",
        "3. **Tema 3.** Bootstrapping y Jackknife: remuestreo y estimación de incertidumbre.\n",
        "4. **Tema 4.** Métricas de evaluación: MSE, RMSE, MAE, R², ROC, AUC, Precision-Recall.\n",
        "5. **Tema 5.** Sesgo, varianza, overfitting y underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. Análisis Multivariante y Series Temporales**\n",
        "\n",
        "**Objetivo:** Analizar datos complejos y dependientes del tiempo.\n",
        "\n",
        "1. **Tema 1.** Análisis de componentes principales (PCA) y reducción de dimensionalidad.\n",
        "2. **Tema 2.** Clustering: K-means, clustering jerárquico, evaluación de clústeres.\n",
        "3. **Tema 3.** Análisis factorial y discriminante.\n",
        "4. **Tema 4.** Series temporales: componentes, estacionariedad, autocorrelación.\n",
        "5. **Tema 5.** Modelos ARIMA y su interpretación.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. Enfoque Bayesiano y Aplicaciones en ML**\n",
        "\n",
        "**Objetivo:** Comprender la inferencia bayesiana y su papel en Machine Learning.\n",
        "\n",
        "1. **Tema 1.** Paradigma bayesiano vs frecuentista.\n",
        "2. **Tema 2.** Distribuciones a priori, verosimilitud y posterior.\n",
        "3. **Tema 3.** Inferencia bayesiana y ejemplos simples.\n",
        "4. **Tema 4.** Clasificador Naive Bayes y aplicaciones prácticas.\n",
        "5. **Tema 5.** Introducción a MCMC y herramientas como PyMC.\n"
      ],
      "metadata": {
        "id": "u7ecmr68-m92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧭 **Programa de Estadística para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estadística Descriptiva**\n",
        "\n",
        "**Objetivo:** Comprender los tipos de datos, su descripción y visualización inicial.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Conceptos básicos: población, muestra, variables, tipos y escalas de medición**\n",
        "\n",
        "* **Lección 1.1.** ¿Qué es la estadística? Ramas descriptiva e inferencial.\n",
        "* **Lección 1.2.** Conceptos fundamentales: población, muestra, parámetro y estadístico.\n",
        "* **Lección 1.3.** Tipos de estudios: observacional vs experimental.\n",
        "* **Lección 1.4.** Tipos de variables: cualitativas, cuantitativas discretas y continuas.\n",
        "* **Lección 1.5.** Escalas de medición: nominal, ordinal, de intervalo y de razón.\n",
        "* **Lección 1.6.** Organización y presentación de datos: tablas de frecuencias y porcentajes.\n",
        "* **Lección 1.7.** Introducción al análisis de datos con Python (pandas y numpy).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Medidas de tendencia central: media, mediana, moda**\n",
        "\n",
        "* **Lección 2.1.** Concepto y utilidad de las medidas de tendencia central.\n",
        "* **Lección 2.2.** Cálculo de la media aritmética, ponderada y geométrica.\n",
        "* **Lección 2.3.** Cálculo e interpretación de la mediana.\n",
        "* **Lección 2.4.** Moda: definición, tipos y limitaciones.\n",
        "* **Lección 2.5.** Comparación entre media, mediana y moda (efecto de valores atípicos).\n",
        "* **Lección 2.6.** Implementación en Python: funciones `mean()`, `median()`, `mode()`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Medidas de dispersión: rango, varianza, desviación estándar, coeficiente de variación**\n",
        "\n",
        "* **Lección 3.1.** Concepto de dispersión y su importancia.\n",
        "* **Lección 3.2.** Cálculo e interpretación del rango y rango intercuartílico (IQR).\n",
        "* **Lección 3.3.** Varianza y desviación estándar: significado y fórmulas.\n",
        "* **Lección 3.4.** Coeficiente de variación y su interpretación relativa.\n",
        "* **Lección 3.5.** Relación entre dispersión y estabilidad de datos.\n",
        "* **Lección 3.6.** Cálculo con Python: `var()`, `std()`, `quantile()`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Medidas de posición y forma: percentiles, cuartiles, asimetría y curtosis**\n",
        "\n",
        "* **Lección 4.1.** Concepto de posición relativa en un conjunto de datos.\n",
        "* **Lección 4.2.** Percentiles y cuartiles: interpretación y cálculo.\n",
        "* **Lección 4.3.** Diagramas de caja y bigotes (boxplots).\n",
        "* **Lección 4.4.** Asimetría (skewness): tipos e interpretación.\n",
        "* **Lección 4.5.** Curtosis: leptocúrtica, mesocúrtica y platicúrtica.\n",
        "* **Lección 4.6.** Cálculo e interpretación práctica con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Estadística bivariante: covarianza, correlación (Pearson, Spearman)**\n",
        "\n",
        "* **Lección 5.1.** Concepto de relación entre dos variables.\n",
        "* **Lección 5.2.** Covarianza: fórmula e interpretación.\n",
        "* **Lección 5.3.** Coeficiente de correlación de Pearson.\n",
        "* **Lección 5.4.** Correlación de Spearman (rangos).\n",
        "* **Lección 5.5.** Diferencias entre correlación y causalidad.\n",
        "* **Lección 5.6.** Matriz de correlaciones y mapa de calor en Python (Seaborn/Matplotlib).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Visualización y análisis exploratorio de datos (EDA): histogramas, boxplots, scatter plots, outliers**\n",
        "\n",
        "* **Lección 6.1.** Importancia del EDA en Data Science.\n",
        "* **Lección 6.2.** Histogramas y densidades: forma y dispersión de la distribución.\n",
        "* **Lección 6.3.** Diagramas de caja, violín y barras.\n",
        "* **Lección 6.4.** Gráficos de dispersión (scatter plots) y relación entre variables.\n",
        "* **Lección 6.5.** Detección de outliers: métodos z-score e IQR.\n",
        "* **Lección 6.6.** Herramientas de visualización en Python: Matplotlib, Seaborn, Plotly.\n",
        "* **Lección 6.7.** Proyecto práctico: análisis exploratorio de un dataset real (ej. Iris o Titanic).\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad y Distribuciones**\n",
        "\n",
        "**Objetivo:** Entender la incertidumbre y las distribuciones que modelan fenómenos aleatorios.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Conceptos de probabilidad: espacio muestral, eventos, independencia, probabilidad condicional**\n",
        "\n",
        "* **Lección 1.1.** Concepto de experimento aleatorio y espacio muestral.\n",
        "* **Lección 1.2.** Eventos y operaciones entre eventos (unión, intersección, complemento).\n",
        "* **Lección 1.3.** Definiciones clásica, frecuentista y axiomática de probabilidad.\n",
        "* **Lección 1.4.** Propiedades básicas de la probabilidad.\n",
        "* **Lección 1.5.** Independencia y dependencia de eventos.\n",
        "* **Lección 1.6.** Probabilidad condicional y regla de la multiplicación.\n",
        "* **Lección 1.7.** Ejercicios prácticos con Python y simulaciones (lanzamiento de dados y monedas).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Teorema de Bayes e interpretación práctica**\n",
        "\n",
        "* **Lección 2.1.** Idea fundamental del razonamiento bayesiano.\n",
        "* **Lección 2.2.** Derivación y enunciado del Teorema de Bayes.\n",
        "* **Lección 2.3.** Probabilidad total y árboles de probabilidad.\n",
        "* **Lección 2.4.** Aplicaciones prácticas: diagnóstico médico, detección de spam.\n",
        "* **Lección 2.5.** Simulación del Teorema de Bayes en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Variables aleatorias: discretas y continuas, funciones de probabilidad y densidad**\n",
        "\n",
        "* **Lección 3.1.** Concepto de variable aleatoria y su función de probabilidad.\n",
        "* **Lección 3.2.** Función de distribución acumulada (FDA).\n",
        "* **Lección 3.3.** Diferencias entre variables discretas y continuas.\n",
        "* **Lección 3.4.** Cálculo de esperanza, varianza y desviación típica.\n",
        "* **Lección 3.5.** Representación gráfica de distribuciones discretas y continuas.\n",
        "* **Lección 3.6.** Implementación en Python: `numpy.random` y `scipy.stats`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Distribuciones discretas: Bernoulli, Binomial, Poisson**\n",
        "\n",
        "* **Lección 4.1.** Distribución de Bernoulli: definición y propiedades.\n",
        "* **Lección 4.2.** Distribución Binomial: probabilidad de éxitos y función de masa.\n",
        "* **Lección 4.3.** Distribución Poisson: conteo de eventos raros.\n",
        "* **Lección 4.4.** Relación entre Binomial y Poisson.\n",
        "* **Lección 4.5.** Aplicaciones prácticas: defectos en producción, llegadas en colas.\n",
        "* **Lección 4.6.** Simulación y visualización en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Distribuciones continuas: Uniforme, Normal, Exponencial, t-Student, Chi-cuadrado, F**\n",
        "\n",
        "* **Lección 5.1.** Distribución Uniforme: definición y ejemplos.\n",
        "* **Lección 5.2.** Distribución Normal: propiedades y regla del 68–95–99,7%.\n",
        "* **Lección 5.3.** Tipificación y uso de la distribución normal estándar.\n",
        "* **Lección 5.4.** Distribución Exponencial: tiempo entre eventos y memoria sin efecto.\n",
        "* **Lección 5.5.** Distribuciones t-Student, Chi-cuadrado y F: usos en inferencia.\n",
        "* **Lección 5.6.** Aplicaciones prácticas en Python y comparación de distribuciones.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Esperanza, varianza, covarianza y Teorema del Límite Central**\n",
        "\n",
        "* **Lección 6.1.** Esperanza matemática y propiedades lineales.\n",
        "* **Lección 6.2.** Varianza y covarianza: interpretación y fórmulas.\n",
        "* **Lección 6.3.** Propiedades de la varianza de combinaciones lineales.\n",
        "* **Lección 6.4.** Ley de los grandes números.\n",
        "* **Lección 6.5.** Teorema del Límite Central: enunciado e importancia en estadística.\n",
        "* **Lección 6.6.** Demostración empírica del Teorema del Límite Central con Python (simulaciones).\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Inferencia Estadística**\n",
        "\n",
        "**Objetivo:** Extraer conclusiones sobre poblaciones a partir de muestras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Muestreo y sesgos: métodos de muestreo y error muestral**\n",
        "\n",
        "* **Lección 1.1.** Concepto de muestreo y necesidad de inferencia.\n",
        "* **Lección 1.2.** Población, marco muestral y muestra representativa.\n",
        "* **Lección 1.3.** Tipos de muestreo: aleatorio simple, sistemático, estratificado, por conglomerados.\n",
        "* **Lección 1.4.** Tamaño muestral y error muestral.\n",
        "* **Lección 1.5.** Sesgos de selección y no respuesta.\n",
        "* **Lección 1.6.** Simulación del proceso de muestreo con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Distribuciones muestrales y estimadores (insesgados, eficientes, consistentes)**\n",
        "\n",
        "* **Lección 2.1.** Concepto de distribución muestral.\n",
        "* **Lección 2.2.** Distribución muestral de la media y de la proporción.\n",
        "* **Lección 2.3.** Propiedades de los estimadores: insesgadez, eficiencia, consistencia.\n",
        "* **Lección 2.4.** Errores estándar y su interpretación.\n",
        "* **Lección 2.5.** Ejemplos prácticos de distribuciones muestrales con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Intervalos de confianza para medias y proporciones**\n",
        "\n",
        "* **Lección 3.1.** Concepto de intervalo de confianza y nivel de confianza.\n",
        "* **Lección 3.2.** Intervalo de confianza para una media (σ conocida y desconocida).\n",
        "* **Lección 3.3.** Intervalo de confianza para una proporción.\n",
        "* **Lección 3.4.** Intervalos de confianza para diferencia de medias y proporciones.\n",
        "* **Lección 3.5.** Interpretación práctica y errores comunes.\n",
        "* **Lección 3.6.** Cálculo en Python con `scipy.stats` y comparación visual.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Pruebas de hipótesis: hipótesis nula/alternativa, p-valor, errores tipo I y II**\n",
        "\n",
        "* **Lección 4.1.** Fundamentos de la prueba de hipótesis: H₀ y H₁.\n",
        "* **Lección 4.2.** Tipos de errores (I y II) y potencia de una prueba.\n",
        "* **Lección 4.3.** Estadístico de prueba y regiones de rechazo.\n",
        "* **Lección 4.4.** Valor p e interpretación correcta.\n",
        "* **Lección 4.5.** Procedimiento paso a paso para realizar un test de hipótesis.\n",
        "* **Lección 4.6.** Ejercicios prácticos en Python: prueba de medias y proporciones.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Tests paramétricos: t-test, ANOVA**\n",
        "\n",
        "* **Lección 5.1.** Supuestos de los tests paramétricos.\n",
        "* **Lección 5.2.** Prueba t para una muestra y para dos muestras independientes.\n",
        "* **Lección 5.3.** Prueba t pareada (muestras relacionadas).\n",
        "* **Lección 5.4.** ANOVA de un factor: hipótesis, estadístico F e interpretación.\n",
        "* **Lección 5.5.** Comparaciones múltiples (Tukey HSD).\n",
        "* **Lección 5.6.** Implementación práctica con `scipy.stats` y `statsmodels`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Tests no paramétricos: chi-cuadrado, Mann-Whitney, Kruskal-Wallis**\n",
        "\n",
        "* **Lección 6.1.** Cuándo usar tests no paramétricos.\n",
        "* **Lección 6.2.** Test chi-cuadrado de independencia y de bondad de ajuste.\n",
        "* **Lección 6.3.** Prueba de Mann-Whitney U (dos muestras independientes).\n",
        "* **Lección 6.4.** Prueba de Kruskal-Wallis (más de dos muestras).\n",
        "* **Lección 6.5.** Comparación entre métodos paramétricos y no paramétricos.\n",
        "* **Lección 6.6.** Aplicaciones en Python con `scipy.stats`.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Modelos Estadísticos y Regresión**\n",
        "\n",
        "**Objetivo:** Modelar relaciones entre variables y realizar predicciones mediante técnicas de regresión.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Concepto de modelo estadístico y ajuste de modelos**\n",
        "\n",
        "* **Lección 1.1.** Qué es un modelo estadístico y su papel en el análisis de datos.\n",
        "* **Lección 1.2.** Tipos de modelos: deterministas vs. probabilísticos.\n",
        "* **Lección 1.3.** Etapas del modelado estadístico.\n",
        "* **Lección 1.4.** Medidas de ajuste: error cuadrático medio, R² y R² ajustado.\n",
        "* **Lección 1.5.** Overfitting y underfitting: diagnóstico y prevención.\n",
        "* **Lección 1.6.** Evaluación de modelos con datos de entrenamiento y prueba.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Regresión lineal simple**\n",
        "\n",
        "* **Lección 2.1.** Concepto y ecuación del modelo lineal simple.\n",
        "* **Lección 2.2.** Estimación de parámetros por mínimos cuadrados.\n",
        "* **Lección 2.3.** Interpretación de coeficientes y significado del intercepto.\n",
        "* **Lección 2.4.** Supuestos del modelo lineal.\n",
        "* **Lección 2.5.** Diagnóstico de residuos: homocedasticidad, normalidad, independencia.\n",
        "* **Lección 2.6.** Implementación en Python con `scikit-learn` y `statsmodels`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Regresión lineal múltiple**\n",
        "\n",
        "* **Lección 3.1.** Extensión del modelo a múltiples variables explicativas.\n",
        "* **Lección 3.2.** Multicolinealidad y su detección (VIF).\n",
        "* **Lección 3.3.** Selección de variables: métodos hacia adelante, hacia atrás y stepwise.\n",
        "* **Lección 3.4.** Evaluación del modelo múltiple: R² ajustado y AIC/BIC.\n",
        "* **Lección 3.5.** Interacción entre variables y términos polinómicos.\n",
        "* **Lección 3.6.** Ejemplo práctico completo en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Regresión logística y modelos para variables categóricas**\n",
        "\n",
        "* **Lección 4.1.** Concepto y función sigmoide.\n",
        "* **Lección 4.2.** Odds, log-odds y probabilidad.\n",
        "* **Lección 4.3.** Estimación de parámetros por máxima verosimilitud.\n",
        "* **Lección 4.4.** Evaluación del modelo: matriz de confusión, precisión, recall, F1-score.\n",
        "* **Lección 4.5.** Curva ROC y AUC.\n",
        "* **Lección 4.6.** Implementación práctica con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Diagnóstico y validación de modelos**\n",
        "\n",
        "* **Lección 5.1.** Supuestos y problemas comunes: multicolinealidad, outliers, leverage.\n",
        "* **Lección 5.2.** Métodos de validación cruzada (k-fold, leave-one-out).\n",
        "* **Lección 5.3.** Regularización: Ridge, Lasso y Elastic Net.\n",
        "* **Lección 5.4.** Comparación de modelos mediante métricas de error.\n",
        "* **Lección 5.5.** Interpretación de resultados y comunicación de modelos.\n",
        "* **Lección 5.6.** Ejercicios prácticos integrados con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. Análisis Multivariante**\n",
        "\n",
        "**Objetivo:** Analizar relaciones simultáneas entre múltiples variables y reducir la dimensionalidad de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Introducción al análisis multivariante**\n",
        "\n",
        "* **Lección 1.1.** Qué es el análisis multivariante y su importancia en Data Science.\n",
        "* **Lección 1.2.** Tipos de variables y estructuras de datos multivariantes.\n",
        "* **Lección 1.3.** Matriz de datos y matriz de covarianzas/correlaciones.\n",
        "* **Lección 1.4.** Escalado y normalización de variables.\n",
        "* **Lección 1.5.** Visualización multivariante: pairplots, mapas de calor y gráficos 3D.\n",
        "* **Lección 1.6.** Ejemplo introductorio en Python con `pandas` y `seaborn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Análisis de Componentes Principales (PCA)**\n",
        "\n",
        "* **Lección 2.1.** Motivación y fundamentos matemáticos del PCA.\n",
        "* **Lección 2.2.** Autovalores y autovectores: interpretación geométrica.\n",
        "* **Lección 2.3.** Varianza explicada y selección del número de componentes.\n",
        "* **Lección 2.4.** Proyección de los datos en los componentes principales.\n",
        "* **Lección 2.5.** Visualización de resultados: biplot y scree plot.\n",
        "* **Lección 2.6.** Implementación práctica con `scikit-learn` y `matplotlib`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Análisis de Factores (FA)**\n",
        "\n",
        "* **Lección 3.1.** Diferencias entre PCA y Análisis Factorial.\n",
        "* **Lección 3.2.** Modelo factorial común y comunalidades.\n",
        "* **Lección 3.3.** Métodos de extracción: componentes principales, máxima verosimilitud.\n",
        "* **Lección 3.4.** Rotación de factores: Varimax, Promax.\n",
        "* **Lección 3.5.** Interpretación de factores y cargas factoriales.\n",
        "* **Lección 3.6.** Ejemplo práctico con `factor_analyzer` en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Análisis de Conglomerados (Clustering)**\n",
        "\n",
        "* **Lección 4.1.** Concepto de agrupamiento y medidas de similitud/distancia.\n",
        "* **Lección 4.2.** Métodos jerárquicos: dendrogramas y linkage.\n",
        "* **Lección 4.3.** Métodos no jerárquicos: K-means y K-medoids.\n",
        "* **Lección 4.4.** Determinación del número óptimo de clusters (Elbow, Silhouette).\n",
        "* **Lección 4.5.** Visualización y análisis de clusters.\n",
        "* **Lección 4.6.** Aplicación práctica con `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Análisis Discriminante y Reducción de Dimensionalidad Supervisada**\n",
        "\n",
        "* **Lección 5.1.** Concepto de análisis discriminante lineal (LDA).\n",
        "* **Lección 5.2.** Funciones discriminantes y separación de grupos.\n",
        "* **Lección 5.3.** Comparación LDA vs PCA.\n",
        "* **Lección 5.4.** Análisis discriminante cuadrático (QDA).\n",
        "* **Lección 5.5.** Aplicación de LDA y QDA a conjuntos de datos reales.\n",
        "* **Lección 5.6.** Implementación con `scikit-learn` y comparación de rendimiento.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Técnicas avanzadas y aplicaciones en Machine Learning**\n",
        "\n",
        "* **Lección 6.1.** Reducción de dimensionalidad no lineal: t-SNE, UMAP.\n",
        "* **Lección 6.2.** Clustering jerárquico avanzado y DBSCAN.\n",
        "* **Lección 6.3.** Detección de outliers multivariantes.\n",
        "* **Lección 6.4.** Combinación de PCA y clustering.\n",
        "* **Lección 6.5.** Visualización de datos de alta dimensión.\n",
        "* **Lección 6.6.** Casos prácticos en Python con datasets del mundo real.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. Series Temporales y Análisis Predictivo**\n",
        "\n",
        "**Objetivo:** Analizar datos que varían en el tiempo, identificar patrones y construir modelos predictivos basados en series temporales.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Fundamentos de series temporales**\n",
        "\n",
        "* **Lección 1.1.** Qué es una serie temporal y su importancia en Data Science.\n",
        "* **Lección 1.2.** Componentes de una serie: tendencia, estacionalidad, ciclo y ruido.\n",
        "* **Lección 1.3.** Tipos de series: aditivas y multiplicativas.\n",
        "* **Lección 1.4.** Visualización y descomposición de series en Python (`statsmodels`).\n",
        "* **Lección 1.5.** Transformaciones y limpieza de datos temporales.\n",
        "* **Lección 1.6.** Resampling y manejo de fechas con `pandas`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Análisis exploratorio de series temporales**\n",
        "\n",
        "* **Lección 2.1.** Autocorrelación y función de autocorrelación parcial (ACF y PACF).\n",
        "* **Lección 2.2.** Identificación de patrones estacionales.\n",
        "* **Lección 2.3.** Estacionariedad y pruebas de raíz unitaria (ADF, KPSS).\n",
        "* **Lección 2.4.** Diferenciación y transformación logarítmica.\n",
        "* **Lección 2.5.** Correlogramas y diagnóstico visual.\n",
        "* **Lección 2.6.** Ejemplo práctico de análisis exploratorio con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Modelos clásicos: AR, MA, ARMA, ARIMA, SARIMA**\n",
        "\n",
        "* **Lección 3.1.** Introducción a los procesos autoregresivos y de medias móviles.\n",
        "* **Lección 3.2.** Modelos ARMA y su formulación matemática.\n",
        "* **Lección 3.3.** Modelos ARIMA: integración y diferenciación.\n",
        "* **Lección 3.4.** Modelos SARIMA: estacionalidad y parámetros (p,d,q)(P,D,Q,s).\n",
        "* **Lección 3.5.** Selección de modelos mediante AIC y BIC.\n",
        "* **Lección 3.6.** Implementación práctica con `statsmodels` y predicción futura.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Modelos avanzados: Prophet, VAR y GARCH**\n",
        "\n",
        "* **Lección 4.1.** Introducción al modelo Prophet (Facebook).\n",
        "* **Lección 4.2.** Modelado multivariante con VAR y VARMAX.\n",
        "* **Lección 4.3.** Modelos GARCH para volatilidad financiera.\n",
        "* **Lección 4.4.** Comparación entre modelos ARIMA, Prophet y VAR.\n",
        "* **Lección 4.5.** Evaluación de precisión: MAPE, RMSE, MAE.\n",
        "* **Lección 4.6.** Casos prácticos de predicción económica y de demanda.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Forecasting y validación de modelos temporales**\n",
        "\n",
        "* **Lección 5.1.** Separación de datos en entrenamiento y validación temporal.\n",
        "* **Lección 5.2.** Validación cruzada para series (TimeSeriesSplit).\n",
        "* **Lección 5.3.** Backtesting y rolling forecast origin.\n",
        "* **Lección 5.4.** Interpretación y comunicación de predicciones.\n",
        "* **Lección 5.5.** Integración de predicciones en dashboards o pipelines ML.\n",
        "* **Lección 5.6.** Proyecto práctico de forecasting con Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Introducción al Deep Learning para series temporales**\n",
        "\n",
        "* **Lección 6.1.** Limitaciones de los modelos clásicos.\n",
        "* **Lección 6.2.** Redes neuronales recurrentes (RNN) y su arquitectura.\n",
        "* **Lección 6.3.** LSTM y GRU para predicción de series.\n",
        "* **Lección 6.4.** Preparación de datos secuenciales con `TensorFlow/Keras`.\n",
        "* **Lección 6.5.** Evaluación y comparación con modelos tradicionales.\n",
        "* **Lección 6.6.** Ejemplo práctico de predicción con LSTM.\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. Técnicas de Muestreo Avanzadas y Bootstrapping**\n",
        "\n",
        "**Objetivo:** Profundizar en técnicas modernas de muestreo, estimación por remuestreo y sus aplicaciones en la inferencia estadística y el aprendizaje automático.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 1. Repaso y fundamentos del muestreo**\n",
        "\n",
        "* **Lección 1.1.** Conceptos clave: población, muestra, error muestral y sesgo.\n",
        "* **Lección 1.2.** Ventajas y limitaciones del muestreo clásico.\n",
        "* **Lección 1.3.** Revisión de métodos de muestreo aleatorio y estratificado.\n",
        "* **Lección 1.4.** Problemas prácticos de representatividad en grandes datos.\n",
        "* **Lección 1.5.** Introducción al remuestreo y su motivación.\n",
        "* **Lección 1.6.** Ejemplos de muestreo con `numpy` y `pandas`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 2. Técnicas de remuestreo: Jackknife, Bootstrap y Permutaciones**\n",
        "\n",
        "* **Lección 2.1.** Idea general del remuestreo: generar nuevas muestras a partir de los datos observados.\n",
        "* **Lección 2.2.** Método Jackknife: estimación del sesgo y la varianza.\n",
        "* **Lección 2.3.** Método Bootstrap: concepto, fundamentos teóricos y ventajas.\n",
        "* **Lección 2.4.** Bootstrapping paramétrico y no paramétrico.\n",
        "* **Lección 2.5.** Pruebas de permutación y su aplicación en contrastes de hipótesis.\n",
        "* **Lección 2.6.** Implementación de remuestreo con `scipy` y `sklearn.utils.resample`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 3. Aplicaciones del Bootstrap en inferencia estadística**\n",
        "\n",
        "* **Lección 3.1.** Estimación de intervalos de confianza por Bootstrapping.\n",
        "* **Lección 3.2.** Estimación del error estándar y sesgo de un estimador.\n",
        "* **Lección 3.3.** Comparación entre métodos bootstrap y aproximaciones normales.\n",
        "* **Lección 3.4.** Visualización de distribuciones bootstrap.\n",
        "* **Lección 3.5.** Ejemplo práctico: estimar la media y la mediana con Bootstrap.\n",
        "* **Lección 3.6.** Casos de uso en Data Science (muestreo en datasets grandes).\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 4. Validación estadística mediante remuestreo**\n",
        "\n",
        "* **Lección 4.1.** Validación cruzada y su relación con el Bootstrap.\n",
        "* **Lección 4.2.** Bootstrap .632 y su uso en modelos predictivos.\n",
        "* **Lección 4.3.** Bagging: relación entre Bootstrap y modelos de ensamblado.\n",
        "* **Lección 4.4.** Comparación de modelos mediante remuestreo.\n",
        "* **Lección 4.5.** Métricas de estabilidad de modelos y estimadores.\n",
        "* **Lección 4.6.** Implementación práctica en `scikit-learn`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 5. Técnicas avanzadas de muestreo en Big Data**\n",
        "\n",
        "* **Lección 5.1.** Submuestreo aleatorio y estratificado en datasets grandes.\n",
        "* **Lección 5.2.** Muestreo ponderado y muestreo por importancia.\n",
        "* **Lección 5.3.** Muestreo secuencial y adaptativo.\n",
        "* **Lección 5.4.** Reservoir sampling y algoritmos eficientes para flujos de datos.\n",
        "* **Lección 5.5.** Uso de muestreo en pipelines de Machine Learning.\n",
        "* **Lección 5.6.** Ejemplo práctico con datos masivos simulados en Python.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tema 6. Aplicaciones integradas y casos prácticos**\n",
        "\n",
        "* **Lección 6.1.** Bootstrapping aplicado a regresión lineal y logística.\n",
        "* **Lección 6.2.** Estimación de intervalos de predicción por remuestreo.\n",
        "* **Lección 6.3.** Validación de modelos ensemble con bagging y random forest.\n",
        "* **Lección 6.4.** Bootstrap en estimaciones bayesianas aproximadas.\n",
        "* **Lección 6.5.** Comparación empírica: muestreo tradicional vs Bootstrap.\n",
        "* **Lección 6.6.** Proyecto final: construcción de un estimador bootstrap personalizado en Python.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TWvB0jdjCeA6"
      }
    }
  ]
}