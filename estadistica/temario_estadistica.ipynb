{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv0HDhKv5tQXL/PpqDojfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/temario_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Programa de Estad铆stica para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estad铆stica Descriptiva**\n",
        "\n",
        "**Objetivo:** Dominar los conceptos b谩sicos y las t茅cnicas de descripci贸n de datos.\n",
        "\n",
        "### **Tema 1. Conceptos fundamentales**\n",
        "- **Lecci贸n 1.1.** Poblaci贸n, muestra y tipos de variables\n",
        "- **Lecci贸n 1.2.** Escalas de medici贸n: nominal, ordinal, intervalo y raz贸n\n",
        "- **Lecci贸n 1.3.** Muestreo y representatividad\n",
        "\n",
        "### **Tema 2. Medidas descriptivas univariantes**\n",
        "- **Lecci贸n 2.1.** Medidas de tendencia central: media, mediana, moda\n",
        "- **Lecci贸n 2.2.** Medidas de dispersi贸n: rango, varianza, desviaci贸n est谩ndar, IQR\n",
        "- **Lecci贸n 2.3.** Medidas de forma: asimetr铆a y curtosis\n",
        "- **Lecci贸n 2.4.** Percentiles y cuartiles\n",
        "\n",
        "### **Tema 3. An谩lisis descriptivo bivariante**\n",
        "- **Lecci贸n 3.1.** Covarianza y su interpretaci贸n\n",
        "- **Lecci贸n 3.2.** Correlaci贸n de Pearson y Spearman\n",
        "- **Lecci贸n 3.3.** Tablas de contingencia y asociaci贸n categ贸rica\n",
        "\n",
        "### **Tema 4. An谩lisis Exploratorio de Datos (EDA)**\n",
        "- **Lecci贸n 4.1.** Visualizaciones: histogramas, boxplots, scatter plots\n",
        "- **Lecci贸n 4.2.** Detecci贸n y tratamiento de outliers\n",
        "- **Lecci贸n 4.3.** Transformaciones de datos\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad**\n",
        "\n",
        "**Objetivo:** Comprender los fundamentos de la probabilidad y su aplicaci贸n pr谩ctica.\n",
        "\n",
        "### **Tema 5. Teor铆a de probabilidad**\n",
        "- **Lecci贸n 5.1.** Experimentos aleatorios, espacio muestral y eventos\n",
        "- **Lecci贸n 5.2.** Reglas de probabilidad: suma y multiplicaci贸n\n",
        "- **Lecci贸n 5.3.** Probabilidad condicional e independencia\n",
        "- **Lecci贸n 5.4.** Teorema de Bayes y aplicaciones\n",
        "\n",
        "### **Tema 6. Variables aleatorias**\n",
        "- **Lecci贸n 6.1.** Variables aleatorias discretas y continuas\n",
        "- **Lecci贸n 6.2.** Funci贸n de probabilidad y funci贸n de densidad\n",
        "- **Lecci贸n 6.3.** Esperanza matem谩tica y varianza\n",
        "- **Lecci贸n 6.4.** Covarianza y correlaci贸n entre variables aleatorias\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Distribuciones de Probabilidad**\n",
        "\n",
        "**Objetivo:** Conocer las distribuciones fundamentales para modelar datos.\n",
        "\n",
        "### **Tema 7. Distribuciones discretas**\n",
        "- **Lecci贸n 7.1.** Distribuci贸n Bernoulli\n",
        "- **Lecci贸n 7.2.** Distribuci贸n Binomial\n",
        "- **Lecci贸n 7.3.** Distribuci贸n Poisson\n",
        "- **Lecci贸n 7.4.** Aplicaciones pr谩cticas en Data Science\n",
        "\n",
        "### **Tema 8. Distribuciones continuas**\n",
        "- **Lecci贸n 8.1.** Distribuci贸n Uniforme\n",
        "- **Lecci贸n 8.2.** Distribuci贸n Normal: propiedades y estandarizaci贸n\n",
        "- **Lecci贸n 8.3.** Distribuci贸n Exponencial\n",
        "- **Lecci贸n 8.4.** Teorema del L铆mite Central\n",
        "\n",
        "### **Tema 9. Distribuciones muestrales**\n",
        "- **Lecci贸n 9.1.** Distribuci贸n t de Student\n",
        "- **Lecci贸n 9.2.** Distribuci贸n Chi-cuadrado\n",
        "- **Lecci贸n 9.3.** Distribuci贸n F\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Inferencia Estad铆stica**\n",
        "\n",
        "**Objetivo:** Realizar inferencias sobre poblaciones a partir de muestras.\n",
        "\n",
        "### **Tema 10. Estimaci贸n de par谩metros**\n",
        "- **Lecci贸n 10.1.** Estimadores: propiedades (insesgados, eficientes, consistentes)\n",
        "- **Lecci贸n 10.2.** Estimaci贸n puntual\n",
        "- **Lecci贸n 10.3.** Intervalos de confianza para medias\n",
        "- **Lecci贸n 10.4.** Intervalos de confianza para proporciones\n",
        "\n",
        "### **Tema 11. Pruebas de hip贸tesis**\n",
        "- **Lecci贸n 11.1.** Hip贸tesis nula y alternativa\n",
        "- **Lecci贸n 11.2.** Nivel de significancia, p-valor y regi贸n cr铆tica\n",
        "- **Lecci贸n 11.3.** Errores tipo I y tipo II, potencia del test\n",
        "- **Lecci贸n 11.4.** Pruebas para una y dos muestras\n",
        "\n",
        "### **Tema 12. Tests estad铆sticos**\n",
        "- **Lecci贸n 12.1.** Test t de Student (una y dos muestras)\n",
        "- **Lecci贸n 12.2.** ANOVA: comparaci贸n de m煤ltiples grupos\n",
        "- **Lecci贸n 12.3.** Test Chi-cuadrado de independencia\n",
        "- **Lecci贸n 12.4.** Tests no param茅tricos: Mann-Whitney, Kruskal-Wallis\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. Regresi贸n y Modelos Lineales**\n",
        "\n",
        "**Objetivo:** Construir modelos predictivos mediante regresi贸n.\n",
        "\n",
        "### **Tema 13. Regresi贸n lineal simple**\n",
        "- **Lecci贸n 13.1.** Modelo de regresi贸n lineal: estimaci贸n por m铆nimos cuadrados\n",
        "- **Lecci贸n 13.2.** Interpretaci贸n de coeficientes\n",
        "- **Lecci贸n 13.3.** Supuestos del modelo lineal\n",
        "- **Lecci贸n 13.4.** Diagn贸stico de residuos\n",
        "\n",
        "### **Tema 14. Regresi贸n lineal m煤ltiple**\n",
        "- **Lecci贸n 14.1.** Modelo de regresi贸n m煤ltiple\n",
        "- **Lecci贸n 14.2.** Multicolinealidad: detecci贸n y soluciones\n",
        "- **Lecci贸n 14.3.** Selecci贸n de variables\n",
        "- **Lecci贸n 14.4.** M茅tricas de evaluaci贸n: R虏, R虏 ajustado, MSE, RMSE\n",
        "\n",
        "### **Tema 15. Regresi贸n log铆stica**\n",
        "- **Lecci贸n 15.1.** Modelo de regresi贸n log铆stica para clasificaci贸n binaria\n",
        "- **Lecci贸n 15.2.** Interpretaci贸n: odds ratio y probabilidades\n",
        "- **Lecci贸n 15.3.** Evaluaci贸n: matriz de confusi贸n, accuracy, precision, recall, F1-score\n",
        "- **Lecci贸n 15.4.** Curva ROC y AUC\n",
        "\n",
        "### **Tema 16. Regularizaci贸n**\n",
        "- **Lecci贸n 16.1.** Overfitting y la necesidad de regularizaci贸n\n",
        "- **Lecci贸n 16.2.** Regresi贸n Ridge (L2)\n",
        "- **Lecci贸n 16.3.** Regresi贸n Lasso (L1)\n",
        "- **Lecci贸n 16.4.** Elastic Net\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. Validaci贸n y Evaluaci贸n de Modelos**\n",
        "\n",
        "**Objetivo:** Aplicar t茅cnicas robustas de validaci贸n para modelos predictivos.\n",
        "\n",
        "### **Tema 17. Estrategias de validaci贸n**\n",
        "- **Lecci贸n 17.1.** Partici贸n de datos: train, validation, test\n",
        "- **Lecci贸n 17.2.** Validaci贸n cruzada: K-fold, stratified K-fold\n",
        "- **Lecci贸n 17.3.** Leave-One-Out Cross-Validation (LOOCV)\n",
        "- **Lecci贸n 17.4.** Bootstrapping\n",
        "\n",
        "### **Tema 18. Sesgo-varianza y generalizaci贸n**\n",
        "- **Lecci贸n 18.1.** Trade-off entre sesgo y varianza\n",
        "- **Lecci贸n 18.2.** Underfitting y overfitting\n",
        "- **Lecci贸n 18.3.** Curvas de aprendizaje\n",
        "- **Lecci贸n 18.4.** Estrategias para mejorar la generalizaci贸n\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. An谩lisis Multivariante**\n",
        "\n",
        "**Objetivo:** Trabajar con datos de m煤ltiples dimensiones.\n",
        "\n",
        "### **Tema 19. Reducci贸n de dimensionalidad**\n",
        "- **Lecci贸n 19.1.** An谩lisis de Componentes Principales (PCA)\n",
        "- **Lecci贸n 19.2.** Interpretaci贸n de componentes principales\n",
        "- **Lecci贸n 19.3.** Varianza explicada y selecci贸n de componentes\n",
        "- **Lecci贸n 19.4.** Aplicaciones en preprocesamiento de datos\n",
        "\n",
        "### **Tema 20. Clustering**\n",
        "- **Lecci贸n 20.1.** Clustering como aprendizaje no supervisado\n",
        "- **Lecci贸n 20.2.** K-means: algoritmo y criterios de convergencia\n",
        "- **Lecci贸n 20.3.** Clustering jer谩rquico: aglomerativo y divisivo\n",
        "- **Lecci贸n 20.4.** Evaluaci贸n de clusters: silhouette, elbow method\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 8. Series Temporales**\n",
        "\n",
        "**Objetivo:** Analizar y modelar datos dependientes del tiempo.\n",
        "\n",
        "### **Tema 21. Fundamentos de series temporales**\n",
        "- **Lecci贸n 21.1.** Componentes: tendencia, estacionalidad, ciclo, ruido\n",
        "- **Lecci贸n 21.2.** Estacionariedad y transformaciones\n",
        "- **Lecci贸n 21.3.** Autocorrelaci贸n (ACF) y autocorrelaci贸n parcial (PACF)\n",
        "\n",
        "### **Tema 22. Modelos ARIMA**\n",
        "- **Lecci贸n 22.1.** Modelos AR, MA y ARMA\n",
        "- **Lecci贸n 22.2.** Modelos ARIMA: identificaci贸n y estimaci贸n\n",
        "- **Lecci贸n 22.3.** Predicci贸n con ARIMA\n",
        "- **Lecci贸n 22.4.** Evaluaci贸n de modelos de series temporales\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 9. Inferencia Bayesiana**\n",
        "\n",
        "**Objetivo:** Introducir el enfoque bayesiano y su aplicaci贸n en Machine Learning.\n",
        "\n",
        "### **Tema 23. Fundamentos bayesianos**\n",
        "- **Lecci贸n 23.1.** Paradigma frecuentista vs bayesiano\n",
        "- **Lecci贸n 23.2.** Teorema de Bayes: prior, verosimilitud y posterior\n",
        "- **Lecci贸n 23.3.** Actualizaci贸n bayesiana\n",
        "\n",
        "### **Tema 24. Aplicaciones bayesianas**\n",
        "- **Lecci贸n 24.1.** Clasificador Naive Bayes\n",
        "- **Lecci贸n 24.2.** Aplicaciones pr谩cticas en text mining y spam detection\n",
        "- **Lecci贸n 24.3.** Introducci贸n a m茅todos MCMC (Monte Carlo Markov Chain)\n",
        "\n",
        "---\n",
        "\n",
        "**Total:** 9 Bloques | 24 Temas | 96 Lecciones"
      ],
      "metadata": {
        "id": "qqrQyztFoZ-q"
      }
    }
  ]
}