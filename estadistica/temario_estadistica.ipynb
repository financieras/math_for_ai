{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv0HDhKv5tQXL/PpqDojfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/temario_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 **Programa de Estadística para Data Science y Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1. Fundamentos y Estadística Descriptiva**\n",
        "\n",
        "**Objetivo:** Dominar los conceptos básicos y las técnicas de descripción de datos.\n",
        "\n",
        "### **Tema 1. Conceptos fundamentales**\n",
        "- **Lección 1.1.** Población, muestra y tipos de variables\n",
        "- **Lección 1.2.** Escalas de medición: nominal, ordinal, intervalo y razón\n",
        "- **Lección 1.3.** Muestreo y representatividad\n",
        "\n",
        "### **Tema 2. Medidas descriptivas univariantes**\n",
        "- **Lección 2.1.** Medidas de tendencia central: media, mediana, moda\n",
        "- **Lección 2.2.** Medidas de dispersión: rango, varianza, desviación estándar, IQR\n",
        "- **Lección 2.3.** Medidas de forma: asimetría y curtosis\n",
        "- **Lección 2.4.** Percentiles y cuartiles\n",
        "\n",
        "### **Tema 3. Análisis descriptivo bivariante**\n",
        "- **Lección 3.1.** Covarianza y su interpretación\n",
        "- **Lección 3.2.** Correlación de Pearson y Spearman\n",
        "- **Lección 3.3.** Tablas de contingencia y asociación categórica\n",
        "\n",
        "### **Tema 4. Análisis Exploratorio de Datos (EDA)**\n",
        "- **Lección 4.1.** Visualizaciones: histogramas, boxplots, scatter plots\n",
        "- **Lección 4.2.** Detección y tratamiento de outliers\n",
        "- **Lección 4.3.** Transformaciones de datos\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2. Probabilidad**\n",
        "\n",
        "**Objetivo:** Comprender los fundamentos de la probabilidad y su aplicación práctica.\n",
        "\n",
        "### **Tema 5. Teoría de probabilidad**\n",
        "- **Lección 5.1.** Experimentos aleatorios, espacio muestral y eventos\n",
        "- **Lección 5.2.** Reglas de probabilidad: suma y multiplicación\n",
        "- **Lección 5.3.** Probabilidad condicional e independencia\n",
        "- **Lección 5.4.** Teorema de Bayes y aplicaciones\n",
        "\n",
        "### **Tema 6. Variables aleatorias**\n",
        "- **Lección 6.1.** Variables aleatorias discretas y continuas\n",
        "- **Lección 6.2.** Función de probabilidad y función de densidad\n",
        "- **Lección 6.3.** Esperanza matemática y varianza\n",
        "- **Lección 6.4.** Covarianza y correlación entre variables aleatorias\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3. Distribuciones de Probabilidad**\n",
        "\n",
        "**Objetivo:** Conocer las distribuciones fundamentales para modelar datos.\n",
        "\n",
        "### **Tema 7. Distribuciones discretas**\n",
        "- **Lección 7.1.** Distribución Bernoulli\n",
        "- **Lección 7.2.** Distribución Binomial\n",
        "- **Lección 7.3.** Distribución Poisson\n",
        "- **Lección 7.4.** Aplicaciones prácticas en Data Science\n",
        "\n",
        "### **Tema 8. Distribuciones continuas**\n",
        "- **Lección 8.1.** Distribución Uniforme\n",
        "- **Lección 8.2.** Distribución Normal: propiedades y estandarización\n",
        "- **Lección 8.3.** Distribución Exponencial\n",
        "- **Lección 8.4.** Teorema del Límite Central\n",
        "\n",
        "### **Tema 9. Distribuciones muestrales**\n",
        "- **Lección 9.1.** Distribución t de Student\n",
        "- **Lección 9.2.** Distribución Chi-cuadrado\n",
        "- **Lección 9.3.** Distribución F\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4. Inferencia Estadística**\n",
        "\n",
        "**Objetivo:** Realizar inferencias sobre poblaciones a partir de muestras.\n",
        "\n",
        "### **Tema 10. Estimación de parámetros**\n",
        "- **Lección 10.1.** Estimadores: propiedades (insesgados, eficientes, consistentes)\n",
        "- **Lección 10.2.** Estimación puntual\n",
        "- **Lección 10.3.** Intervalos de confianza para medias\n",
        "- **Lección 10.4.** Intervalos de confianza para proporciones\n",
        "\n",
        "### **Tema 11. Pruebas de hipótesis**\n",
        "- **Lección 11.1.** Hipótesis nula y alternativa\n",
        "- **Lección 11.2.** Nivel de significancia, p-valor y región crítica\n",
        "- **Lección 11.3.** Errores tipo I y tipo II, potencia del test\n",
        "- **Lección 11.4.** Pruebas para una y dos muestras\n",
        "\n",
        "### **Tema 12. Tests estadísticos**\n",
        "- **Lección 12.1.** Test t de Student (una y dos muestras)\n",
        "- **Lección 12.2.** ANOVA: comparación de múltiples grupos\n",
        "- **Lección 12.3.** Test Chi-cuadrado de independencia\n",
        "- **Lección 12.4.** Tests no paramétricos: Mann-Whitney, Kruskal-Wallis\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5. Regresión y Modelos Lineales**\n",
        "\n",
        "**Objetivo:** Construir modelos predictivos mediante regresión.\n",
        "\n",
        "### **Tema 13. Regresión lineal simple**\n",
        "- **Lección 13.1.** Modelo de regresión lineal: estimación por mínimos cuadrados\n",
        "- **Lección 13.2.** Interpretación de coeficientes\n",
        "- **Lección 13.3.** Supuestos del modelo lineal\n",
        "- **Lección 13.4.** Diagnóstico de residuos\n",
        "\n",
        "### **Tema 14. Regresión lineal múltiple**\n",
        "- **Lección 14.1.** Modelo de regresión múltiple\n",
        "- **Lección 14.2.** Multicolinealidad: detección y soluciones\n",
        "- **Lección 14.3.** Selección de variables\n",
        "- **Lección 14.4.** Métricas de evaluación: R², R² ajustado, MSE, RMSE\n",
        "\n",
        "### **Tema 15. Regresión logística**\n",
        "- **Lección 15.1.** Modelo de regresión logística para clasificación binaria\n",
        "- **Lección 15.2.** Interpretación: odds ratio y probabilidades\n",
        "- **Lección 15.3.** Evaluación: matriz de confusión, accuracy, precision, recall, F1-score\n",
        "- **Lección 15.4.** Curva ROC y AUC\n",
        "\n",
        "### **Tema 16. Regularización**\n",
        "- **Lección 16.1.** Overfitting y la necesidad de regularización\n",
        "- **Lección 16.2.** Regresión Ridge (L2)\n",
        "- **Lección 16.3.** Regresión Lasso (L1)\n",
        "- **Lección 16.4.** Elastic Net\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6. Validación y Evaluación de Modelos**\n",
        "\n",
        "**Objetivo:** Aplicar técnicas robustas de validación para modelos predictivos.\n",
        "\n",
        "### **Tema 17. Estrategias de validación**\n",
        "- **Lección 17.1.** Partición de datos: train, validation, test\n",
        "- **Lección 17.2.** Validación cruzada: K-fold, stratified K-fold\n",
        "- **Lección 17.3.** Leave-One-Out Cross-Validation (LOOCV)\n",
        "- **Lección 17.4.** Bootstrapping\n",
        "\n",
        "### **Tema 18. Sesgo-varianza y generalización**\n",
        "- **Lección 18.1.** Trade-off entre sesgo y varianza\n",
        "- **Lección 18.2.** Underfitting y overfitting\n",
        "- **Lección 18.3.** Curvas de aprendizaje\n",
        "- **Lección 18.4.** Estrategias para mejorar la generalización\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7. Análisis Multivariante**\n",
        "\n",
        "**Objetivo:** Trabajar con datos de múltiples dimensiones.\n",
        "\n",
        "### **Tema 19. Reducción de dimensionalidad**\n",
        "- **Lección 19.1.** Análisis de Componentes Principales (PCA)\n",
        "- **Lección 19.2.** Interpretación de componentes principales\n",
        "- **Lección 19.3.** Varianza explicada y selección de componentes\n",
        "- **Lección 19.4.** Aplicaciones en preprocesamiento de datos\n",
        "\n",
        "### **Tema 20. Clustering**\n",
        "- **Lección 20.1.** Clustering como aprendizaje no supervisado\n",
        "- **Lección 20.2.** K-means: algoritmo y criterios de convergencia\n",
        "- **Lección 20.3.** Clustering jerárquico: aglomerativo y divisivo\n",
        "- **Lección 20.4.** Evaluación de clusters: silhouette, elbow method\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 8. Series Temporales**\n",
        "\n",
        "**Objetivo:** Analizar y modelar datos dependientes del tiempo.\n",
        "\n",
        "### **Tema 21. Fundamentos de series temporales**\n",
        "- **Lección 21.1.** Componentes: tendencia, estacionalidad, ciclo, ruido\n",
        "- **Lección 21.2.** Estacionariedad y transformaciones\n",
        "- **Lección 21.3.** Autocorrelación (ACF) y autocorrelación parcial (PACF)\n",
        "\n",
        "### **Tema 22. Modelos ARIMA**\n",
        "- **Lección 22.1.** Modelos AR, MA y ARMA\n",
        "- **Lección 22.2.** Modelos ARIMA: identificación y estimación\n",
        "- **Lección 22.3.** Predicción con ARIMA\n",
        "- **Lección 22.4.** Evaluación de modelos de series temporales\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 9. Inferencia Bayesiana**\n",
        "\n",
        "**Objetivo:** Introducir el enfoque bayesiano y su aplicación en Machine Learning.\n",
        "\n",
        "### **Tema 23. Fundamentos bayesianos**\n",
        "- **Lección 23.1.** Paradigma frecuentista vs bayesiano\n",
        "- **Lección 23.2.** Teorema de Bayes: prior, verosimilitud y posterior\n",
        "- **Lección 23.3.** Actualización bayesiana\n",
        "\n",
        "### **Tema 24. Aplicaciones bayesianas**\n",
        "- **Lección 24.1.** Clasificador Naive Bayes\n",
        "- **Lección 24.2.** Aplicaciones prácticas en text mining y spam detection\n",
        "- **Lección 24.3.** Introducción a métodos MCMC (Monte Carlo Markov Chain)\n",
        "\n",
        "---\n",
        "\n",
        "**Total:** 9 Bloques | 24 Temas | 96 Lecciones"
      ],
      "metadata": {
        "id": "qqrQyztFoZ-q"
      }
    }
  ]
}