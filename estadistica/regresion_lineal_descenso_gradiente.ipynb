{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2A5/KAf3LONlJnMepDmpZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/regresion_lineal_descenso_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regresi√≥n Lineal con el algoritmo de descenso del gradiente**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introducci√≥n: ¬øQu√© problema queremos resolver?\n",
        "\n",
        "En el coraz√≥n del Machine Learning y la Ciencia de Datos se encuentra una tarea fundamental: la **predicci√≥n**. Queremos usar datos que ya tenemos para hacer estimaciones inteligentes sobre datos que a√∫n no hemos visto.\n",
        "\n",
        "Empecemos con un ejemplo cl√°sico y sencillo: **predecir el precio de una vivienda bas√°ndonos en su tama√±o.**\n",
        "\n",
        "Imagina que tenemos un conjunto de datos de casas. Para cada casa, conocemos su tama√±o en metros cuadrados (nuestra variable $x$) y el precio final por el que se vendi√≥ (nuestra variable $y$). Si visualizamos estos datos en un gr√°fico, probablemente veremos una \"nube de puntos\" que tiende a ir hacia arriba: a m√°s metros cuadrados, mayor es el precio.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro objetivo es trazar **una l√≠nea recta** que represente de la mejor forma posible la tendencia de esos puntos. Esta l√≠nea ser√° nuestro \"modelo\" de Regresi√≥n Lineal. ¬øPor qu√©? Porque una vez que tengamos esa l√≠nea, si alguien nos da un nuevo tama√±o ($x$) de una casa que no estaba en nuestros datos, podremos \"consultar\" la l√≠nea para estimar su precio ($y$).\n",
        "\n",
        "### La Ecuaci√≥n de Nuestro Modelo\n",
        "\n",
        "Como recordar√°s de tus clases de matem√°ticas, la ecuaci√≥n de una l√≠nea recta es $y = b + mx$. En Machine Learning, usamos una notaci√≥n ligeramente diferente pero que significa exactamente lo mismo:\n",
        "\n",
        "> $$\\hat{y} = w_0 + w_1 x$$\n",
        "\n",
        "Vamos a analizar estos t√©rminos, ya que los usaremos durante todo el art√≠culo:\n",
        "\n",
        "* **$x$**: Es nuestra variable de entrada (el *feature*), en este caso, el tama√±o de la casa.\n",
        "* **$\\hat{y}$** (se pronuncia \"y-sombrero\" o \"y-gorro\"): Es la **predicci√≥n** de nuestro modelo (el precio estimado). La distinguimos de la $y$ real (el precio de venta verdadero).\n",
        "* **$w_0$**: Es el **sesgo** (del ingl√©s *bias*). Es la altura de la ordenada en el origen ($b$). Es el precio base que tendr√≠a nuestra predicci√≥n $\\hat{y}$ si $x$ fuera 0.\n",
        "* **$w_1$**: Es el **peso** (del ingl√©s *weight*). Es el equivalente a la pendiente ($m$). Nos dice cu√°nto cambia $\\hat{y}$ (precio) por cada unidad que aumenta $x$ (metro cuadrado).\n",
        "\n",
        "**Objetivo:** Encontrar $ w_0 $ y $ w_1 $ que nos den la recta que mejor se ajuste a la nube de puntos.\n",
        "\n",
        "La pregunta clave que da origen a todo lo que sigue es: De todas las rectas posibles, ¬øc√≥mo encontramos la que **\"mejor se ajusta\"** a los datos? ¬øQu√© significa \"la mejor\"?\n",
        "\n",
        "Para responder a esto, necesitamos una forma de medir qu√© tan \"equivocada\" est√° nuestra l√≠nea. Necesitamos cuantificar el error. Y a esa medida la llamaremos nuestra **Funci√≥n de Costes**."
      ],
      "metadata": {
        "id": "nZ3lqREXVpXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2. üéØ Midiendo el Error: La Funci√≥n de Costes\n",
        "\n",
        "En el apartado anterior, nos quedamos con una pregunta clave: ¬øc√≥mo definimos la \"mejor\" l√≠nea?\n",
        "\n",
        "Intuitivamente, la mejor l√≠nea ser√° aquella que est√© **lo m√°s cerca posible de todos los puntos de datos** al mismo tiempo. Necesitamos una forma de cuantificar esta \"cercan√≠a\" total.\n",
        "\n",
        "### El Residuo: El Error de un Solo Punto\n",
        "\n",
        "Primero, veamos el error para un solo punto. Digamos que tenemos una casa (nuestro punto $i$-√©simo) que mide $x_i$ metros cuadrados y se vendi√≥ por un precio real $y_i$.\n",
        "\n",
        "Si nuestra l√≠nea (definida por $w_0$ y $w_1$) predice un precio $\\hat{y}_i$ para esa casa, el error para *ese punto* es simplemente la diferencia vertical entre el valor real y el valor predicho.\n",
        "\n",
        "$$\\text{Error}_i = e_i = \\hat{y}_i - y_i$$\n",
        "\n",
        "A esta diferencia la llamamos **\"residuo\"**.\n",
        "* Si el punto real est√° por encima de la l√≠nea, el residuo es positivo.\n",
        "* Si el punto real est√° por debajo de la l√≠nea, el residuo es negativo.\n",
        "\n",
        "### Agregando el Error: El Error Cuadr√°tico Medio (MSE)\n",
        "\n",
        "Ahora, ¬øc√≥mo combinamos los residuos de *todos* nuestros puntos ($m$ puntos en total) en una sola m√©trica?\n",
        "\n",
        "El primer impulso ser√≠a simplemente sumarlos. Pero esto es una mala idea: un residuo de +1000 y otro de -1000 se cancelar√≠an mutuamente, haciendo parecer que nuestro modelo no tiene error, ¬°cuando en realidad est√° fallando estrepitosamente en ambos puntos!\n",
        "\n",
        "Para solucionar esto, hacemos dos cosas:\n",
        "\n",
        "1.  **Elevamos cada residuo al cuadrado:** $e_i^2 = (\\hat{y}_i - y_i)^2$.\n",
        "    * Esto convierte todos los errores en n√∫meros positivos (ej. $(-100)^2 = 10000$ y $(+100)^2 = 10000$). ¬°Se acabaron las cancelaciones!\n",
        "    * Adem√°s, **penaliza los errores grandes mucho m√°s** que los peque√±os. Un error de 10 se convierte en 100, pero un error de 2 solo se convierte en 4. Esto fuerza al modelo a evitar predicciones muy alejadas de la realidad.\n",
        "\n",
        "2.  **Calculamos la media:** Sumamos todos estos errores al cuadrado y los dividimos por el n√∫mero de puntos ($m$). Esto nos da el **Error Cuadr√°tico Medio** (o *Mean Squared Error, MSE*).\n",
        "\n",
        "Esta m√©trica es nuestra **Funci√≥n de Costes**, que com√∫nmente se denota como $J$.\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2$$\n",
        "\n",
        "Si sustituimos $\\hat{y}_i$ por la ecuaci√≥n de nuestra l√≠nea, $(w_0 + w_1 x_i)$, obtenemos la f√≥rmula completa:\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (w_0 + w_1 x_i - y_i)^2$$\n",
        "\n",
        "> **Nota t√©cnica:** En muchos libros ver√°s esta f√≥rmula con un $1/2m$ en lugar de $1/m$. (Ej. $J = \\frac{1}{2m} \\sum...$). Este $1/2$ se a√±ade por pura conveniencia matem√°tica. No cambia d√≥nde est√° el m√≠nimo, pero hace que la derivada (que usaremos en el siguiente paso) sea un poco m√°s \"limpia\" al cancelar un 2 que aparece al derivar el t√©rmino al cuadrado.\n",
        "\n",
        "### Nuestro Nuevo Objetivo\n",
        "\n",
        "¬°Este es el punto clave! F√≠jate en $J(w_0, w_1)$. Nuestros datos ($x$ e $y$) son fijos. Por lo tanto, el coste $J$ **no es una funci√≥n de $x$**, sino una funci√≥n de nuestros par√°metros $w_0$ y $w_1$.\n",
        "\n",
        "* Diferentes valores de $w_0$ y $w_1$ (diferentes l√≠neas) nos dar√°n un coste $J$ diferente.\n",
        "* Una l√≠nea mala tendr√° un coste $J$ muy alto.\n",
        "* Una l√≠nea buena tendr√° un coste $J$ muy bajo.\n",
        "\n",
        "Si imaginamos todos los posibles valores de $w_0$ y $w_1$ y el coste $J$ que producen, obtendr√≠amos una superficie en 3D con forma de \"cuenco\" o valle.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro problema de \"encontrar la mejor l√≠nea\" se ha transformado en un problema de optimizaci√≥n mucho m√°s claro:\n",
        "\n",
        "**Encontrar los valores de $w_0$ y $w_1$ que nos sit√∫en en el punto m√°s bajo (el m√≠nimo) de este cuenco.**\n",
        "\n",
        "¬øY c√≥mo encontramos ese punto m√≠nimo? No lo haremos probando todas las combinaciones al azar. Usaremos un algoritmo inteligente llamado **Descenso del Gradiente**."
      ],
      "metadata": {
        "id": "h0FP2R1IXIL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. üìâ El Algoritmo: Descenso del Gradiente (Gradient Descent)\n",
        "\n",
        "Ahora que sabemos que nuestro objetivo es minimizar la Funci√≥n de Costes $J(w_0, w_1)$, necesitamos un m√©todo sistem√°tico para alcanzar ese m√≠nimo global. Aqu√≠ es donde entra en juego el **Descenso del Gradiente**.\n",
        "\n",
        "El Descenso del Gradiente es un **algoritmo de optimizaci√≥n iterativo** que se utiliza para encontrar los valores de los par√°metros $(w_0, w_1)$ que minimizan una funci√≥n (nuestra funci√≥n de costes).\n",
        "\n",
        "### La Analog√≠a de la Monta√±a ‚õ∞Ô∏è\n",
        "\n",
        "La forma m√°s intuitiva de entender el Descenso del Gradiente es a trav√©s de una analog√≠a.\n",
        "\n",
        "Imagina que est√°s en la cima de una monta√±a, con los ojos vendados, y tu objetivo es llegar al valle (el punto m√°s bajo).\n",
        "\n",
        "1.  **Tu Posici√≥n:** Tu posici√≥n actual en la monta√±a corresponde a los valores actuales de tus par√°metros **$(w_0, w_1)$**.\n",
        "2.  **El Objetivo:** El valle corresponde al **m√≠nimo global** de la funci√≥n de costes $J$.\n",
        "\n",
        "Como est√°s vendado, no puedes ver el valle, pero puedes sentir el suelo bajo tus pies. ¬øC√≥mo te mueves de manera eficiente?\n",
        "\n",
        "* **Paso 1: Siente la Pendiente:** Tientas el suelo a tu alrededor para determinar la direcci√≥n en la que la pendiente es **m√°s pronunciada hacia abajo**. Esta direcci√≥n de m√°ximo descenso es el **gradiente**.\n",
        "* **Paso 2: Da un Paso:** Una vez que conoces la direcci√≥n, das un paso. El tama√±o de ese paso est√° determinado por la **tasa de aprendizaje**.\n",
        "* **Paso 3: Repite:** Repites este proceso (sentir la pendiente y dar un paso) hasta que llegas a un punto donde ya no puedes bajar m√°s.\n",
        "\n",
        "El Descenso del Gradiente hace exactamente esto, pero en el mundo de las matem√°ticas:\n",
        "\n",
        "### El Descenso del Gradiente en ML\n",
        "\n",
        "El algoritmo comienza con unos valores **iniciales aleatorios** para nuestros par√°metros $w_0$ y $w_1$ (est√°s en alg√∫n punto aleatorio de la monta√±a). Luego, repite un ciclo de actualizaci√≥n hasta la **convergencia**:\n",
        "\n",
        "#### 1. Calcular el Gradiente (La Direcci√≥n)\n",
        "\n",
        "El gradiente es una herramienta del c√°lculo (un vector de derivadas parciales) que nos dice exactamente cu√°l es la **pendiente** de la funci√≥n de costes $J$ en nuestra posici√≥n actual $(w_0, w_1)$.\n",
        "\n",
        "* Si la pendiente es positiva, significa que estamos a la izquierda del m√≠nimo y debemos reducir el valor de $w$.\n",
        "* Si la pendiente es negativa, estamos a la derecha y debemos aumentar el valor de $w$.\n",
        "\n",
        "Matem√°ticamente, el gradiente apunta siempre hacia la **m√°xima subida**. Por lo tanto, si queremos *descender* (minimizar el coste), debemos movernos en la **direcci√≥n opuesta** al gradiente. Esto explica el signo negativo que introduciremos.\n",
        "\n",
        "#### 2. La Actualizaci√≥n de los Par√°metros (El Paso)\n",
        "\n",
        "En cada iteraci√≥n, actualizamos **simult√°neamente** $w_0$ y $w_1$ usando la siguiente regla:\n",
        "\n",
        "$$\\text{Nuevo } w_j = \\text{Antiguo } w_j - (\\text{Tasa de Aprendizaje } \\times \\text{ Gradiente})$$\n",
        "\n",
        "Donde $w_j$ representa cualquiera de nuestros par√°metros ($w_0$ o $w_1$).\n",
        "\n",
        "El signo de resta es lo que garantiza el \"descenso\": estamos movi√©ndonos en contra de la direcci√≥n de la pendiente.\n",
        "\n",
        "Los detalles de c√≥mo se calcula el gradiente y c√≥mo se elige la tasa de aprendizaje son cruciales y se explican a continuaci√≥n."
      ],
      "metadata": {
        "id": "t93VaGLxlGQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. üß© Las Piezas Clave del Algoritmo\n",
        "\n",
        "El Descenso del Gradiente es simple, pero su eficacia reside en la correcta aplicaci√≥n de dos componentes esenciales: el **Gradiente** (la direcci√≥n de la pendiente) y la **Tasa de Aprendizaje** (el tama√±o del paso).\n",
        "\n",
        "### A. El Gradiente: La Direcci√≥n de M√°ximo Descenso\n",
        "\n",
        "Como mencionamos, necesitamos calcular la pendiente de la funci√≥n de costes $J(w_0, w_1)$ en nuestros valores de par√°metros actuales. Esto se logra calculando las **derivadas parciales** de $J$ con respecto a cada par√°metro ($w_0$ y $w_1$).\n",
        "\n",
        "El resultado de estas derivadas nos dir√° cu√°nto cambiar√≠a el coste $J$ si modific√°ramos ligeramente un par√°metro, manteniendo el otro fijo.\n",
        "\n",
        "Recordemos la f√≥rmula del coste MSE (usando la notaci√≥n $1/m$):\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (w_0 + w_1 x_i - y_i)^2$$\n",
        "\n",
        "#### F√≥rmulas de las Derivadas Parciales (El Gradiente)\n",
        "\n",
        "Al aplicar las reglas de la derivaci√≥n a la funci√≥n de costes $J(w)$, obtenemos las siguientes expresiones para el gradiente:\n",
        "\n",
        "1.  **Derivada con respecto a $w_0$ (el sesgo):**\n",
        "    $$\\frac{\\partial J}{\\partial w_0} = \\frac{2}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)$$\n",
        "    *Esta derivada es simplemente la media de todos los errores (la diferencia entre la predicci√≥n $\\hat{y}$ y el valor real $y$).*\n",
        "\n",
        "2.  **Derivada con respecto a $w_1$ (el peso/pendiente):**\n",
        "    $$\\frac{\\partial J}{\\partial w_1} = \\frac{2}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i) \\cdot x_i$$\n",
        "    *Esta derivada es la media de los errores, multiplicada por la caracter√≠stica $x_i$. Esto significa que los puntos con valores de $x$ m√°s grandes tendr√°n una mayor influencia en el ajuste de $w_1$.*\n",
        "\n",
        "> **Simplificaci√≥n:** Para la implementaci√≥n, es com√∫n trabajar con la versi√≥n con $\\frac{1}{2m}$ en la funci√≥n de costes, lo que simplifica las f√≥rmulas anteriores y elimina el factor 2:\n",
        "> $$\\frac{\\partial J}{\\partial w_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)$$\n",
        "> $$\\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i) \\cdot x_i$$\n",
        "\n",
        "---\n",
        "\n",
        "### B. La Tasa de Aprendizaje ($\\alpha$): El Tama√±o del Paso\n",
        "\n",
        "La **tasa de aprendizaje** ($\\alpha$) es un **hiperpar√°metro** fundamental que controla la magnitud de los pasos que damos en la direcci√≥n del gradiente. En el Machine Learning, los hiperpar√°metros son valores que debemos establecer *antes* de que el algoritmo comience a entrenar.\n",
        "\n",
        "#### La Regla de Actualizaci√≥n\n",
        "\n",
        "Con la direcci√≥n del gradiente y el tama√±o del paso $\\alpha$, definimos la regla de actualizaci√≥n. Esta se aplica repetidamente durante un n√∫mero predefinido de iteraciones (llamadas **√©pocas**):\n",
        "\n",
        "**Repetir (Iteraciones/√âpocas) {**\n",
        "\n",
        "$$\\mathbf{w_0} := w_0 - \\alpha \\frac{\\partial J}{\\partial w_0}$$\n",
        "\n",
        "$$\\mathbf{w_1} := w_1 - \\alpha \\frac{\\partial J}{\\partial w_1}$$\n",
        "\n",
        "**}**\n",
        "\n",
        "#### El Impacto Cr√≠tico de $\\alpha$\n",
        "\n",
        "Elegir la $\\alpha$ correcta es un acto de equilibrio:\n",
        "\n",
        "| Si $\\alpha$ es... | Consecuencia... | Gr√°fico conceptual... |\n",
        "| :--- | :--- | :--- |\n",
        "| **Demasiado Peque√±a** | El algoritmo convergir√° (llegar√° al m√≠nimo), pero lo har√° **extremadamente lento**. Se necesitar√°n miles de √©pocas, lo que consume mucho tiempo y recursos. |  |\n",
        "| **Correcta** | El algoritmo converge eficientemente, acerc√°ndose al m√≠nimo en un n√∫mero razonable de pasos. |  |\n",
        "| **Demasiado Grande** | El algoritmo puede **divergir** u **oscilar**. Al dar pasos gigantescos, el modelo salta de un lado a otro del valle, o incluso se aleja del m√≠nimo, haciendo que el coste $J$ aumente con el tiempo. |  |\n",
        "\n",
        "En la pr√°ctica, la $\\alpha$ se ajusta mediante experimentaci√≥n, siendo un valor t√≠pico inicial alrededor de $0.01$, $0.001$, o $0.0001$.\n",
        "\n",
        "---\n",
        "\n",
        "### C. Nota sobre el C√°lculo Simult√°neo\n",
        "\n",
        "Es vital entender que, dentro de cada paso (cada √©poca), las actualizaciones de $w_0$ y $w_1$ deben realizarse **simult√°neamente**.\n",
        "\n",
        "Esto significa que primero se deben calcular *ambas* derivadas (gradientes) utilizando los valores de $w_0$ y $w_1$ de la *iteraci√≥n anterior*. Una vez que se tienen los dos gradientes, se actualizan ambos par√°metros a sus nuevos valores. Si se actualizara $w_0$ y luego se usara el *nuevo* $w_0$ para calcular la derivada de $w_1$, se introducir√≠a un sesgo en el algoritmo que podr√≠a llevar a resultados incorrectos."
      ],
      "metadata": {
        "id": "z9fpRWAwmrz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5\\. üë®‚Äçüíª Manos a la Obra: Implementaci√≥n \"Manual\" con Python y NumPy\n",
        "\n",
        "Pasamos de la teor√≠a a la pr√°ctica programando el algoritmo de **Regresi√≥n Lineal con Descenso de Gradiente (Gradient Descent)** desde cero. Usaremos las librer√≠as NumPy para las operaciones matriciales eficientes y Matplotlib para la visualizaci√≥n.\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.1. Importaci√≥n y Preparaci√≥n de Datos\n",
        "\n",
        "Comenzamos importando las librer√≠as necesarias y creando un conjunto de datos de ejemplo. Utilizaremos una relaci√≥n lineal simple a la que a√±adiremos un poco de \"ruido\" aleatorio para simular datos reales."
      ],
      "metadata": {
        "id": "mazwxGYYpSmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Crear datos de ejemplo\n",
        "np.random.seed(42) # Fijar semilla para reproducibilidad\n",
        "\n",
        "# Variable independiente X (caracter√≠stica)\n",
        "X = 2 * np.random.rand(100, 1) # 100 valores entre 0 y 2\n",
        "\n",
        "# Variable dependiente y (objetivo)\n",
        "# Relaci√≥n real: y = 4 + 3 * X + ruido\n",
        "y = 4 + 3 * X + np.random.randn(100, 1) * 1.5 # El ruido es esencial\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, alpha=0.7, label='Datos reales')\n",
        "plt.xlabel('Tama√±o (normalizado)')\n",
        "plt.ylabel('Precio')\n",
        "plt.title('Datos de Entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tg47hHkfp0ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.2. Escalamiento de Caracter√≠sticas (Estandarizaci√≥n)\n",
        "\n",
        "**Importante:** Antes de iniciar el Descenso de Gradiente, es **crucial** realizar el **Escalado de Caracter√≠sticas** (Feature Scaling).\n",
        "\n",
        "#### üí° ¬øPor qu√© es crucial el Escalado?\n",
        "\n",
        "El Descenso de Gradiente funciona mejor cuando las caracter√≠sticas de entrada (las columnas de $X$) est√°n en una escala similar. Si una caracter√≠stica (por ejemplo, el precio de una casa) tiene valores mucho mayores que otra (por ejemplo, el n√∫mero de habitaciones), la funci√≥n de costes ($J(w)$) ser√° muy alargada y estrecha (una \"elipse\").\n",
        "\n",
        "  * **Funci√≥n de Costes Asim√©trica:** Esto significa que las derivadas (el gradiente) ser√°n muy grandes en la direcci√≥n de la caracter√≠stica con mayor escala.\n",
        "  * **Convergencia Lenta o Divergencia:** El algoritmo de Descenso de Gradiente tendr√° que dar \"pasos\" muy peque√±os en la direcci√≥n de la caracter√≠stica con menor escala y \"pasos\" muy grandes y zigzagueantes en la direcci√≥n de la caracter√≠stica con mayor escala. Esto ralentiza dr√°sticamente la convergencia o, en el peor de los casos, hace que el algoritmo no converja.\n",
        "\n",
        "La **Estandarizaci√≥n** (o *Z-score normalization*) transforma los datos para que tengan una media ($\\mu$) de 0 y una desviaci√≥n est√°ndar ($\\sigma$) de 1.\n",
        "\n",
        "$$X_{\\text{estandarizado}} = \\frac{X - \\mu}{\\sigma}$$\n",
        "\n",
        "Aplicamos la estandarizaci√≥n solo a la caracter√≠stica $X$ (la segunda columna de `X_b`)."
      ],
      "metadata": {
        "id": "HXuHd1w3rUik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular media y desviaci√≥n est√°ndar\n",
        "mu = X.mean()\n",
        "sigma = X.std()\n",
        "\n",
        "print(f\"Media (Œº): {mu:.4f}\")\n",
        "print(f\"Desviaci√≥n est√°ndar (œÉ): {sigma:.4f}\")\n",
        "print()\n",
        "\n",
        "# Estandarizar: X' = (X - Œº) / œÉ\n",
        "X_scaled = (X - mu) / sigma\n",
        "\n",
        "# A√±adir columna de 1s para w0\n",
        "# np.c_ concatena arrays por columnas\n",
        "X_b = np.c_[np.ones((100, 1)), X_scaled]\n",
        "\n",
        "X_b[:5] # Mostramos las 5 primeras filas de la matriz"
      ],
      "metadata": {
        "id": "r0GEhKRna9XY",
        "outputId": "78949d48-5aeb-4fb9-b5e3-987eb9ef3774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media (Œº): 0.9404\n",
            "Desviaci√≥n est√°ndar (œÉ): 0.5920\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.32311215],\n",
              "       [ 1.        ,  1.62343393],\n",
              "       [ 1.        ,  0.88450935],\n",
              "       [ 1.        ,  0.43404902],\n",
              "       [ 1.        , -1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.3. Implementaci√≥n del Descenso de Gradiente\n",
        "\n",
        "Ahora implementamos el n√∫cleo del algoritmo, siguiendo la f√≥rmula del Descenso de Gradiente.\n",
        "\n",
        "**F√≥rmulas Clave:**\n",
        "\n",
        "1.  **Predicci√≥n:** La predicci√≥n de los valores, denotada como $\\hat{\\mathbf{y}}$, se calcula matricialmente.  \n",
        "    $$\\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w}$$\n",
        "2.  **Funci√≥n de Coste (MSE):** La funci√≥n de coste $J(\\mathbf{w})$ se basa en el error cuadr√°tico medio.  \n",
        "    $$J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2$$\n",
        "3.  **Regla de Actualizaci√≥n (Vectorial):** La actualizaci√≥n de los pesos se realiza en cada paso utilizando el gradiente.  \n",
        "    $$\\mathbf{w} := \\mathbf{w} - \\alpha \\cdot \\frac{1}{m} \\cdot \\mathbf{X}^{\\text{T}} \\cdot (\\hat{\\mathbf{y}} - \\mathbf{y})$$"
      ],
      "metadata": {
        "id": "vLjlunD2sJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperpar√°metros\n",
        "learning_rate = 0.01    # alpha (tasa de aprendizaje)\n",
        "epochs = 1000           # n√∫mero de iteraciones\n",
        "m = len(X)              # N√∫mero de ejemplos de entrenamiento\n",
        "\n",
        "# Inicializaci√≥n\n",
        "w = np.zeros((2, 1))    # 'w' es el vector de pesos iniciales para [w_0, w_1]\n",
        "cost_history = []       # (Opcional) Almacenar el historial de costes\n",
        "w0_history = []\n",
        "w1_history = []\n",
        "\n",
        "# Bucle de entrenamiento (las epochs)\n",
        "for epoch in range(epochs):\n",
        "    # Predicciones (≈∑)\n",
        "    # y_hat = X_scaled * w\n",
        "    # Las predicciones son la regresi√≥n de regresi√≥n\n",
        "    y_pred = X_b @ w        # dot product\n",
        "\n",
        "    # Error\n",
        "    errors = y_pred - y     # El error es (≈∑ - y)\n",
        "\n",
        "    # Gradiente: (1/m) * X_transpuesta * Errores\n",
        "    gradients = (1/m) * X_b.T @ errors\n",
        "\n",
        "    # Actualizaci√≥n: es w := w - alpha * gradiente\n",
        "    w = w - learning_rate * gradients\n",
        "\n",
        "    # Coste de cada paso (MSE/2)\n",
        "    cost = (1/(2*m)) * np.sum(errors**2)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    # Guardar par√°metros\n",
        "    w0_history.append(w[0][0])\n",
        "    w1_history.append(w[1][0])\n",
        "\n",
        "# Pesos √≥ptimos (en espacio estandarizado)\n",
        "w_optimal = w\n",
        "print(f\"w0 (estandarizado): {w_optimal[0][0]:.6f}\")\n",
        "print(f\"w1 (estandarizado): {w_optimal[1][0]:.6f}\")"
      ],
      "metadata": {
        "id": "UBQLoV7pVmAO",
        "outputId": "bb214ab4-c513-49e4-8109-e059cbf6f69e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w0 (estandarizado): 6.819170\n",
            "w1 (estandarizado): 1.571783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado de los par√°metros √≥ptimos:**\n",
        "\n",
        "| Par√°metro | Valor √ìptimo (aproximado) |\n",
        "| :---: | :---: |\n",
        "| $w_0$ | $6.8192$ |\n",
        "| $w_1$ | $1.5718$ |\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.4. Visualizaci√≥n de Resultados\n",
        "\n",
        "Para finalizar, ploteamos el historial de costes para confirmar que el algoritmo converge correctamente y visualizamos la l√≠nea de regresi√≥n final sobre los datos originales.\n",
        "\n",
        "#### 5.4.1. Gr√°fico del Historial de Costes\n",
        "\n",
        "El coste debe disminuir dr√°sticamente al inicio y luego aplanarse, indicando la convergencia."
      ],
      "metadata": {
        "id": "I8HHRmSAsqbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(epochs), cost_history, 'b.')\n",
        "plt.title('Historial de Costes')\n",
        "plt.xlabel('√âpoca (Epoch)')\n",
        "plt.ylabel('Funci√≥n de Coste J(w)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1NtshbJksvFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.4.2. Gr√°fico de la Regresi√≥n Lineal\n",
        "\n",
        "Para plotear la l√≠nea de regresi√≥n, debemos usar los valores originales de $X$ (sin estandarizar) y aplicarles la misma estandarizaci√≥n antes de multiplicarlos por los $w$ √≥ptimos."
      ],
      "metadata": {
        "id": "y3nS1iIMszfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un rango de X para dibujar la l√≠nea\n",
        "X_plot = np.array([[0], [2]])\n",
        "\n",
        "# 1. Estandarizar X_plot de la misma forma que los datos de entrenamiento\n",
        "X_plot_scaled = (X_plot - mu) / sigma\n",
        "\n",
        "# 2. A√±adir el sesgo (columna de unos)\n",
        "X_plot_b = np.c_[np.ones((2, 1)), X_plot_scaled]\n",
        "\n",
        "# 3. Calcular las predicciones con los pesos (w) √≥ptimos\n",
        "# Usamos w_optimal en lugar de theta_optimal\n",
        "y_predict = X_plot_b.dot(w_optimal)\n",
        "\n",
        "# Plotear los datos originales y la l√≠nea de regresi√≥n\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X, y, 'o', label='Datos originales')\n",
        "plt.plot(X_plot, y_predict, 'r-', label='L√≠nea de Regresi√≥n Final')\n",
        "plt.title('Regresi√≥n Lineal con Descenso de Gradiente')\n",
        "plt.xlabel('X (Caracter√≠stica Original)')\n",
        "plt.ylabel('y (Objetivo)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ru5H5FOZs3Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta forma, hemos implementado el Descenso de Gradiente de forma manual, demostrando c√≥mo el algoritmo itera para encontrar los par√°metros $w_0$ y $w_1$ que minimizan la funci√≥n de costes y definen la l√≠nea de mejor ajuste."
      ],
      "metadata": {
        "id": "7dG6VElxpQo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6\\. ‚ö° La V√≠a R√°pida: Implementaci√≥n con Scikit-Learn\n",
        "\n",
        "Tras haber programado la **Regresi√≥n Lineal con Descenso de Gradiente** manualmente, el objetivo de esta secci√≥n es mostrar c√≥mo se realiza esta tarea en un **entorno profesional** utilizando la librer√≠a est√°ndar de *machine learning* en Python: **Scikit-Learn (sklearn)**.\n",
        "\n",
        "El modelo que utilizaremos es `sklearn.linear_model.SGDRegressor`.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.1. ¬øPor qu√© `SGDRegressor`?\n",
        "\n",
        "Mientras que en el apartado anterior implementamos el **Descenso de Gradiente por Lotes (Batch Gradient Descent)**, Scikit-Learn ofrece una variante mucho m√°s com√∫n y eficiente para datos grandes: el **Descenso de Gradiente Estoc√°stico (Stochastic Gradient Descent - SGD)**.\n",
        "\n",
        "#### Concepto Clave: SGD\n",
        "\n",
        "El SGD es una variante del Descenso de Gradiente donde, en lugar de calcular el gradiente usando **todos** los ejemplos de entrenamiento (*batch* completo) en cada paso, el algoritmo:\n",
        "\n",
        "1.  Calcula el gradiente usando **un solo ejemplo** de entrenamiento seleccionado al azar (o un peque√±o subconjunto llamado *mini-batch*).\n",
        "2.  Actualiza los par√°metros $w$ inmediatamente.\n",
        "\n",
        "Esta aproximaci√≥n hace que el proceso sea **mucho m√°s r√°pido** en datasets con millones de datos, aunque el camino hacia el m√≠nimo de la funci√≥n de costes es m√°s ruidoso y aleatorio. Para la regresi√≥n lineal, el `SGDRegressor` es la herramienta est√°ndar cuando se desea aplicar el Descenso de Gradiente.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.2. Implementaci√≥n con Scikit-Learn\n",
        "\n",
        "A diferencia de la implementaci√≥n manual, Scikit-Learn requiere que el escalado de caracter√≠sticas y el modelo se manejen como objetos separados.\n",
        "\n",
        "#### 6.2.1. Preparaci√≥n y Escalado de Datos\n",
        "\n",
        "**Nota Importante:** Usaremos los datos originales $X$ e $y$ del apartado 5 para el proceso de escalado, asegur√°ndonos de que $y$ tenga la forma correcta para Scikit-Learn."
      ],
      "metadata": {
        "id": "mPBbTXkl0u8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Datos originales (asumimos que X e y son los del apartado 5)\n",
        "# X (100, 1), y (100, 1)\n",
        "\n",
        "# 1. Ajustar la forma de 'y' si es necesario (Scikit-Learn prefiere (n_samples,))\n",
        "y_flat = y.ravel()\n",
        "\n",
        "# 2. Crear y ajustar el StandardScaler\n",
        "# El escalador calcular√° la media y la desviaci√≥n est√°ndar de X\n",
        "scaler = StandardScaler()\n",
        "X_scaled_skl = scaler.fit_transform(X)\n",
        "X_scaled_skl[:5]"
      ],
      "metadata": {
        "id": "SY3bfQ0s0zyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac731af8-de0b-4065-cd3e-e81067b86970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.32311215],\n",
              "       [ 1.62343393],\n",
              "       [ 0.88450935],\n",
              "       [ 0.43404902],\n",
              "       [-1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.2. Entrenamiento del Modelo `SGDRegressor`\n",
        "\n",
        "Instanciamos y entrenamos el modelo. Es crucial especificar los hiperpar√°metros:\n",
        "\n",
        "  * `loss='squared_error'`: Indica que queremos minimizar el Error Cuadr√°tico Medio (MSE), adecuado para regresi√≥n lineal.\n",
        "  * `eta0`: La tasa de aprendizaje inicial ($\\alpha$).\n",
        "  * `max_iter`: El n√∫mero de √©pocas."
      ],
      "metadata": {
        "id": "iPsk-iPn09Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Crear una instancia de SGDRegressor\n",
        "sgd_reg = SGDRegressor(\n",
        "    loss='squared_error',\n",
        "    eta0=0.01,         # Learning rate (alpha)\n",
        "    max_iter=1000,     # N√∫mero de √©pocas\n",
        "    tol=1e-3,          # Criterio de parada\n",
        "    random_state=42    # Para obtener resultados reproducibles\n",
        ")\n",
        "\n",
        "# 4. Entrenar el modelo con .fit(X_scaled, y)\n",
        "sgd_reg.fit(X_scaled_skl, y_flat)\n",
        "\n",
        "# 5. Mostrar los par√°metros encontrados\n",
        "# Renombramos las variables a w_0 y w_1 para mantener la consistencia\n",
        "w_0_skl = sgd_reg.intercept_[0]\n",
        "w_1_skl = sgd_reg.coef_[0]\n",
        "\n",
        "print(\"\\n--- Par√°metros √ìptimos encontrados por SGDRegressor ---\")\n",
        "# Usamos w_0 y w_1 en el texto impreso\n",
        "print(f\"w_0 (Intercepto): {w_0_skl:.4f}\")\n",
        "print(f\"w_1 (Pendiente): {w_1_skl:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5jz70i51BH2",
        "outputId": "579cc1ae-9d28-4bd1-d187-01f99f311953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Par√°metros √ìptimos encontrados por SGDRegressor ---\n",
            "w_0 (Intercepto): 6.7827\n",
            "w_1 (Pendiente): 1.5603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 6.3. Comparaci√≥n de Resultados\n",
        "\n",
        "Comparamos los resultados de la implementaci√≥n manual (Descenso de Gradiente por Lotes) y la implementaci√≥n profesional de Scikit-Learn (Descenso de Gradiente Estoc√°stico).\n",
        "\n",
        "| Par√°metro | Manual (Batch GD) | Scikit-Learn (SGDRegressor) |\n",
        "| :---: | :---: | :---: |\n",
        "| $w_0$ (Intercepto) | $6.8192$ | **$6.7827$** |\n",
        "| $w_1$ (Pendiente) | $1.5718$ | **$1.5603$** |\n",
        "\n",
        "\n",
        "Los resultados son pr√°cticamente **iguales**. Esto permite verificar dos puntos fundamentales:\n",
        "\n",
        "1.  **Validaci√≥n de la teor√≠a:** Nuestra implementaci√≥n manual funcion√≥ correctamente.\n",
        "2.  **Eficiencia de la herramienta:** En la pr√°ctica, el `SGDRegressor` nos permite obtener los mismos resultados √≥ptimos con una fracci√≥n del c√≥digo, benefici√°ndonos de la optimizaci√≥n y robustez de una librer√≠a profesional.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "w0HPZ77StqgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. üéØ Conclusi√≥n: ¬øQu√© Hemos Aprendido?\n",
        "\n",
        "A lo largo de este art√≠culo, hemos desglosado la **Regresi√≥n Lineal** desde sus cimientos matem√°ticos hasta su implementaci√≥n pr√°ctica, comprendiendo que es mucho m√°s que una simple l√≠nea de mejor ajuste. Los conceptos que hemos cubierto forman la base de la optimizaci√≥n en casi todo el campo del *Machine Learning*.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumen de Puntos Clave\n",
        "\n",
        "* **Objetivo de la Regresi√≥n Lineal:** La meta fundamental de la Regresi√≥n Lineal es encontrar los par√°metros ($w_0$ y $w_1$) que definen la recta que mejor se ajusta a los datos.\n",
        "* **La Funci√≥n de Costes (MSE):** Para determinar qu√© tan \"buena\" es una recta, utilizamos una m√©trica de error, conocida com√∫nmente como el **Error Cuadr√°tico Medio (MSE)** o $J(w)$. El verdadero objetivo del modelo es **minimizar** el valor de esta funci√≥n.\n",
        "* **El Algoritmo de Optimizaci√≥n: Descenso de Gradiente:** El **Descenso de Gradiente (*Gradient Descent*)** es el algoritmo que nos permite alcanzar ese m√≠nimo. Podemos visualizarlo como un proceso iterativo en el que \"caminamos\" por la superficie de la funci√≥n de costes.\n",
        "    * **El Gradiente es la Br√∫jula:** El gradiente (las derivadas parciales) indica la **direcci√≥n de m√°ximo ascenso** en la funci√≥n de costes. Puesto que queremos *minimizar* el coste, nuestro paso va en la direcci√≥n **opuesta** al gradiente.\n",
        "    * **La Tasa de Aprendizaje ($\\alpha$) es el Tama√±o del Paso:** La **tasa de aprendizaje** determina la magnitud de cada paso. Si es muy grande, corremos el riesgo de \"saltar\" el m√≠nimo; si es muy peque√±a, la convergencia ser√° extremadamente lenta.\n",
        "* **Importancia del Escalado:** El **Escalado de Caracter√≠sticas** (como la Estandarizaci√≥n) es crucial para asegurar que la funci√≥n de costes sea m√°s sim√©trica, permitiendo que el Descenso de Gradiente converja de manera m√°s **r√°pida y estable**.\n",
        "* **Implementaciones (Manual vs. Scikit-Learn):** Hemos comprobado que, si bien es posible y educativo programar el algoritmo desde cero con NumPy (Descenso por Lotes), en un entorno profesional se utiliza `SGDRegressor` de Scikit-Learn (Descenso Estoc√°stico), que ofrece la misma precisi√≥n con mayor eficiencia y rapidez en grandes vol√∫menes de datos.\n",
        "\n",
        "---\n",
        "\n",
        "### La Base de todo el *Machine Learning*\n",
        "\n",
        "El concepto de **Descenso de Gradiente** no se limita a la Regresi√≥n Lineal. La idea de definir una funci√≥n de costes, calcular su gradiente y ajustar par√°metros de forma iterativa es el **motor de optimizaci√≥n** de la inmensa mayor√≠a de los modelos de *Machine Learning* modernos, incluyendo:\n",
        "\n",
        "* **Regresi√≥n Log√≠stica.**\n",
        "* **M√°quinas de Soporte Vectorial (SVM).**\n",
        "* Y, de manera m√°s notable, el **Entrenamiento de Redes Neuronales Profundas**, donde la t√©cnica central es una aplicaci√≥n sofisticada del Descenso de Gradiente llamada **Retropropagaci√≥n (*Backpropagation*)**.\n",
        "\n",
        "Entender el Descenso de Gradiente es, por lo tanto, entender **c√≥mo aprende una m√°quina**."
      ],
      "metadata": {
        "id": "FmUj4QLlui91"
      }
    }
  ]
}