{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEj57HIgZ7p45UZj+B1eQ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/regresion_lineal_descenso_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Descent: How a Linear Regression Model Learns to Fit Data**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introducci√≥n: ¬øQu√© problema queremos resolver?\n",
        "\n",
        "En el coraz√≥n del Machine Learning y la Ciencia de Datos se encuentra una tarea fundamental: la **predicci√≥n**. Queremos usar datos que ya tenemos para hacer estimaciones inteligentes sobre datos que a√∫n no hemos visto.\n",
        "\n",
        "Empecemos con un ejemplo cl√°sico y sencillo: **predecir el precio de una vivienda bas√°ndonos en su tama√±o.**\n",
        "\n",
        "Imagina que tenemos un conjunto de datos de casas. Para cada casa, conocemos su tama√±o en metros cuadrados (nuestra variable $x$) y el precio final por el que se vendi√≥ (nuestra variable $y$). Si visualizamos estos datos en un gr√°fico, probablemente veremos una \"nube de puntos\" que tiende a ir hacia arriba: a m√°s metros cuadrados, mayor es el precio.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro objetivo es trazar **una l√≠nea recta** que represente de la mejor forma posible la tendencia de esos puntos. Esta l√≠nea ser√° nuestro \"modelo\" de Regresi√≥n Lineal. ¬øPor qu√©? Porque una vez que tengamos esa l√≠nea, si alguien nos da un nuevo tama√±o ($x$) de una casa que no estaba en nuestros datos, podremos \"consultar\" la l√≠nea para estimar su precio ($y$).\n",
        "\n",
        "### La Ecuaci√≥n de Nuestro Modelo\n",
        "\n",
        "Como recordar√°s de tus clases de matem√°ticas, la ecuaci√≥n de una l√≠nea recta es $y = b + mx$. En Machine Learning, usamos una notaci√≥n ligeramente diferente pero que significa exactamente lo mismo:\n",
        "\n",
        "$$\\hat{y} = w_0 + w_1 x$$\n",
        "\n",
        "Vamos a analizar estos t√©rminos, ya que los usaremos durante todo el art√≠culo:\n",
        "\n",
        "* **$x$**: Es nuestra variable de entrada (el *feature*), en este caso, el tama√±o de la casa.\n",
        "* **$\\hat{y}$** (se pronuncia \"y-sombrero\" o \"y-gorro\"): Es la **predicci√≥n** de nuestro modelo (el precio estimado). La distinguimos de la $y$ real (el precio de venta verdadero).\n",
        "* **$w_0$**: Es el **sesgo** (del ingl√©s *bias*). Es la altura de la ordenada en el origen ($b$). Es el precio base que tendr√≠a nuestra predicci√≥n $\\hat{y}$ si $x$ fuera 0.\n",
        "* **$w_1$**: Es el **peso** (del ingl√©s *weight*). Es el equivalente a la pendiente ($m$). Nos dice cu√°nto cambia $\\hat{y}$ (precio) por cada unidad que aumenta $x$ (metro cuadrado).\n",
        "\n",
        "**Objetivo:** Encontrar $ w_0 $ y $ w_1 $ que nos den la recta que mejor se ajuste a la nube de puntos.\n",
        "\n",
        "La pregunta clave que da origen a todo lo que sigue es: De todas las rectas posibles, ¬øc√≥mo encontramos la que **\"mejor se ajusta\"** a los datos? ¬øQu√© significa \"la mejor\"?\n",
        "\n",
        "Para responder a esto, necesitamos una forma de medir qu√© tan \"equivocada\" est√° nuestra l√≠nea. Necesitamos cuantificar el error. Y a esa medida la llamaremos nuestra **Funci√≥n de Costes**."
      ],
      "metadata": {
        "id": "nZ3lqREXVpXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2. üéØ Midiendo el Error: La Funci√≥n de Costes\n",
        "\n",
        "En el apartado anterior, nos quedamos con una pregunta clave: ¬øc√≥mo definimos la \"mejor\" l√≠nea?\n",
        "\n",
        "Intuitivamente, la mejor l√≠nea ser√° aquella que est√© **lo m√°s cerca posible de todos los puntos de datos** al mismo tiempo. Necesitamos una forma de cuantificar esta \"cercan√≠a\" total.\n",
        "\n",
        "### El Residuo: El Error de un Solo Punto\n",
        "\n",
        "Primero, veamos el error para un solo punto. Digamos que tenemos una casa (nuestro punto $i$-√©simo) que mide $x_i$ metros cuadrados y se vendi√≥ por un precio real $y_i$.\n",
        "\n",
        "Si nuestra l√≠nea (definida por $w_0$ y $w_1$) predice un precio $\\hat{y}_i$ para esa casa, el error para *ese punto* es simplemente la diferencia vertical entre el valor real y el valor predicho.\n",
        "\n",
        "$$\\text{Error}_i = e_i = y_i - \\hat{y}_i$$\n",
        "\n",
        "A esta diferencia la llamamos **\"residuo\"**.\n",
        "* Si el punto real est√° por encima de la l√≠nea ($y_i > \\hat{y}_i$), el residuo $e_i$ es positivo.\n",
        "* Si el punto real est√° por debajo de la l√≠nea ($y_i < \\hat{y}_i$), el residuo $e_i$ es negativo.\n",
        "\n",
        "### Agregando el Error: El Error Cuadr√°tico Medio (MSE)\n",
        "\n",
        "Ahora, ¬øc√≥mo combinamos los residuos de *todos* nuestros puntos ($m$ puntos en total) en una sola m√©trica?\n",
        "\n",
        "El primer impulso ser√≠a simplemente sumarlos. Pero esto es una mala idea: un residuo de +1000 y otro de -1000 se cancelar√≠an mutuamente, haciendo parecer que nuestro modelo no tiene error, ¬°cuando en realidad est√° fallando estrepitosamente en ambos puntos!\n",
        "\n",
        "Para solucionar esto, hacemos dos cosas:\n",
        "\n",
        "1.  **Elevamos cada residuo al cuadrado:** $e_i^2 = (y_i - \\hat{y}_i)^2$.\n",
        "    * Esto convierte todos los errores en n√∫meros positivos (ej. $(-100)^2 = 10000$ y $(+100)^2 = 10000$). ¬°Se acabaron las cancelaciones!\n",
        "    * Adem√°s, **penaliza los errores grandes mucho m√°s** que los peque√±os. Un error de 10 se convierte en 100, pero un error de 2 solo se convierte en 4. Esto fuerza al modelo a evitar predicciones muy alejadas de la realidad.\n",
        "\n",
        "2.  **Calculamos la media:** Sumamos todos estos errores al cuadrado y los dividimos por el n√∫mero de puntos ($m$). Esto nos da el **Error Cuadr√°tico Medio** (o *Mean Squared Error, MSE*).\n",
        "\n",
        "Esta m√©trica es nuestra **Funci√≥n de Costes**, que com√∫nmente se denota como $J$.\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Si sustituimos $\\hat{y}_i$ por la ecuaci√≥n de nuestra l√≠nea, $(w_0 + w_1 x_i)$, obtenemos la f√≥rmula completa:\n",
        "\n",
        "$$J(w_0, w_1) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - (w_0 + w_1 x_i))^2$$\n",
        "\n",
        "> **Nota t√©cnica:** En muchos libros ver√°s esta f√≥rmula con un $\\frac{1}{2m}$ en lugar de $\\frac{1}{m}$. (Ej. $J = \\frac{1}{2m} \\sum...$). Este $\\frac{1}{2}$ se a√±ade por pura conveniencia matem√°tica: al derivar $(y - \\hat{y})^2$ obtenemos $2(y - \\hat{y})$, y el factor $\\frac{1}{2}$ cancela ese 2, simplificando las ecuaciones del gradiente. Esto no cambia d√≥nde est√° el m√≠nimo de la funci√≥n.\n",
        "\n",
        "\n",
        "### Nuestro Nuevo Objetivo\n",
        "\n",
        "¬°Este es el punto clave! F√≠jate en $J(w_0, w_1)$. Nuestros datos ($x$ e $y$) son fijos. Por lo tanto, el coste $J$ **no es una funci√≥n de $x$**, sino una funci√≥n de nuestros par√°metros $w_0$ y $w_1$.\n",
        "\n",
        "* Diferentes valores de $w_0$ y $w_1$ (diferentes l√≠neas) nos dar√°n un coste $J$ diferente.\n",
        "* Una l√≠nea mala tendr√° un coste $J$ muy alto.\n",
        "* Una l√≠nea buena tendr√° un coste $J$ muy bajo.\n",
        "\n",
        "Si imaginamos todos los posibles valores de $w_0$ y $w_1$ y el coste $J$ que producen, obtendr√≠amos una superficie en 3D con forma de \"cuenco\" o valle.\n",
        "\n",
        "\n",
        "\n",
        "Nuestro problema de \"encontrar la mejor l√≠nea\" se ha transformado en un problema de optimizaci√≥n mucho m√°s claro:\n",
        "\n",
        "**Encontrar los valores de $w_0$ y $w_1$ que nos sit√∫en en el punto m√°s bajo (el m√≠nimo) de este cuenco.**\n",
        "\n",
        "¬øY c√≥mo encontramos ese punto m√≠nimo? No lo haremos probando todas las combinaciones al azar. Usaremos un algoritmo inteligente llamado **Descenso del Gradiente**."
      ],
      "metadata": {
        "id": "h0FP2R1IXIL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. üìâ El Algoritmo: Descenso del Gradiente (Gradient Descent)\n",
        "\n",
        "Ahora que sabemos que nuestro objetivo es minimizar la Funci√≥n de Costes $J(w_0, w_1)$, necesitamos un m√©todo sistem√°tico para alcanzar ese m√≠nimo global. Aqu√≠ es donde entra en juego el **Descenso del Gradiente**.\n",
        "\n",
        "El Descenso del Gradiente es un **algoritmo de optimizaci√≥n iterativo** que se utiliza para encontrar los valores de los par√°metros $(w_0, w_1)$ que minimizan una funci√≥n (nuestra funci√≥n de costes).\n",
        "\n",
        "### La Analog√≠a de la Monta√±a ‚õ∞Ô∏è\n",
        "\n",
        "La forma m√°s intuitiva de entender el Descenso del Gradiente es a trav√©s de una analog√≠a.\n",
        "\n",
        "Imagina que est√°s en la cima de una monta√±a, con los ojos vendados, y tu objetivo es llegar al valle (el punto m√°s bajo).\n",
        "\n",
        "1.  **Tu Posici√≥n:** Tu posici√≥n actual en la monta√±a corresponde a los valores actuales de tus par√°metros **$(w_0, w_1)$**.\n",
        "2.  **El Objetivo:** El valle corresponde al **m√≠nimo global** de la funci√≥n de costes $J$.\n",
        "\n",
        "Como est√°s vendado, no puedes ver el valle, pero puedes sentir el suelo bajo tus pies. ¬øC√≥mo te mueves de manera eficiente?\n",
        "\n",
        "* **Paso 1: Siente la Pendiente:** Tientas el suelo a tu alrededor para determinar la direcci√≥n en la que la pendiente es **m√°s pronunciada hacia abajo**. Esta direcci√≥n de m√°ximo descenso es el **gradiente**.\n",
        "* **Paso 2: Da un Paso:** Una vez que conoces la direcci√≥n, das un paso. El tama√±o de ese paso est√° determinado por la **tasa de aprendizaje**.\n",
        "* **Paso 3: Repite:** Repites este proceso (sentir la pendiente y dar un paso) hasta que llegas a un punto donde ya no puedes bajar m√°s.\n",
        "\n",
        "El Descenso del Gradiente hace exactamente esto, pero en el mundo de las matem√°ticas:\n",
        "\n",
        "### El Descenso del Gradiente en ML\n",
        "\n",
        "El algoritmo comienza con unos valores **iniciales aleatorios** para nuestros par√°metros $w_0$ y $w_1$ (est√°s en alg√∫n punto aleatorio de la monta√±a). Luego, repite un ciclo de actualizaci√≥n hasta la **convergencia**:\n",
        "\n",
        "#### 1. Calcular el Gradiente (La Direcci√≥n)\n",
        "\n",
        "El gradiente es una herramienta del c√°lculo (un vector de derivadas parciales) que nos dice exactamente cu√°l es la **pendiente** de la funci√≥n de costes $J$ en nuestra posici√≥n actual $(w_0, w_1)$.\n",
        "\n",
        "* Si la pendiente es positiva, significa que estamos a la izquierda del m√≠nimo y debemos reducir el valor de $w$.\n",
        "* Si la pendiente es negativa, estamos a la derecha y debemos aumentar el valor de $w$.\n",
        "\n",
        "Matem√°ticamente, el gradiente apunta siempre hacia la **m√°xima subida**. Por lo tanto, si queremos *descender* (minimizar el coste), debemos movernos en la **direcci√≥n opuesta** al gradiente. Esto explica el signo negativo que introduciremos.\n",
        "\n",
        "#### 2. La Actualizaci√≥n de los Par√°metros (El Paso)\n",
        "\n",
        "En cada iteraci√≥n, actualizamos **simult√°neamente** $w_0$ y $w_1$ usando la siguiente regla:\n",
        "\n",
        "$$\\text{Nuevo } w_j = \\text{Antiguo } w_j - (\\text{Tasa de Aprendizaje } \\times \\text{ Gradiente})$$\n",
        "\n",
        "Donde $w_j$ representa cualquiera de nuestros par√°metros ($w_0$ o $w_1$).\n",
        "\n",
        "El signo de resta es lo que garantiza el \"descenso\": estamos movi√©ndonos en contra de la direcci√≥n de la pendiente.\n",
        "\n",
        "Los detalles de c√≥mo se calcula el gradiente y c√≥mo se elige la tasa de aprendizaje son cruciales y se explican a continuaci√≥n."
      ],
      "metadata": {
        "id": "t93VaGLxlGQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. üß© Las Piezas Clave del Algoritmo\n",
        "\n",
        "El Descenso del Gradiente es simple, pero su eficacia reside en la correcta aplicaci√≥n de dos componentes esenciales: el **Gradiente** (la direcci√≥n de la pendiente) y la **Tasa de Aprendizaje** (el tama√±o del paso).\n",
        "\n",
        "### A. El Gradiente: La Direcci√≥n de M√°ximo Descenso\n",
        "\n",
        "Necesitamos calcular la pendiente de la funci√≥n de costes $J(w_0, w_1)$ en nuestra posici√≥n actual. Esto se logra calculando las **derivadas parciales** de $J$ con respecto a cada par√°metro ($w_0$ y $w_1$).\n",
        "\n",
        "El resultado de estas derivadas nos dice cu√°nto cambiar√≠a el coste $J$ si modific√°ramos ligeramente un par√°metro, manteniendo el otro fijo.\n",
        "\n",
        "### El Gradiente\n",
        "\n",
        "El gradiente es un vector que apunta en la direcci√≥n de m√°ximo crecimiento. Se calcula con las derivadas parciales de la funci√≥n de costes con respecto a cada par√°metro.\n",
        "\n",
        "Derivando $J(w_0, w_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$ con respecto a cada par√°metro, obtenemos inicialmente un t√©rmino negativo: $-\\frac{1}{m}\\sum(y_i - \\hat{y}_i)$.\n",
        "\n",
        "Para simplificar la notaci√≥n y eliminar el signo negativo, **reordenamos algebraicamente** la resta:\n",
        "$$-(y_i - \\hat{y}_i) = (\\hat{y}_i - y_i)$$\n",
        "\n",
        "Esto nos da las siguientes f√≥rmulas del gradiente:\n",
        "\n",
        "1.  **Gradiente con respecto a $w_0$ (el sesgo):**\n",
        "    $$\\frac{\\partial J}{\\partial w_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)$$\n",
        "    \n",
        "    *Esta derivada es la media de los errores de predicci√≥n.*\n",
        "\n",
        "2.  **Gradiente con respecto a $w_1$ (el peso/pendiente):**\n",
        "    $$\\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i) \\cdot x_i$$\n",
        "    \n",
        "    *Esta derivada pondera los errores por el valor de $x_i$.*\n",
        "\n",
        "---\n",
        "\n",
        "### B. La Tasa de Aprendizaje ($\\alpha$): El Tama√±o del Paso\n",
        "\n",
        "La **tasa de aprendizaje** ($\\alpha$) es un **hiperpar√°metro** fundamental que controla la magnitud de los pasos que damos en la direcci√≥n del gradiente.\n",
        "\n",
        "#### La Regla de Actualizaci√≥n\n",
        "\n",
        "Con la direcci√≥n del gradiente y el tama√±o del paso $\\alpha$, definimos la regla de actualizaci√≥n. Esta se aplica repetidamente durante un n√∫mero predefinido de iteraciones (**√©pocas**):\n",
        "\n",
        "Repetir (Iteraciones/√âpocas) {\n",
        "\n",
        "$$w_0 := w_0 - \\alpha \\frac{\\partial J}{\\partial w_0}$$\n",
        "$$w_1 := w_1 - \\alpha \\frac{\\partial J}{\\partial w_1}$$\n",
        "\n",
        "}\n",
        "\n",
        "#### El Impacto Cr√≠tico de $\\alpha$\n",
        "\n",
        "Elegir la $\\alpha$ correcta es un acto de equilibrio:\n",
        "\n",
        "| Si $\\alpha$ es... | Consecuencia... |\n",
        "| :--- | :--- |\n",
        "| **Demasiado Peque√±a** | Convergencia **extremadamente lenta**. Se necesitan miles de √©pocas. |\n",
        "| **Correcta** | Convergencia eficiente, acerc√°ndose al m√≠nimo en un n√∫mero razonable de pasos. |\n",
        "| **Demasiado Grande** | **Divergencia** u **oscilaci√≥n**. El modelo salta de un lado a otro, o se aleja del m√≠nimo, haciendo que el coste $J$ aumente. |\n",
        "\n",
        "El impacto de $\\alpha$ es particularmente sensible cuando las caracter√≠sticas de entrada tienen rangos de valores muy diferentes. De hecho, esta sensibilidad extrema es la raz√≥n principal por la que la **normalizaci√≥n de caracter√≠sticas** es un paso obligatorio en la pr√°ctica, ya que permite usar un $\\alpha$ m√°s grande sin riesgo de divergencia.\n",
        "\n",
        "---\n",
        "\n",
        "### C. Nota sobre el C√°lculo Simult√°neo\n",
        "\n",
        "Es vital entender que, dentro de cada paso (cada √©poca), las actualizaciones de $w_0$ y $w_1$ deben realizarse **simult√°neamente**.\n",
        "\n",
        "Esto significa que primero se deben calcular *ambas* derivadas (gradientes) utilizando los valores de $w_0$ y $w_1$ de la *iteraci√≥n anterior*. Una vez que se tienen los dos gradientes, se actualizan ambos par√°metros a sus nuevos valores. Si se actualizara $w_0$ y luego se usara el *nuevo* $w_0$ para calcular la derivada de $w_1$, se introducir√≠a un sesgo en el algoritmo que podr√≠a llevar a resultados incorrectos."
      ],
      "metadata": {
        "id": "z9fpRWAwmrz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5\\. üë®‚Äçüíª Manos a la Obra: Implementaci√≥n \"Manual\" con Python y NumPy\n",
        "\n",
        "Pasamos de la teor√≠a a la pr√°ctica programando el algoritmo de **Regresi√≥n Lineal con Descenso de Gradiente (Gradient Descent)** desde cero. Usaremos las librer√≠as NumPy para las operaciones matriciales eficientes y Matplotlib para la visualizaci√≥n.\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.1. Importaci√≥n y Preparaci√≥n de Datos\n",
        "\n",
        "Comenzamos importando las librer√≠as necesarias y creando un conjunto de datos de ejemplo. Utilizaremos una relaci√≥n lineal simple a la que a√±adiremos un poco de \"ruido\" aleatorio para simular datos reales."
      ],
      "metadata": {
        "id": "mazwxGYYpSmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear datos de ejemplo\n",
        "np.random.seed(42) # Fijar semilla para reproducibilidad\n",
        "\n",
        "# Variable independiente X (caracter√≠stica)\n",
        "X = 2 * np.random.rand(100, 1) # 100 valores entre 0 y 2\n",
        "\n",
        "# Variable dependiente y (objetivo)\n",
        "# Relaci√≥n real: y = 4 + 3 * X + ruido\n",
        "y = 4 + 3 * X + np.random.randn(100, 1) * 1.5 # El ruido es esencial\n",
        "y = y.ravel()  # Aplanamos 'y' a un vector 1D de forma (100,)\n",
        "\n",
        "print(\"Dimensiones de los datos\")\n",
        "print(f\"Forma de X: {X.shape}, y: {y.shape}\\n\")\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, alpha=0.7, label='Datos reales')\n",
        "plt.xlabel('Tama√±o (normalizado)')\n",
        "plt.ylabel('Precio')\n",
        "plt.title('Datos de Entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tg47hHkfp0ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.2. Escalamiento de Caracter√≠sticas (Estandarizaci√≥n)\n",
        "\n",
        "**Importante:** Antes de iniciar el Descenso de Gradiente, es **crucial** realizar el **Escalado de Caracter√≠sticas** (*Feature Scaling*).\n",
        "\n",
        "#### üí° ¬øPor qu√© es crucial el Escalado?\n",
        "\n",
        "El Descenso de Gradiente funciona mejor cuando las caracter√≠sticas de entrada (las columnas de $X$) est√°n en una escala similar. Si una caracter√≠stica tiene valores mucho mayores que otra, la funci√≥n de costes ($J(w)$) se vuelve muy asim√©trica (una \"elipse\" alargada).\n",
        "\n",
        "  * **Funci√≥n de Costes Asim√©trica:** Esto hace que las derivadas (el gradiente) sean desproporcionadamente grandes en la direcci√≥n de la caracter√≠stica con mayor escala.\n",
        "  * **Convergencia Lenta o Divergencia:** El algoritmo tendr√° que dar \"pasos\" muy peque√±os en ciertas direcciones, haciendo que la convergencia sea **extremadamente lenta** o, en el peor de los casos, **diverja**.\n",
        "\n",
        "La **Estandarizaci√≥n** (o *Z-score normalization*) transforma los datos para que tengan una media ($\\mu$) de 0 y una desviaci√≥n est√°ndar ($\\sigma$) de 1, haciendo que el valle de costes sea m√°s sim√©trico y permitiendo una convergencia m√°s r√°pida y estable.\n",
        "\n",
        "$$X_{\\text{estandarizado}} = X' = \\frac{X - \\mu}{\\sigma}$$\n",
        "\n",
        "#### üîÑ El Problema: Pesos en el Espacio Estandarizado\n",
        "- Al estandarizar $X \\to X' = \\frac{X - \\mu}{\\sigma}$, el modelo ajusta:\n",
        "  $$\n",
        "  \\hat{y} = w_0' + w_1' \\cdot X'\n",
        "  $$\n",
        "- Pero **$w_0'$ y $w_1'$ est√°n en el espacio estandarizado**, no en el original.\n",
        "\n",
        "#### ‚úÖ Soluci√≥n (obligatoria): Desnormalizaci√≥n de los Pesos\n",
        "Posteriormente debemos **transformar los pesos al espacio original**:\n",
        "\n",
        "$$\n",
        "w_1 = \\frac{w_1'}{\\sigma}, \\quad w_0 = w_0' - w_1' \\cdot \\frac{\\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "O, sustituyendo la primera en la segunda:\n",
        "\n",
        "$$w_0 = w_0' - w_1 \\cdot \\mu$$\n",
        "\n",
        "### C√≥digo para la estandarizaci√≥n\n",
        "Estandarizamos $X$ y luego crearemos la matriz aumentada `X_b` a√±adiendo una columna de unos para el t√©rmino de sesgo $w_0$."
      ],
      "metadata": {
        "id": "HXuHd1w3rUik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular media y desviaci√≥n est√°ndar\n",
        "mu = X.mean()\n",
        "sigma = X.std()\n",
        "\n",
        "print(f\"Media (Œº): {mu:.4f}\")\n",
        "print(f\"Desviaci√≥n est√°ndar (œÉ): {sigma:.4f}\")\n",
        "print()\n",
        "\n",
        "# Estandarizar: X' = (X - Œº) / œÉ\n",
        "X_scaled = (X - mu) / sigma\n",
        "\n",
        "# A√±adir columna de 1s para w0 (el sesgo)\n",
        "# np.c_ concatena arrays por columnas\n",
        "X_b = np.c_[np.ones((100, 1)), X_scaled]\n",
        "\n",
        "# Mostramos las 5 primeras filas de la matriz\n",
        "X_b[:5] # Columna 0: bias (1s), Columna 1: X escalado"
      ],
      "metadata": {
        "id": "r0GEhKRna9XY",
        "outputId": "c08dbe07-3b4b-4844-d539-f41b5d602729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media (Œº): 0.9404\n",
            "Desviaci√≥n est√°ndar (œÉ): 0.5920\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.32311215],\n",
              "       [ 1.        ,  1.62343393],\n",
              "       [ 1.        ,  0.88450935],\n",
              "       [ 1.        ,  0.43404902],\n",
              "       [ 1.        , -1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> El bias (`w0`) no se escala porque representa el valor predicho cuando todas las caracter√≠sticas son cero; a√±adir una columna de unos despu√©s del escalado mantiene su interpretaci√≥n original."
      ],
      "metadata": {
        "id": "ZL1KrfzAVNG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5.3. Implementaci√≥n del Descenso de Gradiente\n",
        "\n",
        "Ahora implementamos el n√∫cleo del algoritmo, siguiendo la f√≥rmula del Descenso de Gradiente.\n",
        "\n",
        "**F√≥rmulas Clave (Vectorial):**\n",
        "\n",
        "1.  **Predicci√≥n:** $\\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w}$\n",
        "2.  **Funci√≥n de Coste (MSE/2):** $J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2$\n",
        "3.  **Regla de Actualizaci√≥n:** $\\mathbf{w} := \\mathbf{w} - \\alpha \\cdot \\frac{1}{m} \\cdot \\mathbf{X}^{\\text{T}} \\cdot (\\hat{\\mathbf{y}} - \\mathbf{y})$"
      ],
      "metadata": {
        "id": "vLjlunD2sJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperpar√°metros\n",
        "learning_rate = 0.01    # alpha (tasa de aprendizaje)\n",
        "epochs = 1000           # n√∫mero de iteraciones\n",
        "m = len(X)              # n√∫mero de ejemplos de entrenamiento\n",
        "tol = 1e-5              # criterio de parada (early stopping)\n",
        "prev_cost = np.inf      # coste anterior (inicial infinito)\n",
        "\n",
        "# Inicializaci√≥n\n",
        "w = np.zeros(2)         # w[0] = w0 (bias), w[1] = w1 (pendiente)\n",
        "cost_history = []\n",
        "w0_history = []\n",
        "w1_history = []\n",
        "\n",
        "# Bucle de entrenamiento (las epochs)\n",
        "for epoch in range(epochs):\n",
        "    # Predicciones: ≈∑ = X_b @ w  (X_b tiene columna de 1s)\n",
        "    y_pred = X_b @ w        # shape: (m,) porque w es 1D\n",
        "\n",
        "    # Error\n",
        "    errors = y_pred - y     # El error es (≈∑ - y). shape: (m, 1)\n",
        "\n",
        "    # Gradiente: (1/m) * X_transpuesta * Errores\n",
        "    gradients = (1/m) * X_b.T @ errors      # shape: (2,)\n",
        "\n",
        "    # Actualizaci√≥n simult√°nea de par√°metros: w := w - alpha * gradiente\n",
        "    w = w - learning_rate * gradients\n",
        "\n",
        "    # Coste de cada paso (MSE/2)\n",
        "    cost = (1/(2*m)) * np.sum(errors**2)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    # Guardar par√°metros\n",
        "    w0_history.append(w[0])\n",
        "    w1_history.append(w[1])\n",
        "\n",
        "    # Early stopping\n",
        "    # si la mejora en el coste es menor a la tolerancia, se detiene el entrenamiento\n",
        "    if prev_cost - cost < tol:\n",
        "        print(f\"Convergencia alcanzada en la √©poca {epoch}\")\n",
        "        break\n",
        "    prev_cost = cost\n",
        "\n",
        "# Pesos √≥ptimos (en espacio estandarizado)\n",
        "w_optimal = w.copy()  # buena pr√°ctica: no modificar w despu√©s del bucle\n",
        "\n",
        "# --- REVERTIR LA ESTANDARIZACI√ìN (Desnormalizaci√≥n) ---\n",
        "# Par√°metros estandarizados\n",
        "w0_prime = w_optimal[0]   # intercepto en espacio escalado\n",
        "w1_prime = w_optimal[1]   # pendiente en espacio escalado\n",
        "\n",
        "# 1. Pendiente Original: w1 = w1' / sigma\n",
        "w1_original = w1_prime / sigma\n",
        "\n",
        "# 2. Intercepto Original: w0 = w0' - w1_original * mu\n",
        "w0_original = w0_prime - w1_original * mu\n",
        "\n",
        "print(f\"w0' (estandarizado): {w0_prime:.6f}\")\n",
        "print(f\"w1' (estandarizado): {w1_prime:.6f}\")\n",
        "print(\"\\n--- Par√°metros √ìptimos en el espacio de datos ORIGINAL ---\")\n",
        "# La relaci√≥n real es y = 4 + 3 * X + ruido\n",
        "print(f\"w0 (Intercepto original): {w0_original:.4f} (~4.0)\")\n",
        "print(f\"w1 (Pendiente original): {w1_original:.4f} (~3.0)\")"
      ],
      "metadata": {
        "id": "UBQLoV7pVmAO",
        "outputId": "a84c6d30-4348-41f1-b149-f7e29a87cb0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en la √©poca 539\n",
            "w0' (estandarizado): 6.789489\n",
            "w1' (estandarizado): 1.564942\n",
            "\n",
            "--- Par√°metros √ìptimos en el espacio de datos ORIGINAL ---\n",
            "w0 (Intercepto original): 4.3036 (~4.0)\n",
            "w1 (Pendiente original): 2.6435 (~3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 5.4. Interpretaci√≥n Correcta: Revertir la Estandarizaci√≥n\n",
        "\n",
        "Los par√°metros $w_0'$ y $w_1'$ que ha encontrado nuestro algoritmo son √≥ptimos, pero solo son v√°lidos para la versi√≥n **estandarizada** de la caracter√≠stica $X$. Si los compar√°ramos directamente con la relaci√≥n real de nuestros datos ($y = 4 + 3x$), ver√≠amos una gran diferencia ($w_1' \\approx 1.5$ en lugar de $3$), lo que err√≥neamente sugerir√≠a que el modelo ha fallado.\n",
        "\n",
        "Esto no es un error, sino una consecuencia necesaria del escalado para lograr una convergencia eficiente. Para **interpretar** correctamente los resultados, debemos transformar los pesos de vuelta al espacio de datos original.\n",
        "\n",
        "La transformaci√≥n utiliza la media ($\\mu$) y la desviaci√≥n est√°ndar ($\\sigma$) que calculamos previamente:\n",
        "\n",
        "$$w_1 = \\frac{w_1'}{\\sigma}$$\n",
        "\n",
        "$$w_0 = w_0' - w1 \\cdot \\mu$$\n",
        "\n",
        "Al aplicar esta transformaci√≥n, vemos que el modelo ha convergido a los valores correctos de $w_0$ y $w_1$, verificando que el Descenso del Gradiente funcion√≥ con √©xito para descubrir la relaci√≥n subyacente de nuestros datos.\n",
        "\n",
        "-----\n",
        "\n",
        "### 5.5. Visualizaci√≥n de Resultados\n",
        "\n",
        "Para finalizar, ploteamos el historial de costes para confirmar que el algoritmo converge correctamente y visualizamos la l√≠nea de regresi√≥n final sobre los datos originales.\n",
        "\n",
        "#### 5.5.1. Gr√°fico del Historial de Costes\n",
        "\n",
        "El coste debe disminuir dr√°sticamente al inicio y luego aplanarse, indicando la convergencia."
      ],
      "metadata": {
        "id": "I8HHRmSAsqbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(cost_history, 'b.-', markersize=4)\n",
        "plt.title('Historial de Costes (con Early Stopping)')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Funci√≥n de Coste J(w)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- MENSAJE DE EARLY STOPPING ---\n",
        "if len(cost_history) < epochs:\n",
        "    print(f\"\\nEarly stopping activado: no fueron necesarias las {epochs} √©pocas. \")\n",
        "    print(f\"Convergencia alcanzada en {len(cost_history)} √©pocas.\")\n",
        "else:\n",
        "    print(f\"\\nSe completaron las {epochs} √©pocas sin activar early stopping.\")"
      ],
      "metadata": {
        "id": "1NtshbJksvFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.5.2. Gr√°fico de la Regresi√≥n Lineal\n",
        "\n",
        "Para plotear la l√≠nea de regresi√≥n, debemos usar los valores originales de $X$ (sin estandarizar) y aplicarles la misma estandarizaci√≥n antes de multiplicarlos por los $w$ √≥ptimos."
      ],
      "metadata": {
        "id": "y3nS1iIMszfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un rango de X para dibujar la l√≠nea\n",
        "X_plot = np.array([[0], [2]])\n",
        "\n",
        "# 1. Estandarizar X_plot de la misma forma que los datos de entrenamiento\n",
        "X_plot_scaled = (X_plot - mu) / sigma\n",
        "\n",
        "# 2. A√±adir el sesgo (columna de unos)\n",
        "X_plot_b = np.c_[np.ones((2, 1)), X_plot_scaled]\n",
        "\n",
        "# 3. Calcular las predicciones con los pesos (w) √≥ptimos\n",
        "# Usamos w_optimal que son los pesos estandarizados\n",
        "y_predict = X_plot_b @ w_optimal\n",
        "\n",
        "# Plotear los datos originales y la l√≠nea de regresi√≥n\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X, y, 'o', label='Datos originales')\n",
        "plt.plot(X_plot, y_predict, 'r-', label='Recta de Regresi√≥n')\n",
        "plt.title('Regresi√≥n Lineal con Descenso de Gradiente')\n",
        "plt.xlabel('X (Caracter√≠stica Original)')\n",
        "plt.ylabel('y (Objetivo)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ru5H5FOZs3Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta forma, hemos implementado el Descenso de Gradiente de forma manual, mostrando c√≥mo el algoritmo itera para encontrar los par√°metros $w_0$ y $w_1$ que minimizan la funci√≥n de costes y definen la l√≠nea de mejor ajuste."
      ],
      "metadata": {
        "id": "7dG6VElxpQo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6\\. ‚ö° La V√≠a R√°pida: Implementaci√≥n con Scikit-Learn\n",
        "\n",
        "Tras haber programado la **Regresi√≥n Lineal con Descenso de Gradiente** manualmente, el objetivo de esta secci√≥n es mostrar c√≥mo se realiza esta tarea en un **entorno profesional** utilizando la librer√≠a est√°ndar de *machine learning* en Python: **Scikit-Learn (sklearn)**.\n",
        "\n",
        "El modelo que utilizaremos es `sklearn.linear_model.SGDRegressor`.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.1. ¬øPor qu√© `SGDRegressor`?\n",
        "\n",
        "Mientras que en el apartado anterior implementamos el **Descenso de Gradiente por Lotes (*Batch Gradient Descent*)**, Scikit-Learn ofrece una variante mucho m√°s com√∫n y eficiente para datos grandes: el **Descenso de Gradiente Estoc√°stico (*Stochastic Gradient Descent - SGD*)**.\n",
        "\n",
        "#### Concepto Clave: SGD\n",
        "\n",
        "El SGD es una variante del Descenso de Gradiente donde, en lugar de calcular el gradiente usando **todos** los ejemplos de entrenamiento (*batch* completo) en cada paso, el algoritmo:\n",
        "\n",
        "1.  Calcula el gradiente usando **un solo ejemplo** de entrenamiento seleccionado al azar (o un peque√±o subconjunto llamado *mini-batch*).\n",
        "2.  Actualiza los par√°metros $w$ inmediatamente.\n",
        "\n",
        "Esta aproximaci√≥n hace que el proceso sea **mucho m√°s r√°pido** en *datasets* con millones de datos, aunque el camino hacia el m√≠nimo de la funci√≥n de costes es m√°s ruidoso y aleatorio. Para la regresi√≥n lineal, el `SGDRegressor` es la herramienta est√°ndar cuando se desea aplicar el Descenso de Gradiente.\n",
        "\n",
        "### Variantes del Descenso del Gradiente\n",
        "\n",
        "Existen diversas variantes del Descenso del Gradiente, adaptadas a diferentes tama√±os de datos y necesidades computacionales:\n",
        "\n",
        "**1. Batch Gradient Descent (por lotes)**\n",
        "- Como el que implementamos manualmente.\n",
        "- Calcula el gradiente usando **todo el conjunto de datos** en cada iteraci√≥n.\n",
        "- **Ventaja:** Direcci√≥n precisa hacia el m√≠nimo.\n",
        "- **Desventaja:** Lento y requiere mucha memoria para datasets grandes.\n",
        "\n",
        "**2. Stochastic Gradient Descent (SGD)**\n",
        "- Actualiza los par√°metros con **un solo ejemplo aleatorio** por iteraci√≥n.\n",
        "- **Ventaja:** Mucho m√°s r√°pido.\n",
        "- **Desventaja:** Trayectoria m√°s \"ruidosa\" y zigzagueante hacia el m√≠nimo.\n",
        "\n",
        "**3. Mini-Batch Gradient Descent**\n",
        "- Equilibra ambos enfoques al usar **peque√±os subconjuntos (mini-batches)** de datos.\n",
        "- **Ventaja:** Combina velocidad y estabilidad.\n",
        "- **Nota:** Esta es la variante m√°s com√∫n en *deep learning* y se puede configurar en `SGDRegressor` con el par√°metro `batch_size`.\n",
        "\n",
        "-----\n",
        "\n",
        "### 6.2. Implementaci√≥n con Scikit-Learn\n",
        "\n",
        "A diferencia de la implementaci√≥n manual, Scikit-Learn requiere que el escalado de caracter√≠sticas y el modelo se manejen como objetos separados.\n",
        "\n",
        "#### 6.2.1. Preparaci√≥n y Escalado de Datos\n",
        "\n",
        "**Nota Importante:** Usaremos los datos originales $X$ e $y$ del apartado 5 para el proceso de escalado."
      ],
      "metadata": {
        "id": "mPBbTXkl0u8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Datos originales (asumimos que X e y son los del apartado 5)\n",
        "# X (100, 1), y (100, 1)\n",
        "\n",
        "# 1. Ajustar la forma de 'y' si es necesario (Scikit-Learn prefiere (n_samples,))\n",
        "y_flat = y.ravel()\n",
        "\n",
        "# 2. Crear y ajustar el StandardScaler\n",
        "# El escalador calcular√° la media y la desviaci√≥n est√°ndar de X y la almacenar√°\n",
        "scaler = StandardScaler()\n",
        "X_scaled_skl = scaler.fit_transform(X)\n",
        "X_scaled_skl[:5]"
      ],
      "metadata": {
        "id": "SY3bfQ0s0zyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd2af91-fa3c-4b07-c239-8daebd96818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.32311215],\n",
              "       [ 1.62343393],\n",
              "       [ 0.88450935],\n",
              "       [ 0.43404902],\n",
              "       [-1.06136481]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.2. Entrenamiento del Modelo `SGDRegressor`\n",
        "\n",
        "Instanciamos y entrenamos el modelo. Es crucial especificar los hiperpar√°metros que controlan el proceso de optimizaci√≥n:\n",
        "\n",
        "* `loss='squared_error'`: Indica que queremos minimizar el Error Cuadr√°tico Medio (MSE), la funci√≥n de costes adecuada para la regresi√≥n lineal.\n",
        "* `eta0`: La tasa de aprendizaje inicial ($\\alpha$), que determina el tama√±o de los pasos.\n",
        "* `max_iter`: El n√∫mero de √©pocas o pasadas completas a trav√©s del conjunto de datos.\n",
        "* `learning_rate='constant'` (por defecto): Mantiene `eta0` constante durante todo el entrenamiento. Otras opciones incluyen `'optimal'`, `'invscaling'` y `'adaptive'`.\n",
        "\n",
        "Una vez finalizado el entrenamiento, desnormalizamos los pesos encontrados (`coef_` e `intercept_`) usando la media y desviaci√≥n est√°ndar almacenadas previamente en el objeto `scaler`."
      ],
      "metadata": {
        "id": "iPsk-iPn09Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Crear una instancia de SGDRegressor\n",
        "sgd_reg = SGDRegressor(\n",
        "    loss='squared_error',\n",
        "    eta0=0.01,         # Learning rate (alpha)\n",
        "    max_iter=1000,     # N√∫mero de √©pocas\n",
        "    tol=1e-5,          # Criterio de parada\n",
        "    random_state=42    # Para obtener resultados reproducibles\n",
        ")\n",
        "\n",
        "# 4. Entrenar el modelo con los datos escalados\n",
        "sgd_reg.fit(X_scaled_skl, y_flat)\n",
        "\n",
        "# 5. Mostrar los par√°metros encontrados\n",
        "\n",
        "# Pesos estandarizados (w')\n",
        "w_0_prime_skl = sgd_reg.intercept_[0]\n",
        "w_1_prime_skl = sgd_reg.coef_[0]\n",
        "\n",
        "# --- REVERTIR LA ESTANDARIZACI√ìN (Desnormalizaci√≥n) ---\n",
        "# Usamos las propiedades almacenadas por el scaler: .mean_ y .scale_\n",
        "mu_skl = scaler.mean_[0]\n",
        "sigma_skl = scaler.scale_[0]\n",
        "\n",
        "# 1. Pendiente Original: w1 = w1' / sigma\n",
        "w1_original_skl = w_1_prime_skl / sigma_skl\n",
        "\n",
        "# 2. Intercepto Original: w0 = w0' - w1_original * mu\n",
        "w0_original_skl = w_0_prime_skl - w1_original_skl * mu_skl\n",
        "\n",
        "\n",
        "print(\"\\n--- Par√°metros √ìptimos encontrados por SGDRegressor (ESTANDARIZADOS) ---\")\n",
        "print(f\"w0' (Intercepto estandarizado): {w_0_prime_skl:.4f}\")\n",
        "print(f\"w1' (Pendiente estandarizada): {w_1_prime_skl:.4f}\")\n",
        "print(\"\\n--- Par√°metros √ìptimos en el espacio de datos ORIGINAL ---\")\n",
        "# La relaci√≥n real era y = 4 + 3 * X + ruido\n",
        "print(f\"w0 (Intercepto original): {w0_original_skl:.4f} (~4.0)\")\n",
        "print(f\"w1 (Pendiente original): {w1_original_skl:.4f} (~3.0)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-wdihhqfUfJ",
        "outputId": "ffd2ed61-b5c0-42d8-ecaa-060a196ae34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Par√°metros √ìptimos encontrados por SGDRegressor (ESTANDARIZADOS) ---\n",
            "w0' (Intercepto estandarizado): 6.8214\n",
            "w1' (Pendiente estandarizada): 1.5721\n",
            "\n",
            "--- Par√°metros √ìptimos en el espacio de datos ORIGINAL ---\n",
            "w0 (Intercepto original): 4.3242 (~4.0)\n",
            "w1 (Pendiente original): 2.6555 (~3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 6.3. Comparaci√≥n de Resultados\n",
        "\n",
        "Comparamos los resultados de la implementaci√≥n manual (Descenso de Gradiente por Lotes) y la implementaci√≥n profesional de Scikit-Learn (Descenso de Gradiente Estoc√°stico) **despu√©s de revertir la estandarizaci√≥n**.\n",
        "\n",
        "| Par√°metro (Original) | Manual (Batch GD) | Scikit-Learn (SGDRegressor) | Realidad Subyacente ($y=4+3x$) |\n",
        "| :---: | :---: | :---: | :---: |\n",
        "| $w_0$ (Intercepto) | $4.30 $ | $4.32 $ | **$4$** |\n",
        "| $w_1$ (Pendiente) | $2.64$ | $2.66 $ | **$3$** |\n",
        "\n",
        "Los resultados son pr√°cticamente **iguales** y ambos se aproximan con √©xito a los par√°metros reales de $4$ y $3$ de nuestros datos generados.  \n",
        "\n",
        "Las peque√±as **discrepancias entre las estimaciones y los valores reales** (4 y 3) se deben al ruido aleatorio que introdujimos al generar el conjunto de datos. Esto demuestra que la Regresi√≥n Lineal ha encontrado la l√≠nea de mejor ajuste para los datos observados.\n",
        "\n",
        "> **Experimento:** Puedes ver otros valores ligeramente diferentes variando la semilla de los n√∫meros aleatorios (por ejemplo, usando `random_state=44` en lugar de `42`).\n",
        "\n",
        "Esto permite verificar dos puntos fundamentales:\n",
        "\n",
        "1.  **Validaci√≥n de la teor√≠a:** Nuestra implementaci√≥n manual funcion√≥ correctamente.\n",
        "2.  **Eficiencia de la herramienta:** El `SGDRegressor` nos permite obtener los mismos resultados √≥ptimos con una fracci√≥n del c√≥digo, benefici√°ndonos de la optimizaci√≥n y robustez de una librer√≠a profesional.\n",
        "\n",
        "> **Nota:** Scikit-Learn tambi√©n ofrece `LinearRegression`, que permite calcular los par√°metros por el **m√©todo de M√≠nimos Cuadrados Ordinarios (OLS)** mediante una soluci√≥n anal√≠tica directa, en lugar del Descenso del Gradiente iterativo. Este m√©todo es m√°s r√°pido para datasets peque√±os o medianos (hasta decenas de miles de filas), pero no escala bien a millones de datos debido a la complejidad computacional de la inversi√≥n de matrices. Para aprendizaje online o datasets muy grandes, `SGDRegressor` es la opci√≥n preferida.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "w0HPZ77StqgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7\\. üöÄ Generalizando: De la Recta al Hiperplano (Regresi√≥n M√∫ltiple)\n",
        "\n",
        "Hasta ahora, hemos utilizado la Regresi√≥n Lineal Simple (una sola variable $x$) como herramienta did√°ctica. Sin embargo, en el mundo real, los problemas tienen m√∫ltiples factores o **caracter√≠sticas** ($x_1, x_2, \\dots, x_n$).\n",
        "\n",
        "### La Ecuaci√≥n se Convierte en un Hiperplano\n",
        "\n",
        "Cuando a√±adimos m√°s caracter√≠sticas, la ecuaci√≥n del modelo se extiende:\n",
        "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
        "\n",
        "  * Si tuvi√©ramos solo dos caracter√≠sticas ($x_1$ y $x_2$), la l√≠nea de mejor ajuste se convertir√≠a en un **plano** en un espacio tridimensional.\n",
        "  * Con tres o m√°s caracter√≠sticas, esta superficie se denomina **hiperplano** (un plano en un espacio de $n$ dimensiones).\n",
        "\n",
        "### La Ventaja de la Notaci√≥n Matricial\n",
        "\n",
        "La gran ventaja de haber utilizado la **notaci√≥n matricial** desde el principio es que la complejidad del Descenso del Gradiente **no aumenta** al a√±adir variables.\n",
        "\n",
        "Nuestras f√≥rmulas clave de optimizaci√≥n (para la predicci√≥n y el gradiente) son exactamente las mismas:\n",
        "\n",
        "| Concepto | F√≥rmula Matricial (General) |\n",
        "| :--- | :--- |\n",
        "| **Predicci√≥n** | $\\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w}$ |\n",
        "| **C√°lculo del Gradiente** | $\\mathbf{g} = \\frac{1}{m} \\mathbf{X}^{\\text{T}} (\\hat{\\mathbf{y}} - \\mathbf{y})$ |\n",
        "\n",
        "El c√≥digo de entrenamiento solo necesita que la matriz $\\mathbf{X}$ tenga m√°s columnas y el vector de pesos $\\mathbf{w}$ tenga m√°s filas. El proceso de c√°lculo se mantiene id√©ntico.\n",
        "\n",
        "-----\n",
        "\n",
        "### 7.1. Caso con Dos Variables Independientes ($x_1, x_2$)\n",
        "\n",
        "Utilizamos `SGDRegressor` para encontrar los tres par√°metros ($w_0, w_1, w_2$) de un modelo basado en la relaci√≥n real $\\mathbf{y = 4 + 3x_1 + 5x_2 + ruido}$."
      ],
      "metadata": {
        "id": "TZJeizRld3eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Generaci√≥n de Datos con dos variables\n",
        "W_REAL = np.array([4, 3, 5])\n",
        "np.random.seed(42)\n",
        "\n",
        "# Ambos con el mismo rango para mejor visualizaci√≥n posterior\n",
        "X1 = 2 * np.random.rand(1000, 1)  # X1: rango [0, 2]\n",
        "X2 = 2 * np.random.rand(1000, 1)  # X2: rango [0, 2]\n",
        "X_multi = np.hstack([X1, X2])\n",
        "\n",
        "# Misma relaci√≥n real: y = 4 + 3*X1 + 5*X2 + ruido\n",
        "y_multi = W_REAL[0] + W_REAL[1] * X1 + W_REAL[2] * X2 + np.random.randn(1000, 1) * 2\n",
        "y_flat = y_multi.ravel()\n",
        "\n",
        "# 2. Escalado. Estas dos variables tienen la misma escala pero\n",
        "# sigue siendo necesario por si usamos m√°s variables despu√©s\n",
        "scaler = StandardScaler()\n",
        "X_scaled_multi = scaler.fit_transform(X_multi)\n",
        "\n",
        "# 3. Entrenamiento con SGD\n",
        "sgd_reg = SGDRegressor(\n",
        "    loss='squared_error',\n",
        "    eta0=0.01,\n",
        "    max_iter=1000,\n",
        "    tol=1e-5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "sgd_reg.fit(X_scaled_multi, y_flat)\n",
        "\n",
        "# 4. Desnormalizaci√≥n (Para obtener w0, w1, w2 originales)\n",
        "w_0_prime = sgd_reg.intercept_[0]\n",
        "w_1_prime, w_2_prime = sgd_reg.coef_\n",
        "\n",
        "mu, sigma = scaler.mean_, scaler.scale_\n",
        "\n",
        "w1_original = w_1_prime / sigma[0]\n",
        "w2_original = w_2_prime / sigma[1]\n",
        "w0_original = w_0_prime - (w1_original * mu[0]) - (w2_original * mu[1])\n",
        "\n",
        "print(\"\\n--- Resultados con Regresi√≥n M√∫ltiple (2 Variables) ---\")\n",
        "print(f\"w0 (Intercepto): {w0_original:.3f} (Real: {W_REAL[0]})\")\n",
        "print(f\"w1 (Peso X1): {w1_original:.3f} (Real: {W_REAL[1]})\")\n",
        "print(f\"w2 (Peso X2): {w2_original:.3f} (Real: {W_REAL[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guzm2buuhoKi",
        "outputId": "e41542fa-1fbb-4f5c-bddb-286e98038695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados con Regresi√≥n M√∫ltiple (2 Variables) ---\n",
            "w0 (Intercepto): 4.039 (Real: 4)\n",
            "w1 (Peso X1): 2.967 (Real: 3)\n",
            "w2 (Peso X2): 5.014 (Real: 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta prueba final confirma que el **Descenso del Gradiente** es una herramienta escalable que funciona de manera an√°loga para encontrar los par√°metros √≥ptimos de un hiperplano, resolviendo problemas de *Regresi√≥n M√∫ltiple*."
      ],
      "metadata": {
        "id": "xodsGkB8hw_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 7.2. Visualizaci√≥n: El Plano de Regresi√≥n (3D)\n",
        "\n",
        "Ahora, el c√≥digo corregido para la visualizaci√≥n del plano. Se muestra que el algoritmo ha encontrado el plano √≥ptimo que minimiza el error cuadr√°tico medio en el espacio 3D."
      ],
      "metadata": {
        "id": "0A3IeYwDk_gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualizaci√≥n 3D ---\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "\n",
        "# 1. Malla m√°s fina\n",
        "x1_surf = np.linspace(X1.min(), X1.max(), 40)\n",
        "x2_surf = np.linspace(X2.min(), X2.max(), 40)\n",
        "x1_surf, x2_surf = np.meshgrid(x1_surf, x2_surf)\n",
        "\n",
        "# Plano con par√°metros originales\n",
        "Z = w0_original + w1_original * x1_surf + w2_original * x2_surf\n",
        "\n",
        "# 2. Figura grande\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# --- Puntos: grandes y con borde blanco para resaltar ---\n",
        "ax.scatter(X1, X2, y_multi,\n",
        "           c='navy', marker='o', s=40, alpha=0.8,\n",
        "           edgecolors='white', linewidth=0.5, depthshade=True)\n",
        "\n",
        "# --- Plano: color suave, opaco y con bordes ---\n",
        "ax.plot_surface(x1_surf, x2_surf, Z,\n",
        "                color='crimson', alpha=0.50,\n",
        "                linewidth=0.5, edgecolor='darkred', antialiased=True)\n",
        "\n",
        "# Etiquetas con salto de l√≠nea para evitar solapamiento\n",
        "ax.set_xlabel('\\n$X_1$ (Caract. 1)', fontsize=13, linespacing=1.5)\n",
        "ax.set_ylabel('\\n$X_2$ (Caract. 2)', fontsize=13, linespacing=1.5)\n",
        "ax.set_zlabel('\\nPrecio ($Y$)', fontsize=13, linespacing=1.5)\n",
        "ax.set_title('Regresi√≥n Lineal M√∫ltiple: Plano Ajustado\\n', fontsize=16, pad=40)\n",
        "\n",
        "# √ÅNGULO de visi√≥n: plano visible desde arriba y lateral\n",
        "ax.view_init(elev=32, azim=65)\n",
        "\n",
        "# Grid suave\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_facecolor('white')\n",
        "\n",
        "# --- LEYENDA FUERA DEL GR√ÅFICO ---\n",
        "point_proxy = Line2D([0], [0], linestyle=\"none\", marker='o',\n",
        "                     color='navy', markerfacecolor='navy',\n",
        "                     markeredgecolor='white', markersize=10)\n",
        "plane_proxy = Line2D([0], [0], linestyle=\"-\", color='crimson', linewidth=6)\n",
        "\n",
        "legend = fig.legend([point_proxy, plane_proxy],\n",
        "                    ['Datos de entrenamiento', 'Plano de Regresi√≥n'],\n",
        "                    loc='upper right',\n",
        "                    bbox_to_anchor=(0.88, 0.88),\n",
        "                    frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
        "\n",
        "legend.get_frame().set_facecolor('white')\n",
        "legend.get_frame().set_edgecolor('black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CGGkS8amkjCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. üéØ Conclusi√≥n: ¬øQu√© Hemos Aprendido?\n",
        "\n",
        "A lo largo de este art√≠culo, hemos desglosado la **Regresi√≥n Lineal** desde sus cimientos matem√°ticos hasta su implementaci√≥n pr√°ctica, comprendiendo que es mucho m√°s que una simple l√≠nea de mejor ajuste. Los conceptos que hemos cubierto forman la base de la optimizaci√≥n en casi todo el campo del *Machine Learning*.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumen de Puntos Clave\n",
        "\n",
        "* **Objetivo de la Regresi√≥n Lineal:** La meta fundamental de la Regresi√≥n Lineal es encontrar los par√°metros ($w_0$ y $w_1$) que definen la recta que mejor se ajusta a los datos.\n",
        "* **La Funci√≥n de Costes (MSE):** Para determinar qu√© tan \"buena\" es una recta, utilizamos una m√©trica de error, conocida com√∫nmente como el **Error Cuadr√°tico Medio (MSE)** o $J(w)$. El verdadero objetivo del modelo es **minimizar** el valor de esta funci√≥n.\n",
        "* **El Algoritmo de Optimizaci√≥n: Descenso de Gradiente:** El **Descenso de Gradiente (*Gradient Descent*)** es el algoritmo que nos permite alcanzar ese m√≠nimo. Podemos visualizarlo como un proceso iterativo en el que \"caminamos\" por la superficie de la funci√≥n de costes.\n",
        "    * **El Gradiente es la Br√∫jula:** El gradiente (las derivadas parciales) indica la **direcci√≥n de m√°ximo ascenso** en la funci√≥n de costes. Puesto que queremos *minimizar* el coste, nuestro paso va en la direcci√≥n **opuesta** al gradiente.\n",
        "    * **La Tasa de Aprendizaje ($\\alpha$) es el Tama√±o del Paso:** La **tasa de aprendizaje** determina la magnitud de cada paso. Si es muy grande, corremos el riesgo de \"saltar\" el m√≠nimo; si es muy peque√±a, la convergencia ser√° extremadamente lenta.\n",
        "* **El Escalado es Crucial, la Desnormalizaci√≥n es Obligatoria:** El **Escalado de Caracter√≠sticas** (Estandarizaci√≥n) es crucial para la **estabilidad y rapidez** del Descenso del Gradiente. Sin embargo, para la **interpretaci√≥n** correcta de los pesos finales ($w_0$ y $w_1$) en el contexto de los datos originales, es **obligatorio revertir** la estandarizaci√≥n de los par√°metros.\n",
        "* **Implementaciones (Manual vs. Scikit-Learn):** Hemos comprobado que, si bien es posible y educativo programar el algoritmo desde cero con NumPy (Batch Gradient Descent), en un entorno profesional se utiliza `SGDRegressor` de Scikit-Learn (Descenso Estoc√°stico), que ofrece la misma precisi√≥n con mayor eficiencia y rapidez en grandes vol√∫menes de datos.\n",
        "\n",
        "---\n",
        "\n",
        "### La Base de todo el *Machine Learning*\n",
        "\n",
        "El concepto de **Descenso de Gradiente** no se limita a la Regresi√≥n Lineal. La idea de definir una funci√≥n de costes, calcular su gradiente y ajustar par√°metros de forma iterativa es el **motor de optimizaci√≥n** de la inmensa mayor√≠a de los modelos de *Machine Learning* modernos, incluyendo:\n",
        "\n",
        "* **Regresi√≥n Log√≠stica.**\n",
        "* **M√°quinas de Soporte Vectorial (SVM).**\n",
        "* Y, de manera m√°s notable, el **Entrenamiento de Redes Neuronales Profundas**, donde la t√©cnica central es una aplicaci√≥n sofisticada del Descenso de Gradiente llamada **Retropropagaci√≥n (*Backpropagation*)**.\n",
        "\n",
        "Entender el Descenso de Gradiente es, por lo tanto, entender **c√≥mo aprende una m√°quina**."
      ],
      "metadata": {
        "id": "FmUj4QLlui91"
      }
    }
  ]
}