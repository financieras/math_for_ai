{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/math_for_ai/blob/main/estadistica/articulo2_evaluando_regresion_lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHfozEt_pNRE"
      },
      "source": [
        "# Evaluando Regresión Lineal: Métricas, Validación y Cuándo Usarla\n",
        "\n",
        "Ya sabes implementar regresión lineal por mínimos cuadrados. Pero un modelo que hace predicciones no es útil si no sabes **qué tan buenas son esas predicciones** y **cuándo es apropiado usarlo**.\n",
        "\n",
        "En este artículo aprenderás a:\n",
        "- Evaluar el rendimiento con métricas estándar (RMSE, R²)\n",
        "- Interpretar los resultados correctamente\n",
        "- Comparar tu implementación con scikit-learn\n",
        "- Identificar las ventajas y limitaciones del método\n",
        "- Decidir cuándo usar mínimos cuadrados vs otros enfoques\n",
        "\n",
        "**Nota**: Este artículo asume que ya implementaste regresión lineal por mínimos cuadrados. Si no lo has hecho, comienza por el artículo anterior donde construimos el modelo desde cero.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cxHYAK1pNRF"
      },
      "source": [
        "## Configuración inicial\n",
        "\n",
        "Primero recreamos el modelo que construimos en el artículo anterior:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xarx-Wo0pNRF",
        "outputId": "a73cf286-86a5-41e0-d233-7d184ac725a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes calculados:\n",
            "  w0 (intercept) = -17518.73 €\n",
            "  w1 (pendiente) = 3166.02 €/m²\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datos de ejemplo: tamaño de casa vs precio\n",
        "superficie = np.array([50, 55, 60, 64, 70, 78, 80, 89, 90, 100])\n",
        "precio = np.array([140000, 155000, 190000, 170000, 200000, 230000, 240000, 260000, 270000, 300000])\n",
        "\n",
        "# Matriz de diseño y función de mínimos cuadrados\n",
        "X = np.column_stack([np.ones(len(superficie)), superficie])\n",
        "y = precio\n",
        "\n",
        "def minimos_cuadrados(X, y):\n",
        "    \"\"\"Calcula los coeficientes óptimos usando mínimos cuadrados\"\"\"\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "\n",
        "# Calcular coeficientes\n",
        "w = minimos_cuadrados(X, y)\n",
        "precio_predicho = X @ w\n",
        "\n",
        "print(f\"Coeficientes calculados:\")\n",
        "print(f\"  w0 (intercept) = {w[0]:.2f} €\")\n",
        "print(f\"  w1 (pendiente) = {w[1]:.2f} €/m²\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdOYhHWvpNRG"
      },
      "source": [
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del modelo\n",
        "\n",
        "Para evaluar qué tan bien funciona nuestro modelo, utilizamos dos métricas fundamentales:\n",
        "\n",
        "**RMSE (Root Mean Square Error)**: Es la raíz cuadrada del MSE y nos dice el error promedio en las mismas unidades que nuestra variable objetivo (euros). Un RMSE bajo indica predicciones más precisas.\n",
        "\n",
        "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "**R² (Coeficiente de Determinación)**: Indica qué proporción de la variabilidad de los datos es explicada por nuestro modelo. Varía entre 0 y 1, donde 1 significa ajuste perfecto.\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
        "\n",
        "### Conexión con $R^2$: del \"cuánto se mueven juntos\" al \"cuánto explica el modelo\"\n",
        "\n",
        "Ahora viene la magia: **en regresión lineal simple (una sola variable), $R^2 = r^2$**.\n",
        "\n",
        "Es decir:\n",
        "- $R^2$ responde: *“¿Qué porcentaje de la variabilidad en $y$ explica mi modelo?”*\n",
        "- $r^2$ responde lo mismo, **pero partiendo solo de la correlación**.\n",
        "\n",
        "Por eso:\n",
        "- Si $r = 0.5$, entonces $R^2 = 0.25$ → el modelo explica el **25%** de la variabilidad.\n",
        "- Si $r = 0$, entonces $R^2 = 0$ → el modelo no explica nada.\n",
        "\n",
        "> **En resumen**:  \n",
        "> - Usa $r$ para entender la **relación cruda** entre $x$ e $y$ y ver el signo para saber si la relación es directa o inversa.  \n",
        "> - Usa $R^2$ para saber **cuánto de esa relación captura tu modelo lineal**, y expresar esa relación en porcentaje."
      ],
      "metadata": {
        "id": "dIv_SiLlmEGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos el error cuadrático medio (MSE) y RMSE\n",
        "mse = np.mean((precio - precio_predicho) ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Coeficiente de determinación R²\n",
        "ss_res = np.sum((precio - precio_predicho) ** 2)  # Suma de cuadrados de residuos\n",
        "ss_tot = np.sum((precio - precio.mean()) ** 2)    # Suma total de cuadrados\n",
        "r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Métricas de rendimiento\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MÉTRICAS DE RENDIMIENTO\")\n",
        "print(\"=\"*50)\n",
        "print(f\"R² (coeficiente de determinación): {r2:.3f}\")\n",
        "print(f\"  → El modelo explica el {r2*100:.1f}% de la variabilidad\")\n",
        "print(f\"\\nRMSE (raiz del error cuadrático medio): {rmse:,.2f}€\")\n",
        "print(f\"  → Error promedio de {rmse:,.0f} € en las predicciones\")"
      ],
      "metadata": {
        "id": "GZqDjZoKmH-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca60b5f6-d0c5-452e-94f2-4862fcb0dc95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MÉTRICAS DE RENDIMIENTO\n",
            "==================================================\n",
            "R² (coeficiente de determinación): 0.976\n",
            "  → El modelo explica el 97.6% de la variabilidad\n",
            "\n",
            "RMSE (raiz del error cuadrático medio): 7,748.54€\n",
            "  → Error promedio de 7,749 € en las predicciones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un $R^2$ de 0.9 indica que nuestro modelo es excelente, explicando el 90% de la variabilidad en los precios. Sin embargo, el RMSE de ~14.5k€ nos recuerda que aún hay margen de error considerable en las predicciones individuales.\n",
        "\n",
        "### Interpretación\n",
        "- Un MSE más bajo es mejor, pero su valor está en euros al cuadrado, lo que lo hace difícil de interpretar.  \n",
        "Por eso usamos el RMSE, que está en euros y representa el error promedio en las predicciones.\n",
        "- El coeficiente de determinación $R^2$ es la métrica más intuitiva:\n",
        "    - $0 \\le R^2 \\le 1$: El modelo explica un porcentaje de la variabilidad\n",
        "    - $R^2 = 1$: Modelo perfecto (explica el 100% de la variabilidad)\n",
        "    - $R^2 = 0.9$: El modelo explica el 90% de la variabilidad en los datos\n",
        "    - $R^2 = 0$: El modelo no es mejor que simplemente predecir el promedio\n",
        "\n",
        "## Haciendo predicciones"
      ],
      "metadata": {
        "id": "LKGlBcxOd0dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones para nuevas casas\n",
        "nuevas_superficies = np.array([65, 85, 95])\n",
        "predicciones = w[0] + w[1] * nuevas_superficies\n",
        "\n",
        "print(\"\\nPREDICCIONES PARA NUEVAS VIVIENDAS\")\n",
        "print(\"-\" * 34)\n",
        "for sup, pred in zip(nuevas_superficies, predicciones):\n",
        "    print(f\"   Casa de {sup}m²  →  {pred:,.0f}€\")"
      ],
      "metadata": {
        "id": "T0nwWjqq0edR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114e77b4-2269-4d43-929c-42a654e45e07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PREDICCIONES PARA NUEVAS VIVIENDAS\n",
            "----------------------------------\n",
            "   Casa de 65m²  →  188,272€\n",
            "   Casa de 85m²  →  251,593€\n",
            "   Casa de 95m²  →  283,253€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparación con scikit-learn"
      ],
      "metadata": {
        "id": "E99vM8Zld5Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "modelo_sklearn = LinearRegression()\n",
        "modelo_sklearn.fit(superficie.reshape(-1, 1), precio)\n",
        "\n",
        "# Comparamos resultados\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARACIÓN: Nuestra Implementación vs scikit-learn\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n{'Parámetro':<25} {'Nuestra impl.':<20} {'scikit-learn':<20}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'w₀ (intercepto)':<25} {w[0]:>15,.2f}€   {modelo_sklearn.intercept_:>15,.2f}€\")\n",
        "print(f\"{'w₁ (pendiente)':<25} {w[1]:>15,.2f}€/m² {modelo_sklearn.coef_[0]:>14,.2f}€/m²\")\n",
        "print(\"\\n¡Los resultados son idénticos! ✓\")"
      ],
      "metadata": {
        "id": "oYTFVW4W0gEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0567abd7-17ae-4442-fbd0-3f23fd96cde7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "COMPARACIÓN: Nuestra Implementación vs scikit-learn\n",
            "============================================================\n",
            "\n",
            "Parámetro                 Nuestra impl.        scikit-learn        \n",
            "------------------------------------------------------------\n",
            "w₀ (intercepto)                -17,518.73€        -17,518.73€\n",
            "w₁ (pendiente)                   3,166.02€/m²       3,166.02€/m²\n",
            "\n",
            "¡Los resultados son idénticos! ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Ventajas, Limitaciones y Cuándo Usarlo**\n",
        "\n",
        "## Ventajas del método de mínimos cuadrados\n",
        "\n",
        "- **Solución exacta**: Encuentra los coeficientes óptimos directamente, sin iteraciones\n",
        "- **Rápido y eficiente**: Para datasets pequeños y medianos, es computacionalmente muy eficiente\n",
        "- **Interpretabilidad**: Los coeficientes tienen una interpretación directa y clara\n",
        "- **Garantía matemática**: Si existe solución, este método la encuentra\n",
        "- **Sin hiperparámetros**: No requiere ajuste de learning rate u otros parámetros\n",
        "\n",
        "## Limitaciones importantes"
      ],
      "metadata": {
        "id": "MyFfz5WWeunw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de problema con multicolinealidad\n",
        "X_problema = np.column_stack([superficie, superficie * 2])  # Columnas linealmente dependientes\n",
        "print(\"Matriz con columnas linealmente dependientes:\")\n",
        "print(X_problema[:3])\n",
        "print(f\"\\nDeterminante de X.T @ X: {np.linalg.det(X_problema.T @ X_problema):.10f}\")\n",
        "print(\"Un determinante cercano a 0 indica problemas de inversión matricial\")"
      ],
      "metadata": {
        "id": "MxawDmVwevly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efccd9f2-384d-4fe9-8406-ae6b3737b7a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz con columnas linealmente dependientes:\n",
            "[[ 50 100]\n",
            " [ 55 110]\n",
            " [ 60 120]]\n",
            "\n",
            "Determinante de X.T @ X: 0.0000000000\n",
            "Un determinante cercano a 0 indica problemas de inversión matricial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problemas comunes:**\n",
        "- **Matrices singulares**: Cuando las variables son linealmente dependientes\n",
        "- **Multicolinealidad**: Variables predictoras muy correlacionadas entre sí\n",
        "- **No escala bien**: Para datasets muy grandes (millones de registros), la inversión de matriz se vuelve costosa ($O(n^3)$)\n",
        "- **Sensibilidad a outliers**: Los errores al cuadrado amplifican el efecto de valores atípicos\n",
        "\n",
        "Ahora que conocemos las limitaciones del método, surge la pregunta natural: ¿cuándo debemos usar mínimos cuadrados y cuándo recurrir a alternativas como Gradient Descent?\n",
        "\n",
        "## ¿Cuándo usar mínimos cuadrados vs Gradient Descent?\n",
        "\n",
        "**Usa mínimos cuadrados cuando:**\n",
        "- Tienes < 10,000 muestras y < 100 características\n",
        "- Necesitas la solución exacta en una sola operación\n",
        "- El dataset cabe cómodamente en memoria RAM\n",
        "\n",
        "**Usa Gradient Descent cuando:**\n",
        "- Tienes millones de registros o cientos de características\n",
        "- El dataset no cabe en memoria (puedes usar mini-batches)\n",
        "- Necesitas actualizar el modelo con nuevos datos continuamente\n",
        "- Trabajas con redes neuronales u otros modelos no lineales\n",
        "\n",
        "---\n",
        "\n",
        "# **5. Conclusión**\n",
        "\n",
        "Hemos visto cómo el método de mínimos cuadrados nos permite encontrar la mejor recta que se ajusta a nuestros datos mediante una solución matemática elegante y directa.\n",
        "\n",
        "**En resumen:**\n",
        "- **Fácil de implementar** con pocas líneas de código\n",
        "- **Resultados interpretables** que podemos explicar a cualquier stakeholder\n",
        "- **Extremadamente efectivo** para problemas con relaciones lineales\n",
        "- **Base fundamental** para entender métodos más complejos\n",
        "\n",
        "**Próximos pasos:** En el siguiente artículo de esta serie, exploraremos el **algoritmo de Gradient Descent**, que nos permitirá escalar a problemas más grandes, allanando el camino hacia técnicas más avanzadas de Machine Learning."
      ],
      "metadata": {
        "id": "h1GOTQ9wPTkl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}