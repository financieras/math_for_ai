# Matemáticas para Inteligencia Artificial


## 1. Fundamentos Matemáticos
### 1.1. Funciones
- Concepto de función, dominio y rango
- Tipos de funciones (lineales, cuadráticas, exponenciales, logarítmicas)
- Representación gráfica en el plano cartesiano

### 1.2. Geometría Analítica
  - Plano cartesiano
  - Distancia entre dos puntos
  - Recta: ecuación punto-pendiente, pendiente, intersección con los ejes
  - Circunferencia: ecuación general y canónica

### 1.3. Polinomios
- Definición y operaciones básicas
- Raíces y factorización
- Inecuaciones

### 1.4. Trigonometría
- Funciones trigonométricas básicas (seno, coseno, tangente)
- Radianes vs grados
- Gráficas de funciones trigonométricas
- Funciones trigonométricas inversas
- Funciones hiperbólicas (tanh)
- Aplicaciones en funciones de activación de redes neuronales


## 2. Álgebra Lineal
### 2.1. Vectores
- Definición y representación gráfica
- Operaciones suma y resta
- Multiplicación por escalar
- Norma de un vector y distancia
- Normalización
- Producto escala (producto punto: "dot product")
- Producto vectorial (producto cruz)

### 2.2. Matrices
- Definición y propiedades
- Operaciones
  - Producto por escalar
  - Suma matricial
  - Multiplicación de matrices
- Matrices especiales (identidad, transpuesta)
- Determinantes
- Regla de Cramer
- Matriz inversa
- Resolución de sistemas lineales mediante matrices

### 2.3. Sistemas de Ecuaciones
- Sistemas de ecuaciones lineales
- Métodos de resolución (igualación, sustitución, reducción)
- Métodos matriciales:
  - Método de Gauss
  - Método de Gauss-Jordan
- Interpretación geométrica
  - Dos ecuaciones: intersección de rectas
  - Tres ecuaciones: intersección de planos
  - Dimensiones superiores: hiperplanos
- Aplicaciones en modelos de machine learning

### 2.4. Espacios vectoriales
- Definición
- Propiedades
- Bases y dimensiones
- Subespacios

### 2.5. Transformaciones Lineales
- Definición y propiedades
- Representación matricial
- Autovalores y autovectores
- Cambio de base
- Aplicaciones en redes neuronales
- Aplicaciones en reducción de dimensionalidad (PCA)


## 3. Cálculo
### 3.1. Funciones
- Continuidad
- Límites, asíntotas
- Funciones de varias variables

### 3.2. Cálculo Diferencial
- Concepto de Derivada y su interpretación
- Reglas de derivación
- Derivadas de funciones compuestas (regla de la cadena)
- Derivadas parciales
- Gradiente y derivadas direccionales
- Aplicaciones en optimización

### 3.3. Optimización
- Extremos locales y globales
- Puntos de inflexión
- Concavidad y convexidad
- Descenso del gradiente
- Optimización con restricciones (Método de Lagrange)
- Aplicaciones en entrenamiento de modelos: funciones de costo

### 3.4. Cálculo integral
- Concepto de integral
- Integrales definidas e indefinidas
- Teorema fundamental del cálculo
- Técnicas de integración
- Integrales múltiples


## 4. Estadística y Probabilidad
### 4.1. Estadística Descriptiva
- Tipos de variables: cualitativas y cuantitativas3
- Distribución de frecuencias y tablas de frecuencias15
- Medidas de tendencia central: media, mediana y moda13
- Medidas de dispersión: rango, desviación estándar y varianza13
- Medidas de posición: percentiles y cuartiles
- Representaciones gráficas: histogramas, gráficos de barras

### 4.2. Fundamentos de Probabilidad
- Concepto de probabilidad
- Espacios muestrales y eventos
- Probabilidad condicional
- Teorema de Bayes
- Independencia de eventos

### 4.3. Distribuciones de probabilidad 
- Variables aleatorias discretas y contínuas
- Distribuciones: Uniforme, Normal, Binomial, Poisson, Exponencial
- Funciones de densidad y distribución
- Esperanza matemática y varianza

### 4.4. Inferencia
- Muestreo y estimación de parámetros
- Pruebas de hipótesis
- Intervalos de confianza
- Pruebas de hipótesis

### 4.5. Teoría de la Información
- Entropía
- Información mutua
- Divergencia KL
- Aplicaciones en machine learning

## 5. Temas Avanzados
### 5.1. Métodos de Optimización
- Variaciones del descenso del gradiente
- Descenso de gradiente estocástico
- Algoritmos modernos de optimización
- Algoritmos de optimización avanzados (Adam, RMSprop)

### 5.2. Métodos Numéricos
- Integración numérica
- Interpolación
- Análisis de errores
- Consideraciones computacionales

### 5.3. Teoría de Grafos
- Conceptos básicos
- Algoritmos de grafos
- Aplicaciones en redes neuronales

### 5.4. Álgebra Tensorial
- Operaciones con tensores
- Cálculo tensorial
- Aplicaciones en frameworks de deep learning

### 5.5. Geometría Computacional
- Conceptos básicos
- Aplicaciones en reconocimiento de patrones
- Visión por computadora

### 5.6. Álgebra Lineal Computacional
- Descomposición en valores singulares (SVD)
- Análisis de componentes principales (PCA)




# Matemáticas para Inteligencia Artificial (Versión Reducida)

## 1. Álgebra Lineal Fundamental
### 1.1. Vectores
- Definición y operaciones básicas
- Producto escalar y norma
- Normalización
- Aplicaciones en IA: representación de datos y características

### 1.2. Matrices
- Operaciones básicas
- Multiplicación matricial
- Matrices especiales (identidad, transpuesta)
- Aplicaciones: transformaciones de datos y operaciones en capas neuronales

### 1.3. Sistemas de Ecuaciones Lineales
- Métodos de resolución básicos
- Método de Gauss
- Aplicaciones en modelos lineales

## 2. Cálculo para Optimización
### 2.1. Derivadas
- Concepto y reglas básicas
- Derivadas parciales
- Gradiente
- Regla de la cadena
- Aplicación directa al descenso del gradiente

### 2.2. Optimización
- Extremos locales y globales
- Descenso del gradiente
- Aplicaciones en entrenamiento de modelos

## 3. Probabilidad y Estadística
### 3.1. Estadística Descriptiva
- Medidas de tendencia central y dispersión
- Visualización de datos
- Aplicaciones en análisis exploratorio de datos

### 3.2. Probabilidad Básica
- Conceptos fundamentales
- Probabilidad condicional
- Teorema de Bayes
- Aplicaciones en clasificación y toma de decisiones

### 3.3. Distribuciones de Probabilidad
- Distribución normal
- Distribución binomial
- Aplicaciones en modelado probabilístico

## 4. Temas Esenciales para Machine Learning
### 4.1. Métodos Numéricos Básicos
- Descenso del gradiente estocástico
- Optimización básica para redes neuronales

### 4.2. Funciones de Activación
- Funciones lineales y no lineales
- Sigmoid, ReLU, tanh
- Propiedades y usos en redes neuronales
